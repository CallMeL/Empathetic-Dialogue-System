{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data preprocessing codes extracted from src/EDA/69kdataset.ipynb\n",
    "+ will do eda again about our new 4 txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'data_gen (Python -1.-1.-1)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'emotion-emotion_69k.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df = df[['Situation', 'emotion', 'empathetic_dialogues', 'labels']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Situation', 'emotion', 'empathetic_dialogues', 'labels']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['empathetic_dialogues'] = df['empathetic_dialogues'].str.replace(r'^Customer :|Agent :$', '', regex=True).str.strip()\n",
    "df.dropna(inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_counts = df['emotion'].value_counts()\n",
    "# Mapping emotions to their groups\n",
    "emotion_mapping = {\n",
    "    'surprised': 'excited',\n",
    "    'joyful': 'excited',\n",
    "    'terrified': 'afraid',\n",
    "    'anxious': 'afraid',\n",
    "    'apprehensive': 'afraid',\n",
    "    'disgusted': 'disgusted',\n",
    "    'embarrassed': 'disgusted',\n",
    "    'guilty': 'disgusted',\n",
    "    'ashamed': 'disgusted',\n",
    "    'angry': 'annoyed',\n",
    "    'annoyed': 'annoyed',\n",
    "    'jealous': 'annoyed',\n",
    "    'furious': 'annoyed',\n",
    "    'faithful': 'grateful',\n",
    "    'trusting': 'grateful',\n",
    "    'grateful': 'grateful',\n",
    "    'caring': 'grateful',\n",
    "    'hopeful': 'grateful',\n",
    "    'sad': 'disappointed',\n",
    "    'disappointed': 'disappointed',\n",
    "    'devastated': 'disappointed',\n",
    "    'lonely': 'disappointed',\n",
    "    'nostalgic': 'disappointed',\n",
    "    'sentimental': 'disappointed',\n",
    "    'proud': 'impressed',\n",
    "    'impressed': 'impressed',\n",
    "    'content': 'impressed',\n",
    "    'anticipating': 'prepared',\n",
    "    'prepared': 'prepared',\n",
    "    'confident': 'prepared'\n",
    "}\n",
    "emotions = {}\n",
    "df['grouped_emotion'] = df['emotion'].map(emotion_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counts = df['grouped_emotion'].value_counts()\n",
    "print(group_counts)\n",
    "print(\"total counts:\", df['grouped_emotion'].shape[0])\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Situation', 'grouped_emotion', 'empathetic_dialogues', 'labels']]\n",
    "for column in df.columns:\n",
    "    min_length_row = df[column].str.len().idxmin() \n",
    "    print(f\"Column '{column}' - Shortest entry: '{df[column][min_length_row]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['Situation','grouped_emotion', 'empathetic_dialogues', 'labels']\n",
    "mask = ~df.apply(lambda x: x.str.len() < 3).any(axis=1)\n",
    "df = df[mask]\n",
    "\n",
    "for column in df.columns:\n",
    "    min_length_row = df[column].str.len().idxmin() \n",
    "    print(f\"Column '{column}' - Shortest entry: '{df[column][min_length_row]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make txt files with full (59k) data (w/o deleting repeated converstaion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) full data (59k) & have endOfText in every 2 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_eachconv_eot(df, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            f.write(f\"<bot> {row['empathetic_dialogues']}\\n\")\n",
    "            f.write(f\"<human> {row['labels']} <endOfText>\\n\")\n",
    "\n",
    "# output_file = 'emotion.txt'\n",
    "# save_conversation_to_file(df, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_eachconv_eot(df, '59k_eachconv_eot.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) full data (59k) & have endOfText at the very end of whole conversation within the same context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_wholeconv_eot(df, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        prev_emotion = None  \n",
    "        for i, row in df.iterrows():\n",
    "            f.write(f\"<bot> {row['empathetic_dialogues']}\\n\")\n",
    "            \n",
    "            if i == len(df) - 1 or row['grouped_emotion'] != df.iloc[i + 1]['grouped_emotion']:\n",
    "                f.write(f\"<human> {row['labels']} <endOfText>\\n\")\n",
    "            else:\n",
    "                f.write(f\"<human> {row['labels']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_wholeconv_eot(df, '59k_wholeconv_eot.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Make txt files with 38k data (w deleting repeated converstaion)\n",
    "+ its really weird ...!? i used same code but this time we got 38k data (not 21k) after deleting,,, hmm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_delete = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['empathetic_dialogues'] in df['labels'][:index].values:\n",
    "        index_to_delete.append(index)\n",
    "\n",
    "duplicates = df.loc[index_to_delete]\n",
    "duplicates_sorted = duplicates.sort_index()\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df[~df.isin(duplicates).all(axis=1)].reset_index(drop=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_eachconv_eot(final_df, '38k_eachconv_eot.txt')\n",
    "txt_wholeconv_eot(final_df, '38k_wholeconv_eot.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
