{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to create the appropriate test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nanoGPT.chat import init_model as init_nanoGPT\n",
    "from  nanoGPT.chat import respond as get_respond_nanoGPT\n",
    "import torch\n",
    "from bert_score import score\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_dataframe_cleaned(file_path):\n",
    "    data = []\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                # Remove tags and strip whitespace\n",
    "                line_cleaned = line.replace(\"<bot>\", \"\").replace(\"<human>\", \"\").replace(\"<endOfText>\", \"\").strip()\n",
    "                if line_cleaned:  # Skip empty lines\n",
    "                    # Determine speaker based on presence of \"<bot>\" or \"<human>\"\n",
    "                    if \"<bot>\" in line:\n",
    "                        speaker = \"bot\"\n",
    "                    elif \"<human>\" in line:\n",
    "                        speaker = \"human\"\n",
    "                    else:\n",
    "                        speaker = None\n",
    "\n",
    "                    # Append cleaned message to the data list\n",
    "                    data.append({'speaker': speaker, 'message': line_cleaned})\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataframe(df):\n",
    "    # Filter bot and human messages\n",
    "    bot_messages = df[df['speaker'] == 'bot']['message'].reset_index(drop=True)\n",
    "    human_messages = df[df['speaker'] == 'human']['message'].reset_index(drop=True)\n",
    "\n",
    "    # Ensure both columns have the same length\n",
    "    min_length = min(len(bot_messages), len(human_messages))\n",
    "    bot_messages = bot_messages[:min_length]\n",
    "    human_messages = human_messages[:min_length]\n",
    "\n",
    "    # Combine into a new DataFrame\n",
    "    transformed_df = pd.DataFrame({\n",
    "        'empathetic_dialogues': bot_messages,\n",
    "        'label': human_messages\n",
    "    })\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../data/emotion/validation/validation_data.txt\" \n",
    "\n",
    "val_df = txt_to_dataframe_cleaned(file_path)\n",
    "val_df = transform_dataframe(val_df)\n",
    "\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing model's output, because we get (response, emotion, context), and we only want the response.\n",
    "\n",
    "input_file_path = '../../data/emotion/validation/val_df_with_labels.csv'  \n",
    "output_file_path = '../../data/emotion/validation/final_val.csv'  \n",
    "\n",
    "val_df = pd.read_csv(input_file_path)\n",
    "\n",
    "# Columns to modify\n",
    "columns_to_modify = [\n",
    "    'new_label_withoutemotion_single',\n",
    "    'new_label_withoutemotion_whole',\n",
    "    'new_label_withemotion',\n",
    "    'new_label_withcontext',\n",
    "    'new_label_gpt_withoutemotion',\n",
    "    'new_label_gpt_blocksize_256'\n",
    "]\n",
    "\n",
    "for column in columns_to_modify:\n",
    "    val_df[column] = val_df[column].str.extract(r'\"([^\"]+)\"|\\'([^\\']+)\\'').fillna('').sum(axis=1)\n",
    "\n",
    "\n",
    "val_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Processed file saved at: {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
