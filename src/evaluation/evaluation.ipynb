{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading GPT-2 encodings...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nanoGPT.chat import init_model as init_nanoGPT\n",
    "from  nanoGPT.chat import respond as get_respond_nanoGPT\n",
    "import torch\n",
    "from bert_score import score\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/emotion/validation/100_validation.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Situation</th>\n",
       "      <th>grouped_emotion</th>\n",
       "      <th>empathetic_dialogues</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last night I heard strange noises coming from ...</td>\n",
       "      <td>afraid</td>\n",
       "      <td>In the middle of the night I heard some weird ...</td>\n",
       "      <td>Should have grabbed the gun.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My mom and sister threw me a baby shower when ...</td>\n",
       "      <td>excited</td>\n",
       "      <td>that was very nice of them congratulations</td>\n",
       "      <td>Thank you!  It was so nice, I had no idea it w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I just applied for a new job.  After the inter...</td>\n",
       "      <td>grateful</td>\n",
       "      <td>Oh really, do you feel like you did a great job?</td>\n",
       "      <td>I do!  I'm feeling very optimistic about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I loaned some money to my friend at work. Turn...</td>\n",
       "      <td>annoyed</td>\n",
       "      <td>Wow! What a jerk for him to up and leave with ...</td>\n",
       "      <td>It was a medium amount of money but still, he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was out walking late last night and seen som...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oh my god. What happened?</td>\n",
       "      <td>Well, I started walking much faster. It looked...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Situation grouped_emotion  \\\n",
       "0  Last night I heard strange noises coming from ...          afraid   \n",
       "1  My mom and sister threw me a baby shower when ...         excited   \n",
       "2  I just applied for a new job.  After the inter...        grateful   \n",
       "3  I loaned some money to my friend at work. Turn...         annoyed   \n",
       "4  I was out walking late last night and seen som...             NaN   \n",
       "\n",
       "                                empathetic_dialogues  \\\n",
       "0  In the middle of the night I heard some weird ...   \n",
       "1         that was very nice of them congratulations   \n",
       "2   Oh really, do you feel like you did a great job?   \n",
       "3  Wow! What a jerk for him to up and leave with ...   \n",
       "4                          Oh my god. What happened?   \n",
       "\n",
       "                                              labels  \n",
       "0                       Should have grabbed the gun.  \n",
       "1  Thank you!  It was so nice, I had no idea it w...  \n",
       "2        I do!  I'm feeling very optimistic about it  \n",
       "3  It was a medium amount of money but still, he ...  \n",
       "4  Well, I started walking much faster. It looked...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ../trained-saved/block_size=64/withoutemotion/singleConversation/ckpt.pt\n",
      "number of parameters: 3.42M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sofiagermer/Desktop/SOFIA/IAS/WinterSemester_24_25/ml_proj/Project-ML/src/nanoGPT/chat.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ../trained-saved/block_size=64/withoutemotion/wholeConversation/ckpt.pt\n",
      "number of parameters: 3.42M\n",
      "Loading model from: ../trained-saved/block_size=64/withemotion/ckpt.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sofiagermer/Desktop/SOFIA/IAS/WinterSemester_24_25/ml_proj/Project-ML/src/nanoGPT/chat.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 3.42M\n",
      "Loading model from: ../trained-saved/block_size=64/withcontext/ckpt.pt\n",
      "number of parameters: 3.42M\n",
      "Loading model from: ../trained-saved/block_size=64/withoutemotion/singleConversation_withGPTdata/ckpt.pt\n",
      "number of parameters: 3.42M\n",
      "Loading model from: ../trained-saved/block_size=256/singleConversation_withGPTdata/ckpt.pt\n",
      "number of parameters: 3.42M\n"
     ]
    }
   ],
   "source": [
    "model_list = {\n",
    "    'withoutemotion_single': 'block_size=64/withoutemotion/singleConversation',\n",
    "    'withoutemotion_whole':'block_size=64/withoutemotion/wholeConversation',\n",
    "    'withemotion':'block_size=64/withemotion',\n",
    "    'withcontext': 'block_size=64/withcontext',\n",
    "    'gpt_withoutemotion': 'block_size=64/withoutemotion/singleConversation_withGPTdata',\n",
    "    'gpt_blocksize_256': 'block_size=256/singleConversation_withGPTdata',\n",
    "}\n",
    "for model_type, model_path in model_list.items():\n",
    "    model_list[model_type] = init_nanoGPT(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_nanoGPT(row,model):\n",
    "    situation = row['Situation']\n",
    "    emotion = row['grouped_emotion']\n",
    "    human = row['empathetic_dialogues']\n",
    "    start = '<bot> ' + human + '<human>'\n",
    "    response, new_emotion, new_context = get_respond_nanoGPT(start, 1, model=model, enable_print=False)\n",
    "    return response #, new_emotion, new_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_type, model in model_list.items():\n",
    "    label = 'new_label_' + model_type\n",
    "    df[label] = df.apply(lambda row: get_response_from_nanoGPT(row, model), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./evaluation_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Situation</th>\n",
       "      <th>grouped_emotion</th>\n",
       "      <th>empathetic_dialogues</th>\n",
       "      <th>labels</th>\n",
       "      <th>new_label_withoutemotion_single</th>\n",
       "      <th>new_label_withoutemotion_whole</th>\n",
       "      <th>new_label_withemotion</th>\n",
       "      <th>new_label_withcontext</th>\n",
       "      <th>new_label_gpt_withoutemotion</th>\n",
       "      <th>new_label_gpt_blocksize_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last night I heard strange noises coming from ...</td>\n",
       "      <td>afraid</td>\n",
       "      <td>In the middle of the night I heard some weird ...</td>\n",
       "      <td>Should have grabbed the gun.</td>\n",
       "      <td>Oh no! I hate to hear that. Did you end up ge...</td>\n",
       "      <td>He is, he is so old now. He is a very close f...</td>\n",
       "      <td>I'm sorry to hear that. I'm sure you'll get it!</td>\n",
       "      <td>I hope that there was a big storm.</td>\n",
       "      <td>That sounds like a surprising moment! Did you...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My mom and sister threw me a baby shower when ...</td>\n",
       "      <td>excited</td>\n",
       "      <td>that was very nice of them congratulations</td>\n",
       "      <td>Thank you!  It was so nice, I had no idea it w...</td>\n",
       "      <td>It was nice to have some good friends.</td>\n",
       "      <td>Thank you. I am happy with your friend.</td>\n",
       "      <td>Yeah I was so happy for them. I was so glad I...</td>\n",
       "      <td>I was shocked to see it.</td>\n",
       "      <td>Thank you! How can I assist you today?</td>\n",
       "      <td>That was very nice of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I just applied for a new job.  After the inter...</td>\n",
       "      <td>grateful</td>\n",
       "      <td>Oh really, do you feel like you did a great job?</td>\n",
       "      <td>I do!  I'm feeling very optimistic about it</td>\n",
       "      <td>I did, I was really happy. My best friend was...</td>\n",
       "      <td>Yes, I am so proud of him, I have a lot of fa...</td>\n",
       "      <td>I do, it's a lot better than I am. I'm not su...</td>\n",
       "      <td>I did. I just got a new one and I was so happy.</td>\n",
       "      <td>Thank you! I'm here to assist you with any qu...</td>\n",
       "      <td>I did and I was so proud of myself for my job.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I loaned some money to my friend at work. Turn...</td>\n",
       "      <td>annoyed</td>\n",
       "      <td>Wow! What a jerk for him to up and leave with ...</td>\n",
       "      <td>It was a medium amount of money but still, he ...</td>\n",
       "      <td>I was so happy to see him.</td>\n",
       "      <td>Yes, I was so shocked. I was so excited to se...</td>\n",
       "      <td>Not really, but I didn't know what to do thou...</td>\n",
       "      <td>I was so mad! I was so mad.</td>\n",
       "      <td>No, he's just a bit mad about it.</td>\n",
       "      <td>Yes, he had a lot of money.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was out walking late last night and seen som...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oh my god. What happened?</td>\n",
       "      <td>Well, I started walking much faster. It looked...</td>\n",
       "      <td>I was a little sad and scared to tell someone...</td>\n",
       "      <td>I hope so. I'm a little bummed out.</td>\n",
       "      <td>I went to the hospital to go to a new city an...</td>\n",
       "      <td>I got to go to work and I had to go to work.</td>\n",
       "      <td>I'm here to help! What happened?</td>\n",
       "      <td>I'm here to listen. What happened?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Situation grouped_emotion  \\\n",
       "0  Last night I heard strange noises coming from ...          afraid   \n",
       "1  My mom and sister threw me a baby shower when ...         excited   \n",
       "2  I just applied for a new job.  After the inter...        grateful   \n",
       "3  I loaned some money to my friend at work. Turn...         annoyed   \n",
       "4  I was out walking late last night and seen som...             NaN   \n",
       "\n",
       "                                empathetic_dialogues  \\\n",
       "0  In the middle of the night I heard some weird ...   \n",
       "1         that was very nice of them congratulations   \n",
       "2   Oh really, do you feel like you did a great job?   \n",
       "3  Wow! What a jerk for him to up and leave with ...   \n",
       "4                          Oh my god. What happened?   \n",
       "\n",
       "                                              labels  \\\n",
       "0                       Should have grabbed the gun.   \n",
       "1  Thank you!  It was so nice, I had no idea it w...   \n",
       "2        I do!  I'm feeling very optimistic about it   \n",
       "3  It was a medium amount of money but still, he ...   \n",
       "4  Well, I started walking much faster. It looked...   \n",
       "\n",
       "                     new_label_withoutemotion_single  \\\n",
       "0   Oh no! I hate to hear that. Did you end up ge...   \n",
       "1            It was nice to have some good friends.    \n",
       "2   I did, I was really happy. My best friend was...   \n",
       "3                        I was so happy to see him.    \n",
       "4   I was a little sad and scared to tell someone...   \n",
       "\n",
       "                      new_label_withoutemotion_whole  \\\n",
       "0   He is, he is so old now. He is a very close f...   \n",
       "1           Thank you. I am happy with your friend.    \n",
       "2   Yes, I am so proud of him, I have a lot of fa...   \n",
       "3   Yes, I was so shocked. I was so excited to se...   \n",
       "4               I hope so. I'm a little bummed out.    \n",
       "\n",
       "                               new_label_withemotion  \\\n",
       "0   I'm sorry to hear that. I'm sure you'll get it!    \n",
       "1   Yeah I was so happy for them. I was so glad I...   \n",
       "2   I do, it's a lot better than I am. I'm not su...   \n",
       "3   Not really, but I didn't know what to do thou...   \n",
       "4   I went to the hospital to go to a new city an...   \n",
       "\n",
       "                               new_label_withcontext  \\\n",
       "0                I hope that there was a big storm.    \n",
       "1                          I was shocked to see it.    \n",
       "2   I did. I just got a new one and I was so happy.    \n",
       "3                       I was so mad! I was so mad.    \n",
       "4      I got to go to work and I had to go to work.    \n",
       "\n",
       "                        new_label_gpt_withoutemotion  \\\n",
       "0   That sounds like a surprising moment! Did you...   \n",
       "1            Thank you! How can I assist you today?    \n",
       "2   Thank you! I'm here to assist you with any qu...   \n",
       "3                 No, he's just a bit mad about it.    \n",
       "4                  I'm here to help! What happened?    \n",
       "\n",
       "                        new_label_gpt_blocksize_256  \n",
       "0                                                    \n",
       "1                      That was very nice of them.   \n",
       "2   I did and I was so proud of myself for my job.   \n",
       "3                      Yes, he had a lot of money.   \n",
       "4               I'm here to listen. What happened?   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bleu(compared_column):\n",
    "    bleu_scores = []\n",
    "    smoothing_function = SmoothingFunction().method1  # To avoid 0 scores due to short sentences\n",
    "    for _, row in df.iterrows():\n",
    "        for ref, output in zip(row['labels'], row[compared_column]):\n",
    "            # Tokenize each sentence (split by words)\n",
    "            reference_tokens = [ref.split()]  # BLEU expects a list of lists for references\n",
    "            output_tokens = output.split()\n",
    "            \n",
    "            # Calculate BLEU score\n",
    "            bleu = sentence_bleu(reference_tokens, output_tokens, smoothing_function=smoothing_function)\n",
    "            bleu_scores.append(bleu)\n",
    "    return bleu_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_scores = {}\n",
    "bleu_scores_average = {}\n",
    "for model_type, model in model_list.items():\n",
    "    label = 'new_label_' + model_type\n",
    "    # print(label)\n",
    "    bleu_scores[model_type] = get_bleu(label)\n",
    "    bleu_scores_average[model_type] = sum(bleu_scores[model_type]) / len(bleu_scores[model_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'withoutemotion_single': 0.005812953669427137,\n",
       " 'withoutemotion_whole': 0.0051150978040450336,\n",
       " 'withemotion': 0.0058044728517590806,\n",
       " 'withcontext': 0.00634356982528503,\n",
       " 'gpt_withoutemotion': 0.006235954271153653,\n",
       " 'gpt_blocksize_256': 0.006639256948168738}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BertScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bert_score(compared_column):\n",
    "    # Check for MPS device\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model_outputs = df['labels']\n",
    "    reference_sentences = df[compared_column]\n",
    "\n",
    "    if len(model_outputs) != len(reference_sentences):\n",
    "        raise ValueError(\"Mismatch in lengths: model_outputs and reference_sentences must be of the same length.\")\n",
    "    # Convert model outputs and reference sentences to strings\n",
    "    model_outputs = [str(output) for output in model_outputs]\n",
    "    reference_sentences = [str(ref) for ref in reference_sentences]\n",
    "    # Calculate precision, recall, and F1 for each pair of reference and output\n",
    "    P, R, F1 = score(model_outputs, reference_sentences, lang='en', verbose=True, device = device)\n",
    "    return P, R, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e0c2711dec4d978ef1e225c79a22cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0741e3edc9a44417bf8a7a119ca734eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 13.27 seconds, 7.54 sentences/sec\n",
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4532e4aebb7f4914a8984b79314812de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008ce8b2d14149459798609e5b09269f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.73 seconds, 36.57 sentences/sec\n",
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20ef9c9dd50443eb96055a5a50266cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f6eed96dca431892413d7bad2ebe47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.73 seconds, 57.82 sentences/sec\n",
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61997d8e1bc14e038b3a93b95526bc5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b2277510d941a4aecaa9ac71719274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.17 seconds, 85.14 sentences/sec\n",
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6802a9418fe342f6b1a1c4225870f907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10d3f5fb6a144e5b3fc190cac5d5a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.33 seconds, 75.38 sentences/sec\n",
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6280aa122c4ba0a6ec4edd333cb04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e712404bbc7c471e884d14eb64d1e8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.39 seconds, 71.75 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    }
   ],
   "source": [
    "bert_scores = {}\n",
    "\n",
    "for model_type, model in model_list.items():\n",
    "    label = 'new_label_' + model_type\n",
    "    bert_scores[model_type] = {}\n",
    "    \n",
    "    # Calculate BERT score and assign it to the dictionary\n",
    "    bert_scores[model_type]['P'], bert_scores[model_type]['R'], bert_scores[model_type]['F1'] = calculate_bert_score(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Model: withoutemotion_single\n",
      "Average Precision: 0.8582502603530884\n",
      "Average Recall: 0.8634032607078552\n",
      "Average F1: 0.8606156706809998\n",
      "--------------------------------------------------\n",
      "Model: withoutemotion_whole\n",
      "Average Precision: 0.7520891427993774\n",
      "Average Recall: 0.7587206959724426\n",
      "Average F1: 0.7552400231361389\n",
      "--------------------------------------------------\n",
      "Model: withemotion\n",
      "Average Precision: 0.857521653175354\n",
      "Average Recall: 0.8639740943908691\n",
      "Average F1: 0.8604713678359985\n",
      "--------------------------------------------------\n",
      "Model: withcontext\n",
      "Average Precision: 0.8555678725242615\n",
      "Average Recall: 0.8625133633613586\n",
      "Average F1: 0.8588142991065979\n",
      "--------------------------------------------------\n",
      "Model: gpt_withoutemotion\n",
      "Average Precision: 0.8563526272773743\n",
      "Average Recall: 0.8623169660568237\n",
      "Average F1: 0.8591411113739014\n",
      "--------------------------------------------------\n",
      "Model: gpt_blocksize_256\n",
      "Average Precision: 0.562935471534729\n",
      "Average Recall: 0.5645362734794617\n",
      "Average F1: 0.5636320114135742\n"
     ]
    }
   ],
   "source": [
    "for model_type, model in model_list.items():\n",
    "    label = 'new_label_' + model_type\n",
    "    # P avarage\n",
    "    P_average = sum(bert_scores[model_type]['P']) / len(bert_scores[model_type]['P'])\n",
    "    # R avarage\n",
    "    R_average = sum(bert_scores[model_type]['R']) / len(bert_scores[model_type]['R'])\n",
    "    # F1 avarage\n",
    "    F1_average = sum(bert_scores[model_type]['F1']) / len(bert_scores[model_type]['F1'])\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(f\"Model: {model_type}\")\n",
    "    print(f\"Average Precision: {P_average}\")\n",
    "    print(f\"Average Recall: {R_average}\")\n",
    "    print(f\"Average F1: {F1_average}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # GLUE - Sentiment Analysis Evaluation (SST-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "def evaluate_sentiment(compared_column):\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load multi-class sentiment or emotion pipeline\n",
    "    sentiment_pipeline = pipeline(\n",
    "        \"text-classification\", \n",
    "        model=\"bhadresh-savani/distilbert-base-uncased-emotion\", \n",
    "        device=0 if device == \"mps\" else -1\n",
    "    )\n",
    "    \n",
    "    scores = []\n",
    "    model_outputs = df['labels']\n",
    "    reference_sentences = df[compared_column]\n",
    "\n",
    "    if len(model_outputs) != len(reference_sentences):\n",
    "        raise ValueError(\"Mismatch in lengths: model_outputs and reference_sentences must be of the same length.\")\n",
    "    # Convert model outputs and reference sentences to strings\n",
    "    model_outputs = [str(output) for output in model_outputs]\n",
    "    reference_sentences = [str(ref) for ref in reference_sentences]\n",
    "\n",
    "    for i, (output, reference) in enumerate(zip(model_outputs, reference_sentences), start=1):\n",
    "        output_sentiment = sentiment_pipeline(output)[0]['label']\n",
    "        reference_sentiment = sentiment_pipeline(reference)[0]['label']\n",
    "        \n",
    "        score = 1 if output_sentiment == reference_sentiment else 0\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Using device: mps\n",
      "Using device: mps\n",
      "Using device: mps\n",
      "Using device: mps\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "sentiment_scores = {}\n",
    "\n",
    "for model_type, model in model_list.items():\n",
    "    label = 'new_label_' + model_type\n",
    "    sentiment_scores[model_type] = {}\n",
    "    \n",
    "    sentiment_scores[model_type] = evaluate_sentiment(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Model: withoutemotion_single\n",
      "Average Sentiment Score: 0.53\n",
      "--------------------------------------------------\n",
      "Model: withoutemotion_whole\n",
      "Average Sentiment Score: 0.44\n",
      "--------------------------------------------------\n",
      "Model: withemotion\n",
      "Average Sentiment Score: 0.52\n",
      "--------------------------------------------------\n",
      "Model: withcontext\n",
      "Average Sentiment Score: 0.47\n",
      "--------------------------------------------------\n",
      "Model: gpt_withoutemotion\n",
      "Average Sentiment Score: 0.42\n",
      "--------------------------------------------------\n",
      "Model: gpt_blocksize_256\n",
      "Average Sentiment Score: 0.41\n"
     ]
    }
   ],
   "source": [
    "for model_type, model in model_list.items():\n",
    "    label = 'new_label_' + model_type\n",
    "    GLUE_average = sum(sentiment_scores[model_type]) / len(sentiment_scores[model_type])\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(f\"Model: {model_type}\")\n",
    "    print(f\"Average Sentiment Score: {GLUE_average}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "\n",
    "def get_token_probabilities(reference_text, output_text, model):\n",
    "    try:\n",
    "        # Tokenize the input\n",
    "        input_ids = tokenizer.encode(output_text)  # List of token IDs\n",
    "        input_ids = torch.tensor([input_ids], dtype=torch.long)  # Convert to PyTorch tensor\n",
    "\n",
    "        # Pass the tokenized input to the model\n",
    "        logits, _ = model(input_ids)\n",
    "\n",
    "        # Convert logits to probabilities\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "        # Handle length mismatch\n",
    "        max_length = min(len(input_ids[0]), probs.size(1))  # to deal when reference has difference size of the model output\n",
    "\n",
    "        # Extract probabilities for the predicted tokens\n",
    "        token_probs = []\n",
    "        for i, token_id in enumerate(input_ids[0][:max_length]):\n",
    "            token_probs.append(probs[0, i, token_id].item())\n",
    "\n",
    "        return token_probs\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching token probabilities: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentence_perplexity(token_probs):\n",
    "    \"\"\"\n",
    "    Calculate sentence perplexity based on token probabilities.\n",
    "    \"\"\"\n",
    "    if not token_probs:  # Handle empty token probabilities\n",
    "        return float('inf')\n",
    "\n",
    "    log_probs = np.log(token_probs)\n",
    "    avg_log_prob = np.mean(log_probs)\n",
    "    return np.exp(-avg_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexity(compared_column, model):\n",
    "    \"\"\"\n",
    "    Calculate sentence-level perplexity using token probabilities.\n",
    "    \"\"\"\n",
    "    perplexities = []\n",
    "    print(f\"Calculating token-based perplexity for column: {compared_column}\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        print(f\"\\nProcessing row {index}...\")\n",
    "        reference_text = row['labels']\n",
    "        output_text = row[compared_column]\n",
    "        \n",
    "        print(f\"Reference Text: {reference_text}\")\n",
    "        print(f\"Output Text: {output_text}\")\n",
    "        \n",
    "        # Query model for token probabilities\n",
    "        token_probs = get_token_probabilities(reference_text, output_text, model)\n",
    "        print(f\"Token Probabilities: {token_probs}\")\n",
    "        \n",
    "        # Calculate sentence-level perplexity\n",
    "        sentence_perplexity = calculate_sentence_perplexity(token_probs)\n",
    "        print(f\"Sentence Perplexity for row {index}: {sentence_perplexity}\")\n",
    "        \n",
    "        perplexities.append(sentence_perplexity)\n",
    "    \n",
    "    print(f\"Completed token-based perplexity calculations for column: {compared_column}\")\n",
    "    return perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_scores_average():\n",
    "    # Compute perplexities for each model\n",
    "    perplexity_scores = {}\n",
    "    perplexity_scores_average = {}\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Columns in the DataFrame:\")\n",
    "    print(df.columns)\n",
    "    print(\"\")\n",
    "    \n",
    "    for model_type, model in model_list.items():\n",
    "        label = 'new_label_' + model_type\n",
    "        print(label)\n",
    "        perplexity_scores[model_type] = get_perplexity(label, model)\n",
    "        perplexity_scores_average[model_type] = sum(perplexity_scores[model_type]) / len(perplexity_scores[model_type])\n",
    "\n",
    "        print(f\"Average Perplexity for {model_type}: {perplexity_scores_average[model_type]}\")\n",
    "\n",
    "    return perplexity_scores_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in the DataFrame:\n",
      "Index(['Situation', 'grouped_emotion', 'empathetic_dialogues', 'labels',\n",
      "       'new_label_withoutemotion_single', 'new_label_withoutemotion_whole',\n",
      "       'new_label_withemotion', 'new_label_withcontext',\n",
      "       'new_label_gpt_withoutemotion', 'new_label_gpt_blocksize_256'],\n",
      "      dtype='object')\n",
      "\n",
      "new_label_withoutemotion_single\n",
      "Calculating token-based perplexity for column: new_label_withoutemotion_single\n",
      "\n",
      "Processing row 0...\n",
      "Reference Text: Should have grabbed the gun.\n",
      "Output Text:  Oh no! I hate to hear that. Did you end up getting it? \n",
      "Token Probabilities: [8.637574501335621e-05]\n",
      "Sentence Perplexity for row 0: 11577.324164849406\n",
      "\n",
      "Processing row 1...\n",
      "Reference Text: Thank you!  It was so nice, I had no idea it was happening.  They're not usually so good with secrets haha\n",
      "Output Text:  It was nice to have some good friends. \n",
      "Token Probabilities: [0.17217420041561127]\n",
      "Sentence Perplexity for row 1: 5.80807111394216\n",
      "\n",
      "Processing row 2...\n",
      "Reference Text: I do!  I'm feeling very optimistic about it\n",
      "Output Text:  I did, I was really happy. My best friend was cheating on me. \n",
      "Token Probabilities: [0.23521481454372406]\n",
      "Sentence Perplexity for row 2: 4.2514328952444025\n",
      "\n",
      "Processing row 3...\n",
      "Reference Text: It was a medium amount of money but still, he did me so dirty.\n",
      "Output Text:  I was so happy to see him. \n",
      "Token Probabilities: [0.22190287709236145]\n",
      "Sentence Perplexity for row 3: 4.506476045300555\n",
      "\n",
      "Processing row 4...\n",
      "Reference Text: Well, I started walking much faster. It looked like they were carrying a weapon or something.\n",
      "Output Text:  I was a little sad and scared to tell someone about it. \n",
      "Token Probabilities: [0.27045926451683044]\n",
      "Sentence Perplexity for row 4: 3.6974144767659487\n",
      "\n",
      "Processing row 5...\n",
      "Reference Text: I had braces growing up too, the worst part for me was the molding!\n",
      "Output Text:  I agree with you.  I am so sad. \n",
      "Token Probabilities: [0.2626833915710449]\n",
      "Sentence Perplexity for row 5: 3.8068642026404693\n",
      "\n",
      "Processing row 6...\n",
      "Reference Text: Yes, and it really sucks if you forget something important.\n",
      "Output Text:  Oh that's so exciting! Are you going to be able to go to college? \n",
      "Token Probabilities: [0.00011797370825661346]\n",
      "Sentence Perplexity for row 6: 8476.464924072958\n",
      "\n",
      "Processing row 7...\n",
      "Reference Text: O no! That's a terrible thing to have happen or see.\n",
      "Output Text:  I hope you didn't get to go to the doctor and it's not so gross. \n",
      "Token Probabilities: [0.09766306728124619]\n",
      "Sentence Perplexity for row 7: 10.239285206149017\n",
      "\n",
      "Processing row 8...\n",
      "Reference Text: Wow, that is so disgusting.\n",
      "Output Text:  That is a good attitude to have.  \n",
      "Token Probabilities: [0.0067333136685192585]\n",
      "Sentence Perplexity for row 8: 148.51528522655508\n",
      "\n",
      "Processing row 9...\n",
      "Reference Text: Wow.Really? What kind?\n",
      "Output Text:  That's great! Did you get it in the car? \n",
      "Token Probabilities: [0.003757544793188572]\n",
      "Sentence Perplexity for row 9: 266.131225318387\n",
      "\n",
      "Processing row 10...\n",
      "Reference Text: Omg my current dog does that sometimes. She pukes up bile if she doesn't eat, so I always have to make sure she is eating her food.\n",
      "Output Text:  Oh man..I have a dog, I hate cats!  \n",
      "Token Probabilities: [0.004717991221696138]\n",
      "Sentence Perplexity for row 10: 211.95461225137578\n",
      "\n",
      "Processing row 11...\n",
      "Reference Text: That's amazing, It's always nice to get on with your family! Have you always got on with them? \n",
      "Output Text:  That's awesome. I hope you have a wonderful life. \n",
      "Token Probabilities: [0.003954942338168621]\n",
      "Sentence Perplexity for row 11: 252.84818702642846\n",
      "\n",
      "Processing row 12...\n",
      "Reference Text: I am not sure as I could not stop because of all the traffic.\n",
      "Output Text:  I am so sorry.  I hope it goes smoothly \n",
      "Token Probabilities: [0.0004583811096381396]\n",
      "Sentence Perplexity for row 12: 2181.590774518242\n",
      "\n",
      "Processing row 13...\n",
      "Reference Text: I can barely walk much less imagine that.\n",
      "Output Text:  I bet he was! He was so happy \n",
      "Token Probabilities: [0.001374747953377664]\n",
      "Sentence Perplexity for row 13: 727.4060656304792\n",
      "\n",
      "Processing row 14...\n",
      "Reference Text: Oh for sure! I love riding jet skis!\n",
      "Output Text:  I am sorry to hear that. I hope you can get a good grade in hope. \n",
      "Token Probabilities: [0.03833138942718506]\n",
      "Sentence Perplexity for row 14: 26.088279473918274\n",
      "\n",
      "Processing row 15...\n",
      "Reference Text: I feel like this is me. I'm clean, but I'm stuck with a dirty roommate who doesn't do dishes. And I also live in a place that is old and looks terrible to begin with. Sorry you have to deal with that, because I know I hate living in it!\n",
      "Output Text:  That's the worst! I'm sorry. \n",
      "Token Probabilities: [0.0074797323904931545]\n",
      "Sentence Perplexity for row 15: 133.69462272086292\n",
      "\n",
      "Processing row 16...\n",
      "Reference Text: You can get a adviser\n",
      "Output Text:  I hope you feel better now \n",
      "Token Probabilities: [6.245889380807057e-05]\n",
      "Sentence Perplexity for row 16: 16010.530110777996\n",
      "\n",
      "Processing row 17...\n",
      "Reference Text: Yeah, Medical emergency. I borrowed $5000. Hope I'll repay this month.\n",
      "Output Text:  A coworker. \n",
      "Token Probabilities: [0.014228313229978085]\n",
      "Sentence Perplexity for row 17: 70.28239987668165\n",
      "\n",
      "Processing row 18...\n",
      "Reference Text: You shouldn't let those kind of people upset you.\n",
      "Output Text:  I hope the person is very helpful for you. \n",
      "Token Probabilities: [0.1433563232421875]\n",
      "Sentence Perplexity for row 18: 6.975625332623736\n",
      "\n",
      "Processing row 19...\n",
      "Reference Text: Oh no! He doesn't seem like such a good friend then. I hate it when friends pull stuff like that!\n",
      "Output Text:  Oh, that is really sad. I hope you can find something that is wrong. \n",
      "Token Probabilities: [0.0003168970870319754]\n",
      "Sentence Perplexity for row 19: 3155.598586802718\n",
      "\n",
      "Processing row 20...\n",
      "Reference Text: Ohh you have a really good memory. I am very bad at remembering things, lol.\n",
      "Output Text:  That's awesome! What was it like? \n",
      "Token Probabilities: [0.0033690149430185556]\n",
      "Sentence Perplexity for row 20: 296.82266683686004\n",
      "\n",
      "Processing row 21...\n",
      "Reference Text: I wish i could make that type of money!\n",
      "Output Text:  I know that feeling. I am so thankful for the stuff I love the work we get. \n",
      "Token Probabilities: [0.04926016926765442]\n",
      "Sentence Perplexity for row 21: 20.30037685348815\n",
      "\n",
      "Processing row 22...\n",
      "Reference Text: I thought we had a ghost for a long time\n",
      "Output Text:  I don't know. It's a nice thing to do. \n",
      "Token Probabilities: [0.09360136091709137]\n",
      "Sentence Perplexity for row 22: 10.683605347210316\n",
      "\n",
      "Processing row 23...\n",
      "Reference Text: this is true.\n",
      "Output Text:  That's great! Have you ever made a birthday cake for them? \n",
      "Token Probabilities: [0.005892663728445768]\n",
      "Sentence Perplexity for row 23: 169.70253964648975\n",
      "\n",
      "Processing row 24...\n",
      "Reference Text: I get you, I've been in your situation before\n",
      "Output Text:  I was very lonely. It's just so hard to find out what I need to do \n",
      "Token Probabilities: [0.00038832472637295723]\n",
      "Sentence Perplexity for row 24: 2575.164371685087\n",
      "\n",
      "Processing row 25...\n",
      "Reference Text: I see that more in the country I guess. That would be horrifying. But maybe he is just immune to pain?\n",
      "Output Text:  I hate the fact that we're not always here. \n",
      "Token Probabilities: [0.2637896239757538]\n",
      "Sentence Perplexity for row 25: 3.790899675765545\n",
      "\n",
      "Processing row 26...\n",
      "Reference Text: Can you tell me the name of the book? I find myself being engaged by a lot of novels these days.\n",
      "Output Text:  What did you do? \n",
      "Token Probabilities: [0.008129761554300785]\n",
      "Sentence Perplexity for row 26: 123.00483763524196\n",
      "\n",
      "Processing row 27...\n",
      "Reference Text: Wow how exciting, has he been practicing a lot? \n",
      "Output Text:  I bet.  I am sure it will be a lot of fun. \n",
      "Token Probabilities: [0.1694200485944748]\n",
      "Sentence Perplexity for row 27: 5.902489158137406\n",
      "\n",
      "Processing row 28...\n",
      "Reference Text: yea i was very happy he helped me\n",
      "Output Text:  I was happy for you \n",
      "Token Probabilities: [0.0003272478352300823]\n",
      "Sentence Perplexity for row 28: 3055.7879757918563\n",
      "\n",
      "Processing row 29...\n",
      "Reference Text: They wer really nice and trustworthy. I even let them use my wifi password.\n",
      "Output Text:  I was scared at the time, but I was scared of the movie. \n",
      "Token Probabilities: [0.2486063838005066]\n",
      "Sentence Perplexity for row 29: 4.022422854605564\n",
      "\n",
      "Processing row 30...\n",
      "Reference Text: Or it could be you and a dope house party\n",
      "Output Text:  That sounds like a lot of fun, but you can always take it to the next time. \n",
      "Token Probabilities: [0.003076008753851056]\n",
      "Sentence Perplexity for row 30: 325.0966040808676\n",
      "\n",
      "Processing row 31...\n",
      "Reference Text: Yeah it might be a good idea to tell him. But you may want to have the money to give back to him first. \n",
      "Output Text:  I am sure he will understand. \n",
      "Token Probabilities: [0.21595992147922516]\n",
      "Sentence Perplexity for row 31: 4.630488810842607\n",
      "\n",
      "Processing row 32...\n",
      "Reference Text: What did you do with them?\n",
      "Output Text:  I would be mad at all that point.  \n",
      "Token Probabilities: [0.17299383878707886]\n",
      "Sentence Perplexity for row 32: 5.780552689109361\n",
      "\n",
      "Processing row 33...\n",
      "Reference Text: Congrats!!\n",
      "Output Text:  That is awesome!  I am glad you are doing that! \n",
      "Token Probabilities: [0.010435670614242554]\n",
      "Sentence Perplexity for row 33: 95.82517855969934\n",
      "\n",
      "Processing row 34...\n",
      "Reference Text: what was on it\n",
      "Output Text:  That sounds so nice. Did you get to do it? \n",
      "Token Probabilities: [0.001442360458895564]\n",
      "Sentence Perplexity for row 34: 693.3079687762063\n",
      "\n",
      "Processing row 35...\n",
      "Reference Text: I am so ready for it!\n",
      "Output Text:  Yeah I am going to the movies. \n",
      "Token Probabilities: [0.0006268142606131732]\n",
      "Sentence Perplexity for row 35: 1595.3689359616076\n",
      "\n",
      "Processing row 36...\n",
      "Reference Text: I am going to be a birthday clown.\n",
      "Output Text:  It's a job that I have to give it to my job. \n",
      "Token Probabilities: [0.07926821708679199]\n",
      "Sentence Perplexity for row 36: 12.615396646364387\n",
      "\n",
      "Processing row 37...\n",
      "Reference Text: She was 23 years old. I got her when I was 5.\n",
      "Output Text:  She was 13 and she was a sad thing that happened to me. I'm sorry. \n",
      "Token Probabilities: [0.05672205239534378]\n",
      "Sentence Perplexity for row 37: 17.62982751452922\n",
      "\n",
      "Processing row 38...\n",
      "Reference Text: This was a few months ago.\n",
      "Output Text:  A few years ago, it was a big deal for me \n",
      "Token Probabilities: [0.00020658510038629174]\n",
      "Sentence Perplexity for row 38: 4840.620151841094\n",
      "\n",
      "Processing row 39...\n",
      "Reference Text: It's a band called Say Anything, I've been a fan of theirs since 2006! \n",
      "Output Text:  It's a guitar? \n",
      "Token Probabilities: [0.01603953167796135]\n",
      "Sentence Perplexity for row 39: 62.34595997425667\n",
      "\n",
      "Processing row 40...\n",
      "Reference Text: Oh that's a standard prcedure. Have you ever had one?\n",
      "Output Text:  That's great.  I am so sorry.  It must be hard to be in your life.  \n",
      "Token Probabilities: [0.006836958695203066]\n",
      "Sentence Perplexity for row 40: 146.26386447260796\n",
      "\n",
      "Processing row 41...\n",
      "Reference Text: Have you been before? It seems like such a great way to both play and get a workout \n",
      "Output Text:  I'm glad you are safe. \n",
      "Token Probabilities: [0.16359014809131622]\n",
      "Sentence Perplexity for row 41: 6.112837549616978\n",
      "\n",
      "Processing row 42...\n",
      "Reference Text: No, I hate being by myself.\n",
      "Output Text:  I did, I had a good time, but I was so happy. \n",
      "Token Probabilities: [0.18246658146381378]\n",
      "Sentence Perplexity for row 42: 5.480455609885567\n",
      "\n",
      "Processing row 43...\n",
      "Reference Text: I could see that happening but sounds like you were super brave.\n",
      "Output Text:  Wow!  I hope you didn't have any fun.   \n",
      "Token Probabilities: [8.006908319657668e-05]\n",
      "Sentence Perplexity for row 43: 12489.215063758284\n",
      "\n",
      "Processing row 44...\n",
      "Reference Text: He's quite the piece of garbage.\n",
      "Output Text:  I am too proud of you! \n",
      "Token Probabilities: [0.16584424674510956]\n",
      "Sentence Perplexity for row 44: 6.02975393856699\n",
      "\n",
      "Processing row 45...\n",
      "Reference Text: Tell me about it. How long have you been job hunting for?\n",
      "Output Text:  Yeah, I hope they are good at your job. \n",
      "Token Probabilities: [0.0003111177356913686]\n",
      "Sentence Perplexity for row 45: 3214.217273013356\n",
      "\n",
      "Processing row 46...\n",
      "Reference Text: That is such a beautiful memory to have. I love that we forever have moments like this... How cool Hong Kong! \n",
      "Output Text:  I would love to see that show. I hope you do well! \n",
      "Token Probabilities: [0.03328460827469826]\n",
      "Sentence Perplexity for row 46: 30.043916748155443\n",
      "\n",
      "Processing row 47...\n",
      "Reference Text: I think he was slightly over the limit but he had a few drinks earlier, so I felt a bit uncomfortable.\n",
      "Output Text:  I was a serious accident. I was so mad at my friend. \n",
      "Token Probabilities: [0.2860890030860901]\n",
      "Sentence Perplexity for row 47: 3.495415724522202\n",
      "\n",
      "Processing row 48...\n",
      "Reference Text: IT is. \n",
      "Output Text:  I can relate. I love the food and watch some of the food. \n",
      "Token Probabilities: [0.20426103472709656]\n",
      "Sentence Perplexity for row 48: 4.895696339422016\n",
      "\n",
      "Processing row 49...\n",
      "Reference Text: OH that sucks.\n",
      "Output Text:  I hope you did. \n",
      "Token Probabilities: [0.12347570806741714]\n",
      "Sentence Perplexity for row 49: 8.098758983864299\n",
      "\n",
      "Processing row 50...\n",
      "Reference Text: thats wonderful\n",
      "Output Text:  I hope you will be able to get another one soon. \n",
      "Token Probabilities: [0.10036211460828781]\n",
      "Sentence Perplexity for row 50: 9.963919193043996\n",
      "\n",
      "Processing row 51...\n",
      "Reference Text: I've had that feeling as well, especially if it is with someone that is close to me.  Is it because you dont like confrontation or a different reason?\n",
      "Output Text:  I would be mad at the kid's cheating.  \n",
      "Token Probabilities: [0.23630765080451965]\n",
      "Sentence Perplexity for row 51: 4.231771576567481\n",
      "\n",
      "Processing row 52...\n",
      "Reference Text: No they did not. And it is going to cost too much to take them to court. \n",
      "Output Text:  What kind of car did you get? \n",
      "Token Probabilities: [0.005859061144292355]\n",
      "Sentence Perplexity for row 52: 170.67580886643532\n",
      "\n",
      "Processing row 53...\n",
      "Reference Text: thats good!\n",
      "Output Text:  That's great! I bet you were proud of yourself. \n",
      "Token Probabilities: [0.005038694478571415]\n",
      "Sentence Perplexity for row 53: 198.46410697310688\n",
      "\n",
      "Processing row 54...\n",
      "Reference Text: That is so true! \n",
      "Output Text:  I know. I have a good day here. \n",
      "Token Probabilities: [0.14513356983661652]\n",
      "Sentence Perplexity for row 54: 6.890204665438504\n",
      "\n",
      "Processing row 55...\n",
      "Reference Text: I sort of have. I worked like crazy to get a work visa for the US, so I could be with the person I wanted to spend my life with. It paid off, so I can kind of understand what you're saying.\n",
      "Output Text:  I'm sure you will get it. I hope it will be well for you. \n",
      "Token Probabilities: [0.06763482093811035]\n",
      "Sentence Perplexity for row 55: 14.785283469812924\n",
      "\n",
      "Processing row 56...\n",
      "Reference Text: It sounds like you did great. Studying is the biggest part really.\n",
      "Output Text:  I'm sorry to hear that.  I bet you felt like it was a great time. \n",
      "Token Probabilities: [0.07961507886648178]\n",
      "Sentence Perplexity for row 56: 12.560434709573633\n",
      "\n",
      "Processing row 57...\n",
      "Reference Text: Don't tell her right after she awakes up. Women are never in the best mood right after waking up.\n",
      "Output Text:  That's great! I hope your family will be able to do that. \n",
      "Token Probabilities: [0.003035220317542553]\n",
      "Sentence Perplexity for row 57: 329.4653749582316\n",
      "\n",
      "Processing row 58...\n",
      "Reference Text: Maybe.\n",
      "Output Text:  I hope you can find something else. \n",
      "Token Probabilities: [0.11156269907951355]\n",
      "Sentence Perplexity for row 58: 8.963569438986724\n",
      "\n",
      "Processing row 59...\n",
      "Reference Text: They thought it was a better school, and it probably was, but I didn't feel like it was at the time\n",
      "Output Text:  I am so excited to see my daughter. \n",
      "Token Probabilities: [0.3139285445213318]\n",
      "Sentence Perplexity for row 59: 3.185438270752881\n",
      "\n",
      "Processing row 60...\n",
      "Reference Text: That's great. I hope you have a wonderful time.\n",
      "Output Text:  I hope you're doing well. \n",
      "Token Probabilities: [0.16816574335098267]\n",
      "Sentence Perplexity for row 60: 5.946514314231505\n",
      "\n",
      "Processing row 61...\n",
      "Reference Text: That is bad. What are you planning to do instead?\n",
      "Output Text:  I hope you are ok. \n",
      "Token Probabilities: [0.13333624601364136]\n",
      "Sentence Perplexity for row 61: 7.499836165311658\n",
      "\n",
      "Processing row 62...\n",
      "Reference Text: A little bit bu, they took the insurance money and bought a big house - i mean BIG! I know they needed more room for my mother to move in, but what they bought was way over and above what was needed.\n",
      "Output Text:  I don't know. She is just so kind of looking at her job. \n",
      "Token Probabilities: [0.16014893352985382]\n",
      "Sentence Perplexity for row 62: 6.244187694285126\n",
      "\n",
      "Processing row 63...\n",
      "Reference Text: Mostly happy. They have annoyed me greatly all summer\n",
      "Output Text:  I am so happy for you. \n",
      "Token Probabilities: [0.2529599070549011]\n",
      "Sentence Perplexity for row 63: 3.953195633420932\n",
      "\n",
      "Processing row 64...\n",
      "Reference Text: That is really interesting. Still over my head, but you did a decent job of explaining it in layman's terms. I appreciate it. So are you a med student, or what?\n",
      "Output Text:  I hope so. I feel that I will be fine. \n",
      "Token Probabilities: [0.05603809282183647]\n",
      "Sentence Perplexity for row 64: 17.845004168491762\n",
      "\n",
      "Processing row 65...\n",
      "Reference Text: Oh wow! Congratulations! I also recently applied for grad school to study Computer Science (seriously). What are you wanting to study?\n",
      "Output Text:  I'm sure you will do well.  I hope you do do well!  \n",
      "Token Probabilities: [0.07723205536603928]\n",
      "Sentence Perplexity for row 65: 12.947991546522058\n",
      "\n",
      "Processing row 66...\n",
      "Reference Text: I'm sure that much be hard to stand by and watch as someone who works hard for their things. \n",
      "Output Text:  Yes, I was so happy to see her. \n",
      "Token Probabilities: [0.00017120152187999338]\n",
      "Sentence Perplexity for row 66: 5841.069571221264\n",
      "\n",
      "Processing row 67...\n",
      "Reference Text: It does get better, but it was just so sudden.\n",
      "Output Text:  I hope it goes well! \n",
      "Token Probabilities: [0.14914217591285706]\n",
      "Sentence Perplexity for row 67: 6.705011468950905\n",
      "\n",
      "Processing row 68...\n",
      "Reference Text: True, driving takes more focus than a lot of people can handle\n",
      "Output Text:  I think it would be a relief.  I don't know how that would be. \n",
      "Token Probabilities: [0.22320634126663208]\n",
      "Sentence Perplexity for row 68: 4.480159453917333\n",
      "\n",
      "Processing row 69...\n",
      "Reference Text: I have no idea. We found it after she left. It was really gross. I wonder if her house is that nasty?\n",
      "Output Text:  I was so mad at the moment.  I was so embarrassed. \n",
      "Token Probabilities: [0.19372574985027313]\n",
      "Sentence Perplexity for row 69: 5.161936401190243\n",
      "\n",
      "Processing row 70...\n",
      "Reference Text: That's good, it sounds like his bathroom motivated you to take yours to the next level. That's probably good for society.\n",
      "Output Text:  That sounds like a lot of fun! You must feel like you have a good time. \n",
      "Token Probabilities: [0.001388342003338039]\n",
      "Sentence Perplexity for row 70: 720.2836171459661\n",
      "\n",
      "Processing row 71...\n",
      "Reference Text: I do look a little like a somewhat taller version of him.\n",
      "Output Text:  I do, but I am so happy he won't be coming up. \n",
      "Token Probabilities: [0.2519608438014984]\n",
      "Sentence Perplexity for row 71: 3.968870658283027\n",
      "\n",
      "Processing row 72...\n",
      "Reference Text: Absolutely! Not to mention gardening saves a ton of money in the long run.\n",
      "Output Text:  That's great! What was it? \n",
      "Token Probabilities: [0.005888714455068111]\n",
      "Sentence Perplexity for row 72: 169.81635085724895\n",
      "\n",
      "Processing row 73...\n",
      "Reference Text: That's great! Not too many 16 year olds are that responsible.\n",
      "Output Text:  That's great! I bet he loves it in the future. \n",
      "Token Probabilities: [0.0037634309846907854]\n",
      "Sentence Perplexity for row 73: 265.71498296843697\n",
      "\n",
      "Processing row 74...\n",
      "Reference Text: The prices have risen alot with all the technology and electrical components.\n",
      "Output Text:  That's a good idea. It's just because you know how that goes. \n",
      "Token Probabilities: [0.004487837199121714]\n",
      "Sentence Perplexity for row 74: 222.82448217945685\n",
      "\n",
      "Processing row 75...\n",
      "Reference Text: Does he get anything else?\n",
      "Output Text:  You and something you know? \n",
      "Token Probabilities: [0.01473058108240366]\n",
      "Sentence Perplexity for row 75: 67.88598456543882\n",
      "\n",
      "Processing row 76...\n",
      "Reference Text: Sounds like you have a very responsible young lady growing up.\n",
      "Output Text:  I'm happy for you.  I hope she recovers! \n",
      "Token Probabilities: [0.0750371441245079]\n",
      "Sentence Perplexity for row 76: 13.326733202168736\n",
      "\n",
      "Processing row 77...\n",
      "Reference Text: ah you used her. You should have filled. But however she will understand\n",
      "Output Text:  Oh no, did you find out who was it? \n",
      "Token Probabilities: [0.0005291613633744419]\n",
      "Sentence Perplexity for row 77: 1889.7827188724405\n",
      "\n",
      "Processing row 78...\n",
      "Reference Text: I gave him some Tylenol, and we ended up snuggling til he could go back to sleep.  \n",
      "Output Text:  I know. I was so embarrassed for not to worry about it. \n",
      "Token Probabilities: [0.11756549030542374]\n",
      "Sentence Perplexity for row 78: 8.50589741430157\n",
      "\n",
      "Processing row 79...\n",
      "Reference Text: It was a hand written note from my dead mother. I never had read or seen it before. \n",
      "Output Text:  A few days ago I was able to get a job for a job and there is no one to come in. \n",
      "Token Probabilities: [0.0008578406414017081]\n",
      "Sentence Perplexity for row 79: 1165.7176773135902\n",
      "\n",
      "Processing row 80...\n",
      "Reference Text: Ouch, I hope you don't either. I'd keep any eye out at work from now on.\n",
      "Output Text:  I know.  I am so sorry.  I am sure you will get it. \n",
      "Token Probabilities: [0.16735796630382538]\n",
      "Sentence Perplexity for row 80: 5.975216012033617\n",
      "\n",
      "Processing row 81...\n",
      "Reference Text: I hope both our ego and your nose heal up quickly!\n",
      "Output Text:  I am sorry, I hope you can find something else to do. \n",
      "Token Probabilities: [0.04358411952853203]\n",
      "Sentence Perplexity for row 81: 22.944136782328652\n",
      "\n",
      "Processing row 82...\n",
      "Reference Text: Yeah I would go off with my friends and have adventures. I miss that so much.\n",
      "Output Text:  I've been there.  I am so proud of you. \n",
      "Token Probabilities: [0.17831635475158691]\n",
      "Sentence Perplexity for row 82: 5.608010557377662\n",
      "\n",
      "Processing row 83...\n",
      "Reference Text: a bearded dragon\n",
      "Output Text:  It's a bearded dragon! \n",
      "Token Probabilities: [0.22831977903842926]\n",
      "Sentence Perplexity for row 83: 4.379822038246133\n",
      "\n",
      "Processing row 84...\n",
      "Reference Text: I don't know yet. Kinda need some time to process this.\n",
      "Output Text:  I am! It will be a lot better. \n",
      "Token Probabilities: [0.10160454362630844]\n",
      "Sentence Perplexity for row 84: 9.842079540044015\n",
      "\n",
      "Processing row 85...\n",
      "Reference Text: It feels so good to update/upgrade, doesn't it? I feel like I have been out of the loop for too long.\n",
      "Output Text:  I am sure you will get it. I hope so! \n",
      "Token Probabilities: [0.03967228904366493]\n",
      "Sentence Perplexity for row 85: 25.206511247671123\n",
      "\n",
      "Processing row 86...\n",
      "Reference Text: Yeah it hurt and I was listening to music so I might have yelled a cuss word loudly.\n",
      "Output Text:  It was really gross. \n",
      "Token Probabilities: [0.19932422041893005]\n",
      "Sentence Perplexity for row 86: 5.016951767819526\n",
      "\n",
      "Processing row 87...\n",
      "Reference Text: I cannot imagine anyone wanting to drink that without losing a bet\n",
      "Output Text:  I know right \n",
      "Token Probabilities: [0.04438846930861473]\n",
      "Sentence Perplexity for row 87: 22.52837314680559\n",
      "\n",
      "Processing row 88...\n",
      "Reference Text: Im taking your advice and putting it into practice tomorrow!\n",
      "Output Text:  I am a parent. They are great at the same time. \n",
      "Token Probabilities: [0.21213260293006897]\n",
      "Sentence Perplexity for row 88: 4.7140325729640775\n",
      "\n",
      "Processing row 89...\n",
      "Reference Text: Thank you, the bracelet means a lot to me\n",
      "Output Text:  I was so mad at the police. I was so mad at the store \n",
      "Token Probabilities: [0.0060829175636172295]\n",
      "Sentence Perplexity for row 89: 164.3947973224457\n",
      "\n",
      "Processing row 90...\n",
      "Reference Text: How terrible! I'm so sorry that happened. How long ago was it?\n",
      "Output Text:  I'm sorry to hear that. What was it for? \n",
      "Token Probabilities: [0.03773447126150131]\n",
      "Sentence Perplexity for row 90: 26.50096759193901\n",
      "\n",
      "Processing row 91...\n",
      "Reference Text: That's awesome! It really pays not to burn bridges, you never know when someone from your past can help you out like that.\n",
      "Output Text:  Thats awesome! I hope you have a good job! \n",
      "Token Probabilities: [0.0049393270164728165]\n",
      "Sentence Perplexity for row 91: 202.45673077829582\n",
      "\n",
      "Processing row 92...\n",
      "Reference Text: What did you eat?\n",
      "Output Text:  Did you get a good friend? \n",
      "Token Probabilities: [0.04495396092534065]\n",
      "Sentence Perplexity for row 92: 22.244980851871894\n",
      "\n",
      "Processing row 93...\n",
      "Reference Text: wow good for you man\n",
      "Output Text:  I hope you won't be able to play it all. \n",
      "Token Probabilities: [0.1704902946949005]\n",
      "Sentence Perplexity for row 93: 5.865436515254676\n",
      "\n",
      "Processing row 94...\n",
      "Reference Text: Investigate that right now! You need to know\n",
      "Output Text:  Oh, why did you do that? \n",
      "Token Probabilities: [4.772001921082847e-05]\n",
      "Sentence Perplexity for row 94: 20955.56574656793\n",
      "\n",
      "Processing row 95...\n",
      "Reference Text: That's really special, and a great attitude to have\n",
      "Output Text:  I would be too. It's so funny \n",
      "Token Probabilities: [0.007357509341090918]\n",
      "Sentence Perplexity for row 95: 135.9155596874481\n",
      "\n",
      "Processing row 96...\n",
      "Reference Text: I've never watched a single full star wars movie, just bits and pieces haha\n",
      "Output Text:  I love the show, I love the show. \n",
      "Token Probabilities: [0.15569953620433807]\n",
      "Sentence Perplexity for row 96: 6.422626710253092\n",
      "\n",
      "Processing row 97...\n",
      "Reference Text: Me too! It seems like such a huge accomplishment at the time, doesn't it?\n",
      "Output Text:  That's great! I bet you will have a great time! \n",
      "Token Probabilities: [0.004975620191544294]\n",
      "Sentence Perplexity for row 97: 200.97997063751512\n",
      "\n",
      "Processing row 98...\n",
      "Reference Text: That's great! good luck\n",
      "Output Text:  I bet you are so excited! \n",
      "Token Probabilities: [0.13471364974975586]\n",
      "Sentence Perplexity for row 98: 7.423152752951172\n",
      "\n",
      "Processing row 99...\n",
      "Reference Text: No not at all. I just got up and couldnt stop laughing at myself. I could feel the heat coming off of my face.\n",
      "Output Text:  I was just so upset. \n",
      "Token Probabilities: [0.24736034870147705]\n",
      "Sentence Perplexity for row 99: 4.042685116064557\n",
      "Completed token-based perplexity calculations for column: new_label_withoutemotion_single\n",
      "Average Perplexity for withoutemotion_single: 1061.468651178604\n",
      "new_label_withoutemotion_whole\n",
      "Calculating token-based perplexity for column: new_label_withoutemotion_whole\n",
      "\n",
      "Processing row 0...\n",
      "Reference Text: Should have grabbed the gun.\n",
      "Output Text:  He is, he is so old now. He is a very close friend. \n",
      "Token Probabilities: [0.088869608938694]\n",
      "Sentence Perplexity for row 0: 11.252440648071738\n",
      "\n",
      "Processing row 1...\n",
      "Reference Text: Thank you!  It was so nice, I had no idea it was happening.  They're not usually so good with secrets haha\n",
      "Output Text:  Thank you. I am happy with your friend. \n",
      "Token Probabilities: [0.002240304369479418]\n",
      "Sentence Perplexity for row 1: 446.3679192985598\n",
      "\n",
      "Processing row 2...\n",
      "Reference Text: I do!  I'm feeling very optimistic about it\n",
      "Output Text:  Yes, I am so proud of him, I have a lot of faith in my life. \n",
      "Token Probabilities: [0.0007972741150297225]\n",
      "Sentence Perplexity for row 2: 1254.2737574801606\n",
      "\n",
      "Processing row 3...\n",
      "Reference Text: It was a medium amount of money but still, he did me so dirty.\n",
      "Output Text:  Yes, I was so shocked. I was so excited to see him. \n",
      "Token Probabilities: [0.00088603695621714]\n",
      "Sentence Perplexity for row 3: 1128.6210952976674\n",
      "\n",
      "Processing row 4...\n",
      "Reference Text: Well, I started walking much faster. It looked like they were carrying a weapon or something.\n",
      "Output Text:  I hope so. I'm a little bummed out. \n",
      "Token Probabilities: [0.2659761607646942]\n",
      "Sentence Perplexity for row 4: 3.7597354481881085\n",
      "\n",
      "Processing row 5...\n",
      "Reference Text: I had braces growing up too, the worst part for me was the molding!\n",
      "Output Text:  Not really, but I do not know what to do. \n",
      "Token Probabilities: [0.008880178444087505]\n",
      "Sentence Perplexity for row 5: 112.61034970145312\n",
      "\n",
      "Processing row 6...\n",
      "Reference Text: Yes, and it really sucks if you forget something important.\n",
      "Output Text:  I think it's going to be a good time. \n",
      "Token Probabilities: [0.2060546725988388]\n",
      "Sentence Perplexity for row 6: 4.853080919678379\n",
      "\n",
      "Processing row 7...\n",
      "Reference Text: O no! That's a terrible thing to have happen or see.\n",
      "Output Text:  I know. I was so upset that it was a good thing to do. \n",
      "Token Probabilities: [0.1376388818025589]\n",
      "Sentence Perplexity for row 7: 7.265388870526327\n",
      "\n",
      "Processing row 8...\n",
      "Reference Text: Wow, that is so disgusting.\n",
      "Output Text:  It was a good story. I was so upset. \n",
      "Token Probabilities: [0.04624336212873459]\n",
      "Sentence Perplexity for row 8: 21.62472523550839\n",
      "\n",
      "Processing row 9...\n",
      "Reference Text: Wow.Really? What kind?\n",
      "Output Text: \n",
      "Error fetching token probabilities: backend='inductor' raised:\n",
      "LoweringException: IndexError: index is out of bounds for dimension with size 0\n",
      "  target: aten.index.Tensor\n",
      "  args[0]: TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.float32,\n",
      "      def inner_fn(index):\n",
      "          _, i1, i2 = index\n",
      "          tmp0 = ops.constant(nan, torch.float32)\n",
      "          tmp1 = ops.load(primals_28, i2)\n",
      "          tmp2 = tmp0 * tmp1\n",
      "          return tmp2\n",
      "      ,\n",
      "      ranges=[1, 0, 64],\n",
      "      origin_node=mul_37,\n",
      "      origins=OrderedSet([mul_37, add_18, add_15, add, add_3, add_2...\n",
      "    )\n",
      "  ))\n",
      "  args[1]: [None, TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.int64,\n",
      "      def inner_fn(index):\n",
      "          _ = index\n",
      "          tmp0 = ops.constant(-1, torch.int64)\n",
      "          return tmp0\n",
      "      ,\n",
      "      ranges=[1],\n",
      "      origin_node=full_default_16,\n",
      "      origins=OrderedSet([full_default_16])\n",
      "    )\n",
      "  ))]\n",
      "\n",
      "Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "\n",
      "\n",
      "You can suppress this exception and fall back to eager by setting:\n",
      "    import torch._dynamo\n",
      "    torch._dynamo.config.suppress_errors = True\n",
      "\n",
      "Token Probabilities: []\n",
      "Sentence Perplexity for row 9: inf\n",
      "\n",
      "Processing row 10...\n",
      "Reference Text: Omg my current dog does that sometimes. She pukes up bile if she doesn't eat, so I always have to make sure she is eating her food.\n",
      "Output Text:  I have no idea, but I was so sad. I was so sad. \n",
      "Token Probabilities: [0.3250620663166046]\n",
      "Sentence Perplexity for row 10: 3.0763355790214475\n",
      "\n",
      "Processing row 11...\n",
      "Reference Text: That's amazing, It's always nice to get on with your family! Have you always got on with them? \n",
      "Output Text:  I was happy to have my mom hang out with her. \n",
      "Token Probabilities: [0.28665047883987427]\n",
      "Sentence Perplexity for row 11: 3.488569089600613\n",
      "\n",
      "Processing row 12...\n",
      "Reference Text: I am not sure as I could not stop because of all the traffic.\n",
      "Output Text:  I hope so. I was very sad and sad. \n",
      "Token Probabilities: [0.26131579279899597]\n",
      "Sentence Perplexity for row 12: 3.8267874638912454\n",
      "\n",
      "Processing row 13...\n",
      "Reference Text: I can barely walk much less imagine that.\n",
      "Output Text:  I am happy for him \n",
      "Token Probabilities: [0.006206199526786804]\n",
      "Sentence Perplexity for row 13: 161.12920567311176\n",
      "\n",
      "Processing row 14...\n",
      "Reference Text: Oh for sure! I love riding jet skis!\n",
      "Output Text:  I have been married for years.  I am going to miss having a lot of people and I do not have a friend with a lot of people to do. \n",
      "Token Probabilities: [0.25823089480400085]\n",
      "Sentence Perplexity for row 14: 3.872503329855273\n",
      "\n",
      "Processing row 15...\n",
      "Reference Text: I feel like this is me. I'm clean, but I'm stuck with a dirty roommate who doesn't do dishes. And I also live in a place that is old and looks terrible to begin with. Sorry you have to deal with that, because I know I hate living in it!\n",
      "Output Text:  I was. I was so scared that he was ok. \n",
      "Token Probabilities: [0.25850141048431396]\n",
      "Sentence Perplexity for row 15: 3.8684508456896047\n",
      "\n",
      "Processing row 16...\n",
      "Reference Text: You can get a adviser\n",
      "Output Text:  I'm going to have a great time. I'm so ready! \n",
      "Token Probabilities: [0.13258828222751617]\n",
      "Sentence Perplexity for row 16: 7.542144623942258\n",
      "\n",
      "Processing row 17...\n",
      "Reference Text: Yeah, Medical emergency. I borrowed $5000. Hope I'll repay this month.\n",
      "Output Text:   I was very happy that he was there.  I was so happy. \n",
      "Token Probabilities: [0.03274264559149742]\n",
      "Sentence Perplexity for row 17: 30.541209542935626\n",
      "\n",
      "Processing row 18...\n",
      "Reference Text: You shouldn't let those kind of people upset you.\n",
      "Output Text:  I'm not sure I'll be able to sleep at home. \n",
      "Token Probabilities: [0.2506730258464813]\n",
      "Sentence Perplexity for row 18: 3.9892604983051747\n",
      "\n",
      "Processing row 19...\n",
      "Reference Text: Oh no! He doesn't seem like such a good friend then. I hate it when friends pull stuff like that!\n",
      "Output Text:  I did, but I still have to give a friend to my friends. I was so mad. \n",
      "Token Probabilities: [0.3061664402484894]\n",
      "Sentence Perplexity for row 19: 3.266197298398821\n",
      "\n",
      "Processing row 20...\n",
      "Reference Text: Ohh you have a really good memory. I am very bad at remembering things, lol.\n",
      "Output Text:  in a 60th grade for a jist of 5 years in the 80's. \n",
      "Token Probabilities: [2.1089272195240483e-06]\n",
      "Sentence Perplexity for row 20: 474174.7324147504\n",
      "\n",
      "Processing row 21...\n",
      "Reference Text: I wish i could make that type of money!\n",
      "Output Text:  I hope so too.  I'm still trying to get a new job. \n",
      "Token Probabilities: [0.29780980944633484]\n",
      "Sentence Perplexity for row 21: 3.3578477547771963\n",
      "\n",
      "Processing row 22...\n",
      "Reference Text: I thought we had a ghost for a long time\n",
      "Output Text:  I was really scared of the movie. But I feel guilty about it. \n",
      "Token Probabilities: [0.20924703776836395]\n",
      "Sentence Perplexity for row 22: 4.779040175025073\n",
      "\n",
      "Processing row 23...\n",
      "Reference Text: this is true.\n",
      "Output Text:  i went to the gym and the other day and my friend made me feel bad, but I feel bad about it. \n",
      "Token Probabilities: [0.005124322604387999]\n",
      "Sentence Perplexity for row 23: 195.14774482459237\n",
      "\n",
      "Processing row 24...\n",
      "Reference Text: I get you, I've been in your situation before\n",
      "Output Text:  It's for work. I'm so sad. \n",
      "Token Probabilities: [0.06545402109622955]\n",
      "Sentence Perplexity for row 24: 15.27790016949172\n",
      "\n",
      "Processing row 25...\n",
      "Reference Text: I see that more in the country I guess. That would be horrifying. But maybe he is just immune to pain?\n",
      "Output Text:  I'm really looking forward to my family. It's going to be a great time, but I'm sure you will do great! \n",
      "Token Probabilities: [0.02406766265630722]\n",
      "Sentence Perplexity for row 25: 41.54952702637861\n",
      "\n",
      "Processing row 26...\n",
      "Reference Text: Can you tell me the name of the book? I find myself being engaged by a lot of novels these days.\n",
      "Output Text:  yea i can't wait to go on vacation \n",
      "Token Probabilities: [1.0803174887996647e-07]\n",
      "Sentence Perplexity for row 26: 9256538.104470521\n",
      "\n",
      "Processing row 27...\n",
      "Reference Text: Wow how exciting, has he been practicing a lot? \n",
      "Output Text:  Cute!!! I'm gonna do well. \n",
      "Token Probabilities: [0.0018710511503741145]\n",
      "Sentence Perplexity for row 27: 534.4589322424731\n",
      "\n",
      "Processing row 28...\n",
      "Reference Text: yea i was very happy he helped me\n",
      "Output Text:  Yea, it is very difficult.  I am so happy for him. \n",
      "Token Probabilities: [8.394835458602756e-05]\n",
      "Sentence Perplexity for row 28: 11912.085769057358\n",
      "\n",
      "Processing row 29...\n",
      "Reference Text: They wer really nice and trustworthy. I even let them use my wifi password.\n",
      "Output Text:  I guess it was a very good idea. I'm going to go back to school. I'm so excited. \n",
      "Token Probabilities: [0.10513084381818771]\n",
      "Sentence Perplexity for row 29: 9.511956374376586\n",
      "\n",
      "Processing row 30...\n",
      "Reference Text: Or it could be you and a dope house party\n",
      "Output Text:  I think it's a good thing.  I'm a cheater and I don't like it until I get a new place.  I have a little bit of a yard for the other day. \n",
      "Token Probabilities: [0.3708251416683197]\n",
      "Sentence Perplexity for row 30: 2.6966887830233435\n",
      "\n",
      "Processing row 31...\n",
      "Reference Text: Yeah it might be a good idea to tell him. But you may want to have the money to give back to him first. \n",
      "Output Text:  I know! I'm just sad that I have to do it all. \n",
      "Token Probabilities: [0.26796209812164307]\n",
      "Sentence Perplexity for row 31: 3.7318710631458174\n",
      "\n",
      "Processing row 32...\n",
      "Reference Text: What did you do with them?\n",
      "Output Text:  I'm really sorry. It's not easy to be in a relationship. \n",
      "Token Probabilities: [0.2265194058418274]\n",
      "Sentence Perplexity for row 32: 4.414632805006887\n",
      "\n",
      "Processing row 33...\n",
      "Reference Text: Congrats!!\n",
      "Output Text:  yeah, i feel very confident and I will do well. \n",
      "Token Probabilities: [4.624917835371889e-07]\n",
      "Sentence Perplexity for row 33: 2162200.5743580735\n",
      "\n",
      "Processing row 34...\n",
      "Reference Text: what was on it\n",
      "Output Text:  It was a big read about 5 pounds.  \n",
      "Token Probabilities: [0.05919264629483223]\n",
      "Sentence Perplexity for row 34: 16.893990429471714\n",
      "\n",
      "Processing row 35...\n",
      "Reference Text: I am so ready for it!\n",
      "Output Text:  it was! I was so mad!  I was so mad! \n",
      "Token Probabilities: [8.126766624627635e-05]\n",
      "Sentence Perplexity for row 35: 12305.016818983891\n",
      "\n",
      "Processing row 36...\n",
      "Reference Text: I am going to be a birthday clown.\n",
      "Output Text:  It's a job, and I'm in college. \n",
      "Token Probabilities: [0.05963677540421486]\n",
      "Sentence Perplexity for row 36: 16.768176904637347\n",
      "\n",
      "Processing row 37...\n",
      "Reference Text: She was 23 years old. I got her when I was 5.\n",
      "Output Text:  She was 13, and I had to take her a few weeks ago. She was a good kid. \n",
      "Token Probabilities: [0.14647382497787476]\n",
      "Sentence Perplexity for row 37: 6.827158368746447\n",
      "\n",
      "Processing row 38...\n",
      "Reference Text: This was a few months ago.\n",
      "Output Text:  It was a huge storm. I was so scared to look at it. \n",
      "Token Probabilities: [0.057722724974155426]\n",
      "Sentence Perplexity for row 38: 17.324199445673027\n",
      "\n",
      "Processing row 39...\n",
      "Reference Text: It's a band called Say Anything, I've been a fan of theirs since 2006! \n",
      "Output Text:  She's going to be a great birthday! \n",
      "Token Probabilities: [0.026224195957183838]\n",
      "Sentence Perplexity for row 39: 38.132722987301385\n",
      "\n",
      "Processing row 40...\n",
      "Reference Text: Oh that's a standard prcedure. Have you ever had one?\n",
      "Output Text: \n",
      "Error fetching token probabilities: backend='inductor' raised:\n",
      "LoweringException: IndexError: index is out of bounds for dimension with size 0\n",
      "  target: aten.index.Tensor\n",
      "  args[0]: TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.float32,\n",
      "      def inner_fn(index):\n",
      "          _, i1, i2 = index\n",
      "          tmp0 = ops.constant(nan, torch.float32)\n",
      "          tmp1 = ops.load(primals_28, i2)\n",
      "          tmp2 = tmp0 * tmp1\n",
      "          return tmp2\n",
      "      ,\n",
      "      ranges=[1, 0, 64],\n",
      "      origin_node=mul_37,\n",
      "      origins=OrderedSet([add_21, sub_12, embedding, add_24, add, a...\n",
      "    )\n",
      "  ))\n",
      "  args[1]: [None, TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.int64,\n",
      "      def inner_fn(index):\n",
      "          _ = index\n",
      "          tmp0 = ops.constant(-1, torch.int64)\n",
      "          return tmp0\n",
      "      ,\n",
      "      ranges=[1],\n",
      "      origin_node=full_default_16,\n",
      "      origins=OrderedSet([full_default_16])\n",
      "    )\n",
      "  ))]\n",
      "\n",
      "Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "\n",
      "\n",
      "You can suppress this exception and fall back to eager by setting:\n",
      "    import torch._dynamo\n",
      "    torch._dynamo.config.suppress_errors = True\n",
      "\n",
      "Token Probabilities: []\n",
      "Sentence Perplexity for row 40: inf\n",
      "\n",
      "Processing row 41...\n",
      "Reference Text: Have you been before? It seems like such a great way to both play and get a workout \n",
      "Output Text: \n",
      "Error fetching token probabilities: backend='inductor' raised:\n",
      "LoweringException: IndexError: index is out of bounds for dimension with size 0\n",
      "  target: aten.index.Tensor\n",
      "  args[0]: TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.float32,\n",
      "      def inner_fn(index):\n",
      "          _, i1, i2 = index\n",
      "          tmp0 = ops.constant(nan, torch.float32)\n",
      "          tmp1 = ops.load(primals_28, i2)\n",
      "          tmp2 = tmp0 * tmp1\n",
      "          return tmp2\n",
      "      ,\n",
      "      ranges=[1, 0, 64],\n",
      "      origin_node=mul_37,\n",
      "      origins=OrderedSet([add_25, mul_36, add_15, add_21, add, embe...\n",
      "    )\n",
      "  ))\n",
      "  args[1]: [None, TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.int64,\n",
      "      def inner_fn(index):\n",
      "          _ = index\n",
      "          tmp0 = ops.constant(-1, torch.int64)\n",
      "          return tmp0\n",
      "      ,\n",
      "      ranges=[1],\n",
      "      origin_node=full_default_16,\n",
      "      origins=OrderedSet([full_default_16])\n",
      "    )\n",
      "  ))]\n",
      "\n",
      "Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "\n",
      "\n",
      "You can suppress this exception and fall back to eager by setting:\n",
      "    import torch._dynamo\n",
      "    torch._dynamo.config.suppress_errors = True\n",
      "\n",
      "Token Probabilities: []\n",
      "Sentence Perplexity for row 41: inf\n",
      "\n",
      "Processing row 42...\n",
      "Reference Text: No, I hate being by myself.\n",
      "Output Text:  I did, it was a good time of work \n",
      "Token Probabilities: [0.008495623245835304]\n",
      "Sentence Perplexity for row 42: 117.70766794422251\n",
      "\n",
      "Processing row 43...\n",
      "Reference Text: I could see that happening but sounds like you were super brave.\n",
      "Output Text: \n",
      "Error fetching token probabilities: backend='inductor' raised:\n",
      "LoweringException: IndexError: index is out of bounds for dimension with size 0\n",
      "  target: aten.index.Tensor\n",
      "  args[0]: TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.float32,\n",
      "      def inner_fn(index):\n",
      "          _, i1, i2 = index\n",
      "          tmp0 = ops.constant(nan, torch.float32)\n",
      "          tmp1 = ops.load(primals_28, i2)\n",
      "          tmp2 = tmp0 * tmp1\n",
      "          return tmp2\n",
      "      ,\n",
      "      ranges=[1, 0, 64],\n",
      "      origin_node=mul_37,\n",
      "      origins=OrderedSet([rsqrt_8, add_21, add_9, add_12, sub_12, e...\n",
      "    )\n",
      "  ))\n",
      "  args[1]: [None, TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.int64,\n",
      "      def inner_fn(index):\n",
      "          _ = index\n",
      "          tmp0 = ops.constant(-1, torch.int64)\n",
      "          return tmp0\n",
      "      ,\n",
      "      ranges=[1],\n",
      "      origin_node=full_default_16,\n",
      "      origins=OrderedSet([full_default_16])\n",
      "    )\n",
      "  ))]\n",
      "\n",
      "Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "\n",
      "\n",
      "You can suppress this exception and fall back to eager by setting:\n",
      "    import torch._dynamo\n",
      "    torch._dynamo.config.suppress_errors = True\n",
      "\n",
      "Token Probabilities: []\n",
      "Sentence Perplexity for row 43: inf\n",
      "\n",
      "Processing row 44...\n",
      "Reference Text: He's quite the piece of garbage.\n",
      "Output Text:  yes, i hope so. \n",
      "Token Probabilities: [6.03377447987441e-05]\n",
      "Sentence Perplexity for row 44: 16573.373819911394\n",
      "\n",
      "Processing row 45...\n",
      "Reference Text: Tell me about it. How long have you been job hunting for?\n",
      "Output Text:  I know, I have been so frustrated at my job for the past couple of days. I hope I'm not in a hurry. \n",
      "Token Probabilities: [0.05274473875761032]\n",
      "Sentence Perplexity for row 45: 18.959236950542568\n",
      "\n",
      "Processing row 46...\n",
      "Reference Text: That is such a beautiful memory to have. I love that we forever have moments like this... How cool Hong Kong! \n",
      "Output Text:  Yes, I think it is. I'm so proud of him. \n",
      "Token Probabilities: [0.00047212152276188135]\n",
      "Sentence Perplexity for row 46: 2118.0987347284295\n",
      "\n",
      "Processing row 47...\n",
      "Reference Text: I think he was slightly over the limit but he had a few drinks earlier, so I felt a bit uncomfortable.\n",
      "Output Text:  I was. I was so mad. \n",
      "Token Probabilities: [0.4406950771808624]\n",
      "Sentence Perplexity for row 47: 2.26914266071912\n",
      "\n",
      "Processing row 48...\n",
      "Reference Text: IT is. \n",
      "Output Text:  i love to be the perfect time \n",
      "Token Probabilities: [0.005574813112616539]\n",
      "Sentence Perplexity for row 48: 179.378210497652\n",
      "\n",
      "Processing row 49...\n",
      "Reference Text: OH that sucks.\n",
      "Output Text:  I am so nervous to get a new job.  I have to work. \n",
      "Token Probabilities: [0.38070976734161377]\n",
      "Sentence Perplexity for row 49: 2.6266728247680926\n",
      "\n",
      "Processing row 50...\n",
      "Reference Text: thats wonderful\n",
      "Output Text:  I have three years.  I am so happy for you! \n",
      "Token Probabilities: [0.20060767233371735]\n",
      "Sentence Perplexity for row 50: 4.984854210044707\n",
      "\n",
      "Processing row 51...\n",
      "Reference Text: I've had that feeling as well, especially if it is with someone that is close to me.  Is it because you dont like confrontation or a different reason?\n",
      "Output Text:  I feel the same way. It's hard to be with my friends. \n",
      "Token Probabilities: [0.2756189703941345]\n",
      "Sentence Perplexity for row 51: 3.6281972847152075\n",
      "\n",
      "Processing row 52...\n",
      "Reference Text: No they did not. And it is going to cost too much to take them to court. \n",
      "Output Text:  I hope they can get it off.  \n",
      "Token Probabilities: [0.2729932367801666]\n",
      "Sentence Perplexity for row 52: 3.663094411402105\n",
      "\n",
      "Processing row 53...\n",
      "Reference Text: thats good!\n",
      "Output Text:  It was so nice \n",
      "Token Probabilities: [0.0002539964916650206]\n",
      "Sentence Perplexity for row 53: 3937.0622540678014\n",
      "\n",
      "Processing row 54...\n",
      "Reference Text: That is so true! \n",
      "Output Text:  I hope so too. \n",
      "Token Probabilities: [0.3212004601955414]\n",
      "Sentence Perplexity for row 54: 3.113320570559634\n",
      "\n",
      "Processing row 55...\n",
      "Reference Text: I sort of have. I worked like crazy to get a work visa for the US, so I could be with the person I wanted to spend my life with. It paid off, so I can kind of understand what you're saying.\n",
      "Output Text:  I don't want to be the same way. I'm not sure if I'm going to try it. \n",
      "Token Probabilities: [0.2273433953523636]\n",
      "Sentence Perplexity for row 55: 4.398632291252984\n",
      "\n",
      "Processing row 56...\n",
      "Reference Text: It sounds like you did great. Studying is the biggest part really.\n",
      "Output Text:  Yeah, I was so happy for him. I was so happy to see him. \n",
      "Token Probabilities: [0.0003278955991845578]\n",
      "Sentence Perplexity for row 56: 3049.751208881414\n",
      "\n",
      "Processing row 57...\n",
      "Reference Text: Don't tell her right after she awakes up. Women are never in the best mood right after waking up.\n",
      "Output Text:  Yes, I am fine now. I am so sad. \n",
      "Token Probabilities: [0.0003318415838293731]\n",
      "Sentence Perplexity for row 57: 3013.4860991809323\n",
      "\n",
      "Processing row 58...\n",
      "Reference Text: Maybe.\n",
      "Output Text:  Yeah, I'm not sure, but I'm not sure what I will do. \n",
      "Token Probabilities: [0.00019162625540047884]\n",
      "Sentence Perplexity for row 58: 5218.4915783596825\n",
      "\n",
      "Processing row 59...\n",
      "Reference Text: They thought it was a better school, and it probably was, but I didn't feel like it was at the time\n",
      "Output Text:  I am so proud of him! \n",
      "Token Probabilities: [0.24721497297286987]\n",
      "Sentence Perplexity for row 59: 4.045062432807187\n",
      "\n",
      "Processing row 60...\n",
      "Reference Text: That's great. I hope you have a wonderful time.\n",
      "Output Text:  I hope so too! I'm really excited for it! \n",
      "Token Probabilities: [0.14334866404533386]\n",
      "Sentence Perplexity for row 60: 6.975998044067932\n",
      "\n",
      "Processing row 61...\n",
      "Reference Text: That is bad. What are you planning to do instead?\n",
      "Output Text: \n",
      "Error fetching token probabilities: backend='inductor' raised:\n",
      "LoweringException: IndexError: index is out of bounds for dimension with size 0\n",
      "  target: aten.index.Tensor\n",
      "  args[0]: TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.float32,\n",
      "      def inner_fn(index):\n",
      "          _, i1, i2 = index\n",
      "          tmp0 = ops.constant(nan, torch.float32)\n",
      "          tmp1 = ops.load(primals_28, i2)\n",
      "          tmp2 = tmp0 * tmp1\n",
      "          return tmp2\n",
      "      ,\n",
      "      ranges=[1, 0, 64],\n",
      "      origin_node=mul_37,\n",
      "      origins=OrderedSet([sub_12, embedding_1, add_6, add_12, rsqrt...\n",
      "    )\n",
      "  ))\n",
      "  args[1]: [None, TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.int64,\n",
      "      def inner_fn(index):\n",
      "          _ = index\n",
      "          tmp0 = ops.constant(-1, torch.int64)\n",
      "          return tmp0\n",
      "      ,\n",
      "      ranges=[1],\n",
      "      origin_node=full_default_16,\n",
      "      origins=OrderedSet([full_default_16])\n",
      "    )\n",
      "  ))]\n",
      "\n",
      "Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "\n",
      "\n",
      "You can suppress this exception and fall back to eager by setting:\n",
      "    import torch._dynamo\n",
      "    torch._dynamo.config.suppress_errors = True\n",
      "\n",
      "Token Probabilities: []\n",
      "Sentence Perplexity for row 61: inf\n",
      "\n",
      "Processing row 62...\n",
      "Reference Text: A little bit bu, they took the insurance money and bought a big house - i mean BIG! I know they needed more room for my mother to move in, but what they bought was way over and above what was needed.\n",
      "Output Text:  She's a great girl \n",
      "Token Probabilities: [0.0009935094276443124]\n",
      "Sentence Perplexity for row 62: 1006.5329751032933\n",
      "\n",
      "Processing row 63...\n",
      "Reference Text: Mostly happy. They have annoyed me greatly all summer\n",
      "Output Text:  I am a kid, but I am so sad right now. \n",
      "Token Probabilities: [0.2749289572238922]\n",
      "Sentence Perplexity for row 63: 3.637303287720384\n",
      "\n",
      "Processing row 64...\n",
      "Reference Text: That is really interesting. Still over my head, but you did a decent job of explaining it in layman's terms. I appreciate it. So are you a med student, or what?\n",
      "Output Text:  It was a very important wreck than a couple of other than I had to go. I was so upset. \n",
      "Token Probabilities: [0.06865284591913223]\n",
      "Sentence Perplexity for row 64: 14.56603854671841\n",
      "\n",
      "Processing row 65...\n",
      "Reference Text: Oh wow! Congratulations! I also recently applied for grad school to study Computer Science (seriously). What are you wanting to study?\n",
      "Output Text:  I am very ready to go \n",
      "Token Probabilities: [0.003347694640979171]\n",
      "Sentence Perplexity for row 65: 298.7130270960164\n",
      "\n",
      "Processing row 66...\n",
      "Reference Text: I'm sure that much be hard to stand by and watch as someone who works hard for their things. \n",
      "Output Text:  I hope so.  I am so sad that I can't wait. \n",
      "Token Probabilities: [0.37868648767471313]\n",
      "Sentence Perplexity for row 66: 2.640706844705236\n",
      "\n",
      "Processing row 67...\n",
      "Reference Text: It does get better, but it was just so sudden.\n",
      "Output Text:  I hope so too!  I am really nervous about it! \n",
      "Token Probabilities: [0.23738208413124084]\n",
      "Sentence Perplexity for row 67: 4.212617829436246\n",
      "\n",
      "Processing row 68...\n",
      "Reference Text: True, driving takes more focus than a lot of people can handle\n",
      "Output Text:  I hope I can do it. I hope I do do well. \n",
      "Token Probabilities: [0.021671060472726822]\n",
      "Sentence Perplexity for row 68: 46.14448846462807\n",
      "\n",
      "Processing row 69...\n",
      "Reference Text: I have no idea. We found it after she left. It was really gross. I wonder if her house is that nasty?\n",
      "Output Text:  I was so mad. I was so mad! \n",
      "Token Probabilities: [0.2810589075088501]\n",
      "Sentence Perplexity for row 69: 3.5579729846082593\n",
      "\n",
      "Processing row 70...\n",
      "Reference Text: That's good, it sounds like his bathroom motivated you to take yours to the next level. That's probably good for society.\n",
      "Output Text:  Yeah, I'm so sorry to hear that. I am sure you had a good time. \n",
      "Token Probabilities: [0.00035454268800094724]\n",
      "Sentence Perplexity for row 70: 2820.534829355524\n",
      "\n",
      "Processing row 71...\n",
      "Reference Text: I do look a little like a somewhat taller version of him.\n",
      "Output Text:  I'm not sure I will be able to get the book. \n",
      "Token Probabilities: [0.3024193346500397]\n",
      "Sentence Perplexity for row 71: 3.3066668874104965\n",
      "\n",
      "Processing row 72...\n",
      "Reference Text: Absolutely! Not to mention gardening saves a ton of money in the long run.\n",
      "Output Text:  I hope so too!  I have a good feeling.  I have to be so nervous to do that! \n",
      "Token Probabilities: [0.2660941779613495]\n",
      "Sentence Perplexity for row 72: 3.758067942941808\n",
      "\n",
      "Processing row 73...\n",
      "Reference Text: That's great! Not too many 16 year olds are that responsible.\n",
      "Output Text:  Yea, I am so happy for him too. \n",
      "Token Probabilities: [5.694824722013436e-05]\n",
      "Sentence Perplexity for row 73: 17559.802958192624\n",
      "\n",
      "Processing row 74...\n",
      "Reference Text: The prices have risen alot with all the technology and electrical components.\n",
      "Output Text:  I know, I just wish they would be a good idea.  I'm sure they are a great friend.  I'm sure they are proud of you. \n",
      "Token Probabilities: [0.14411982893943787]\n",
      "Sentence Perplexity for row 74: 6.938670461649108\n",
      "\n",
      "Processing row 75...\n",
      "Reference Text: Does he get anything else?\n",
      "Output Text:  Yes, I am a little excited about it. \n",
      "Token Probabilities: [0.0002991972432937473]\n",
      "Sentence Perplexity for row 75: 3342.276783674157\n",
      "\n",
      "Processing row 76...\n",
      "Reference Text: Sounds like you have a very responsible young lady growing up.\n",
      "Output Text: \n",
      "Error fetching token probabilities: backend='inductor' raised:\n",
      "LoweringException: IndexError: index is out of bounds for dimension with size 0\n",
      "  target: aten.index.Tensor\n",
      "  args[0]: TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.float32,\n",
      "      def inner_fn(index):\n",
      "          _, i1, i2 = index\n",
      "          tmp0 = ops.constant(nan, torch.float32)\n",
      "          tmp1 = ops.load(primals_28, i2)\n",
      "          tmp2 = tmp0 * tmp1\n",
      "          return tmp2\n",
      "      ,\n",
      "      ranges=[1, 0, 64],\n",
      "      origin_node=mul_37,\n",
      "      origins=OrderedSet([add_12, embedding, add_24, add_15, add_18...\n",
      "    )\n",
      "  ))\n",
      "  args[1]: [None, TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.int64,\n",
      "      def inner_fn(index):\n",
      "          _ = index\n",
      "          tmp0 = ops.constant(-1, torch.int64)\n",
      "          return tmp0\n",
      "      ,\n",
      "      ranges=[1],\n",
      "      origin_node=full_default_16,\n",
      "      origins=OrderedSet([full_default_16])\n",
      "    )\n",
      "  ))]\n",
      "\n",
      "Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "\n",
      "\n",
      "You can suppress this exception and fall back to eager by setting:\n",
      "    import torch._dynamo\n",
      "    torch._dynamo.config.suppress_errors = True\n",
      "\n",
      "Token Probabilities: []\n",
      "Sentence Perplexity for row 76: inf\n",
      "\n",
      "Processing row 77...\n",
      "Reference Text: ah you used her. You should have filled. But however she will understand\n",
      "Output Text: \n",
      "Error fetching token probabilities: backend='inductor' raised:\n",
      "LoweringException: IndexError: index is out of bounds for dimension with size 0\n",
      "  target: aten.index.Tensor\n",
      "  args[0]: TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.float32,\n",
      "      def inner_fn(index):\n",
      "          _, i1, i2 = index\n",
      "          tmp0 = ops.constant(nan, torch.float32)\n",
      "          tmp1 = ops.load(primals_28, i2)\n",
      "          tmp2 = tmp0 * tmp1\n",
      "          return tmp2\n",
      "      ,\n",
      "      ranges=[1, 0, 64],\n",
      "      origin_node=mul_37,\n",
      "      origins=OrderedSet([var_mean_8, embedding_1, mul_37, add_18, ...\n",
      "    )\n",
      "  ))\n",
      "  args[1]: [None, TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.int64,\n",
      "      def inner_fn(index):\n",
      "          _ = index\n",
      "          tmp0 = ops.constant(-1, torch.int64)\n",
      "          return tmp0\n",
      "      ,\n",
      "      ranges=[1],\n",
      "      origin_node=full_default_16,\n",
      "      origins=OrderedSet([full_default_16])\n",
      "    )\n",
      "  ))]\n",
      "\n",
      "Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "\n",
      "\n",
      "You can suppress this exception and fall back to eager by setting:\n",
      "    import torch._dynamo\n",
      "    torch._dynamo.config.suppress_errors = True\n",
      "\n",
      "Token Probabilities: []\n",
      "Sentence Perplexity for row 77: inf\n",
      "\n",
      "Processing row 78...\n",
      "Reference Text: I gave him some Tylenol, and we ended up snuggling til he could go back to sleep.  \n",
      "Output Text:  I know.  I'm so proud of him. \n",
      "Token Probabilities: [0.3140047490596771]\n",
      "Sentence Perplexity for row 78: 3.1846652096651837\n",
      "\n",
      "Processing row 79...\n",
      "Reference Text: It was a hand written note from my dead mother. I never had read or seen it before. \n",
      "Output Text:  It was a big deal. I was so scared! \n",
      "Token Probabilities: [0.07005903869867325]\n",
      "Sentence Perplexity for row 79: 14.273675725141484\n",
      "\n",
      "Processing row 80...\n",
      "Reference Text: Ouch, I hope you don't either. I'd keep any eye out at work from now on.\n",
      "Output Text:  nothing wrong. i was just looking forward to it \n",
      "Token Probabilities: [1.1241377251280937e-06]\n",
      "Sentence Perplexity for row 80: 889570.7150883597\n",
      "\n",
      "Processing row 81...\n",
      "Reference Text: I hope both our ego and your nose heal up quickly!\n",
      "Output Text:  I hope so too! \n",
      "Token Probabilities: [0.2369755506515503]\n",
      "Sentence Perplexity for row 81: 4.219844609498993\n",
      "\n",
      "Processing row 82...\n",
      "Reference Text: Yeah I would go off with my friends and have adventures. I miss that so much.\n",
      "Output Text:  I hope so.  I have to think about my family. \n",
      "Token Probabilities: [0.3070325553417206]\n",
      "Sentence Perplexity for row 82: 3.256983608422311\n",
      "\n",
      "Processing row 83...\n",
      "Reference Text: a bearded dragon\n",
      "Output Text:  It's a bearded dragon \n",
      "Token Probabilities: [0.00544239254668355]\n",
      "Sentence Perplexity for row 83: 183.7427181928238\n",
      "\n",
      "Processing row 84...\n",
      "Reference Text: I don't know yet. Kinda need some time to process this.\n",
      "Output Text:  I'm not sure if she'll be a good girl! \n",
      "Token Probabilities: [0.29474493861198425]\n",
      "Sentence Perplexity for row 84: 3.392763942645495\n",
      "\n",
      "Processing row 85...\n",
      "Reference Text: It feels so good to update/upgrade, doesn't it? I feel like I have been out of the loop for too long.\n",
      "Output Text:  I think I will! \n",
      "Token Probabilities: [0.1997113674879074]\n",
      "Sentence Perplexity for row 85: 5.007226241443418\n",
      "\n",
      "Processing row 86...\n",
      "Reference Text: Yeah it hurt and I was listening to music so I might have yelled a cuss word loudly.\n",
      "Output Text:  I was too shocked. I was so excited to see how it took me. \n",
      "Token Probabilities: [0.14537963271141052]\n",
      "Sentence Perplexity for row 86: 6.878542622164103\n",
      "\n",
      "Processing row 87...\n",
      "Reference Text: I cannot imagine anyone wanting to drink that without losing a bet\n",
      "Output Text:  I feel so guilty for a week. \n",
      "Token Probabilities: [0.40533849596977234]\n",
      "Sentence Perplexity for row 87: 2.4670738406119064\n",
      "\n",
      "Processing row 88...\n",
      "Reference Text: Im taking your advice and putting it into practice tomorrow!\n",
      "Output Text:  They are so true. They are really good to have a good family. \n",
      "Token Probabilities: [0.028651772066950798]\n",
      "Sentence Perplexity for row 88: 34.901855203346344\n",
      "\n",
      "Processing row 89...\n",
      "Reference Text: Thank you, the bracelet means a lot to me\n",
      "Output Text:  I know, but I'm sure you will do well on the weekends. \n",
      "Token Probabilities: [0.10921242833137512]\n",
      "Sentence Perplexity for row 89: 9.156467036570001\n",
      "\n",
      "Processing row 90...\n",
      "Reference Text: How terrible! I'm so sorry that happened. How long ago was it?\n",
      "Output Text:  I hope so too!  I will do well! \n",
      "Token Probabilities: [0.11005549132823944]\n",
      "Sentence Perplexity for row 90: 9.086325343071795\n",
      "\n",
      "Processing row 91...\n",
      "Reference Text: That's awesome! It really pays not to burn bridges, you never know when someone from your past can help you out like that.\n",
      "Output Text:  Yeah, I am sure she will do well if she won't get it. \n",
      "Token Probabilities: [0.0007607959560118616]\n",
      "Sentence Perplexity for row 91: 1314.4128752235497\n",
      "\n",
      "Processing row 92...\n",
      "Reference Text: What did you eat?\n",
      "Output Text: \n",
      "Error fetching token probabilities: backend='inductor' raised:\n",
      "LoweringException: IndexError: index is out of bounds for dimension with size 0\n",
      "  target: aten.index.Tensor\n",
      "  args[0]: TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.float32,\n",
      "      def inner_fn(index):\n",
      "          _, i1, i2 = index\n",
      "          tmp0 = ops.constant(nan, torch.float32)\n",
      "          tmp1 = ops.load(primals_28, i2)\n",
      "          tmp2 = tmp0 * tmp1\n",
      "          return tmp2\n",
      "      ,\n",
      "      ranges=[1, 0, 64],\n",
      "      origin_node=mul_37,\n",
      "      origins=OrderedSet([add_6, add_3, add_25, add_21, add_24, rsq...\n",
      "    )\n",
      "  ))\n",
      "  args[1]: [None, TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.int64,\n",
      "      def inner_fn(index):\n",
      "          _ = index\n",
      "          tmp0 = ops.constant(-1, torch.int64)\n",
      "          return tmp0\n",
      "      ,\n",
      "      ranges=[1],\n",
      "      origin_node=full_default_16,\n",
      "      origins=OrderedSet([full_default_16])\n",
      "    )\n",
      "  ))]\n",
      "\n",
      "Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "\n",
      "\n",
      "You can suppress this exception and fall back to eager by setting:\n",
      "    import torch._dynamo\n",
      "    torch._dynamo.config.suppress_errors = True\n",
      "\n",
      "Token Probabilities: []\n",
      "Sentence Perplexity for row 92: inf\n",
      "\n",
      "Processing row 93...\n",
      "Reference Text: wow good for you man\n",
      "Output Text:  I'm going to go to crush it! \n",
      "Token Probabilities: [0.23060519993305206]\n",
      "Sentence Perplexity for row 93: 4.336415658841665\n",
      "\n",
      "Processing row 94...\n",
      "Reference Text: Investigate that right now! You need to know\n",
      "Output Text: \n",
      "Error fetching token probabilities: backend='inductor' raised:\n",
      "LoweringException: IndexError: index is out of bounds for dimension with size 0\n",
      "  target: aten.index.Tensor\n",
      "  args[0]: TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.float32,\n",
      "      def inner_fn(index):\n",
      "          _, i1, i2 = index\n",
      "          tmp0 = ops.constant(nan, torch.float32)\n",
      "          tmp1 = ops.load(primals_28, i2)\n",
      "          tmp2 = tmp0 * tmp1\n",
      "          return tmp2\n",
      "      ,\n",
      "      ranges=[1, 0, 64],\n",
      "      origin_node=mul_37,\n",
      "      origins=OrderedSet([add_3, add_9, add_18, mul_37, add_25, add...\n",
      "    )\n",
      "  ))\n",
      "  args[1]: [None, TensorBox(StorageBox(\n",
      "    Pointwise(\n",
      "      'cpu',\n",
      "      torch.int64,\n",
      "      def inner_fn(index):\n",
      "          _ = index\n",
      "          tmp0 = ops.constant(-1, torch.int64)\n",
      "          return tmp0\n",
      "      ,\n",
      "      ranges=[1],\n",
      "      origin_node=full_default_16,\n",
      "      origins=OrderedSet([full_default_16])\n",
      "    )\n",
      "  ))]\n",
      "\n",
      "Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "\n",
      "\n",
      "You can suppress this exception and fall back to eager by setting:\n",
      "    import torch._dynamo\n",
      "    torch._dynamo.config.suppress_errors = True\n",
      "\n",
      "Token Probabilities: []\n",
      "Sentence Perplexity for row 94: inf\n",
      "\n",
      "Processing row 95...\n",
      "Reference Text: That's really special, and a great attitude to have\n",
      "Output Text:  Yes! He's been in a couple years. He's a great driver. \n",
      "Token Probabilities: [0.0009574758587405086]\n",
      "Sentence Perplexity for row 95: 1044.4127555502328\n",
      "\n",
      "Processing row 96...\n",
      "Reference Text: I've never watched a single full star wars movie, just bits and pieces haha\n",
      "Output Text:  I love roller coasters.  I love roller coasters. \n",
      "Token Probabilities: [0.33166879415512085]\n",
      "Sentence Perplexity for row 96: 3.0150560366927435\n",
      "\n",
      "Processing row 97...\n",
      "Reference Text: Me too! It seems like such a huge accomplishment at the time, doesn't it?\n",
      "Output Text:  I'm in college. It is my first child, so I am happy for her. \n",
      "Token Probabilities: [0.11096354573965073]\n",
      "Sentence Perplexity for row 97: 9.011968690566716\n",
      "\n",
      "Processing row 98...\n",
      "Reference Text: That's great! good luck\n",
      "Output Text:  I'm going to be very exciting! \n",
      "Token Probabilities: [0.34798622131347656]\n",
      "Sentence Perplexity for row 98: 2.873676998547508\n",
      "\n",
      "Processing row 99...\n",
      "Reference Text: No not at all. I just got up and couldnt stop laughing at myself. I could feel the heat coming off of my face.\n",
      "Output Text:  I did, I had a really bad experience.  I just felt like I was going to have to go to work. \n",
      "Token Probabilities: [0.3736211359500885]\n",
      "Sentence Perplexity for row 99: 2.6765081088281595\n",
      "Completed token-based perplexity calculations for column: new_label_withoutemotion_whole\n",
      "Average Perplexity for withoutemotion_whole: inf\n",
      "new_label_withemotion\n",
      "Calculating token-based perplexity for column: new_label_withemotion\n",
      "\n",
      "Processing row 0...\n",
      "Reference Text: Should have grabbed the gun.\n",
      "Output Text:  I'm sorry to hear that. I'm sure you'll get it! \n",
      "Token Probabilities: [0.002270638942718506]\n",
      "Sentence Perplexity for row 0: 440.4046725292034\n",
      "\n",
      "Processing row 1...\n",
      "Reference Text: Thank you!  It was so nice, I had no idea it was happening.  They're not usually so good with secrets haha\n",
      "Output Text:  Yeah I was so happy for them. I was so glad I was able to get it, it was a good time. \n",
      "Token Probabilities: [0.0005198946455493569]\n",
      "Sentence Perplexity for row 1: 1923.4666264803132\n",
      "\n",
      "Processing row 2...\n",
      "Reference Text: I do!  I'm feeling very optimistic about it\n",
      "Output Text:  I do, it's a lot better than I am. I'm not sure if I can get it. \n",
      "Token Probabilities: [0.08130446821451187]\n",
      "Sentence Perplexity for row 2: 12.299447028687558\n",
      "\n",
      "Processing row 3...\n",
      "Reference Text: It was a medium amount of money but still, he did me so dirty.\n",
      "Output Text:  Not really, but I didn't know what to do though. \n",
      "Token Probabilities: [0.004328303970396519]\n",
      "Sentence Perplexity for row 3: 231.03737788277124\n",
      "\n",
      "Processing row 4...\n",
      "Reference Text: Well, I started walking much faster. It looked like they were carrying a weapon or something.\n",
      "Output Text:  I went to the hospital to go to a new city and get a new friend. \n",
      "Token Probabilities: [0.41777586936950684]\n",
      "Sentence Perplexity for row 4: 2.393627955365555\n",
      "\n",
      "Processing row 5...\n",
      "Reference Text: I had braces growing up too, the worst part for me was the molding!\n",
      "Output Text:  I know right! It is a little bit, but I'm not sure it will be better than the place. \n",
      "Token Probabilities: [0.05942491441965103]\n",
      "Sentence Perplexity for row 5: 16.827958605680607\n",
      "\n",
      "Processing row 6...\n",
      "Reference Text: Yes, and it really sucks if you forget something important.\n",
      "Output Text:  I'm sure that you will do well. \n",
      "Token Probabilities: [0.05554470792412758]\n",
      "Sentence Perplexity for row 6: 18.00351531897459\n",
      "\n",
      "Processing row 7...\n",
      "Reference Text: O no! That's a terrible thing to have happen or see.\n",
      "Output Text:  That's terrible, I'm sorry to hear that. \n",
      "Token Probabilities: [0.007385349832475185]\n",
      "Sentence Perplexity for row 7: 135.40319994088242\n",
      "\n",
      "Processing row 8...\n",
      "Reference Text: Wow, that is so disgusting.\n",
      "Output Text:  Oh no, was it a big accident? \n",
      "Token Probabilities: [0.0018574876012280583]\n",
      "Sentence Perplexity for row 8: 538.3616016273057\n",
      "\n",
      "Processing row 9...\n",
      "Reference Text: Wow.Really? What kind?\n",
      "Output Text:  That's good. Did you get it? \n",
      "Token Probabilities: [0.00144032237585634]\n",
      "Sentence Perplexity for row 9: 694.2890124896187\n",
      "\n",
      "Processing row 10...\n",
      "Reference Text: Omg my current dog does that sometimes. She pukes up bile if she doesn't eat, so I always have to make sure she is eating her food.\n",
      "Output Text:  I have no idea. I'm not sure what to do anymore. \n",
      "Token Probabilities: [0.06123160943388939]\n",
      "Sentence Perplexity for row 10: 16.33143419298297\n",
      "\n",
      "Processing row 11...\n",
      "Reference Text: That's amazing, It's always nice to get on with your family! Have you always got on with them? \n",
      "Output Text:  That is so sweet.  I'm glad you're enjoying it.  I hope things go well! \n",
      "Token Probabilities: [0.005244315601885319]\n",
      "Sentence Perplexity for row 11: 190.68265068572572\n",
      "\n",
      "Processing row 12...\n",
      "Reference Text: I am not sure as I could not stop because of all the traffic.\n",
      "Output Text:  Yeah I'm sorry to hear that. I hope you find him again. \n",
      "Token Probabilities: [3.877261042362079e-05]\n",
      "Sentence Perplexity for row 12: 25791.402463600603\n",
      "\n",
      "Processing row 13...\n",
      "Reference Text: I can barely walk much less imagine that.\n",
      "Output Text:  He is a sweet and piano one. He is only 13. He is so talented. \n",
      "Token Probabilities: [0.022489167749881744]\n",
      "Sentence Perplexity for row 13: 44.46585178792392\n",
      "\n",
      "Processing row 14...\n",
      "Reference Text: Oh for sure! I love riding jet skis!\n",
      "Output Text:  I'm sure it will go well.  \n",
      "Token Probabilities: [0.062451936304569244]\n",
      "Sentence Perplexity for row 14: 16.012313775559203\n",
      "\n",
      "Processing row 15...\n",
      "Reference Text: I feel like this is me. I'm clean, but I'm stuck with a dirty roommate who doesn't do dishes. And I also live in a place that is old and looks terrible to begin with. Sorry you have to deal with that, because I know I hate living in it!\n",
      "Output Text:  Oh, that sounds like you had to be a lot of faith. \n",
      "Token Probabilities: [0.00016559931100346148]\n",
      "Sentence Perplexity for row 15: 6038.67246753881\n",
      "\n",
      "Processing row 16...\n",
      "Reference Text: You can get a adviser\n",
      "Output Text:  I'm sorry to hear that.  \n",
      "Token Probabilities: [0.0627611055970192]\n",
      "Sentence Perplexity for row 16: 15.933435054839034\n",
      "\n",
      "Processing row 17...\n",
      "Reference Text: Yeah, Medical emergency. I borrowed $5000. Hope I'll repay this month.\n",
      "Output Text:  I went to a new place and I was so thankful. \n",
      "Token Probabilities: [0.16367806494235992]\n",
      "Sentence Perplexity for row 17: 6.109554144302447\n",
      "\n",
      "Processing row 18...\n",
      "Reference Text: You shouldn't let those kind of people upset you.\n",
      "Output Text:  I was so mad. \n",
      "Token Probabilities: [0.2474524974822998]\n",
      "Sentence Perplexity for row 18: 4.041179661448071\n",
      "\n",
      "Processing row 19...\n",
      "Reference Text: Oh no! He doesn't seem like such a good friend then. I hate it when friends pull stuff like that!\n",
      "Output Text:  Oh that was a nice thing to do. Did you find a chance to do it? \n",
      "Token Probabilities: [0.0001398941094521433]\n",
      "Sentence Perplexity for row 19: 7148.263811222814\n",
      "\n",
      "Processing row 20...\n",
      "Reference Text: Ohh you have a really good memory. I am very bad at remembering things, lol.\n",
      "Output Text:  I never feel the same time.  \n",
      "Token Probabilities: [0.19419047236442566]\n",
      "Sentence Perplexity for row 20: 5.149583230444796\n",
      "\n",
      "Processing row 21...\n",
      "Reference Text: I wish i could make that type of money!\n",
      "Output Text:  I would have been that much better \n",
      "Token Probabilities: [0.0017174907261505723]\n",
      "Sentence Perplexity for row 21: 582.2447741777969\n",
      "\n",
      "Processing row 22...\n",
      "Reference Text: I thought we had a ghost for a long time\n",
      "Output Text:  I had a scary experience. I'm so glad you got to see them. \n",
      "Token Probabilities: [0.03622497245669365]\n",
      "Sentence Perplexity for row 22: 27.605265985929552\n",
      "\n",
      "Processing row 23...\n",
      "Reference Text: this is true.\n",
      "Output Text:  I bet. I'm sorry to hear that. \n",
      "Token Probabilities: [0.027052562683820724]\n",
      "Sentence Perplexity for row 23: 36.96507468396212\n",
      "\n",
      "Processing row 24...\n",
      "Reference Text: I get you, I've been in your situation before\n",
      "Output Text:  I am so glad you have a lot of luck with what I was doing! \n",
      "Token Probabilities: [0.011804724112153053]\n",
      "Sentence Perplexity for row 24: 84.71184845145959\n",
      "\n",
      "Processing row 25...\n",
      "Reference Text: I see that more in the country I guess. That would be horrifying. But maybe he is just immune to pain?\n",
      "Output Text:  Sounds like you have to be able to find a good friend. \n",
      "Token Probabilities: [0.004568604286760092]\n",
      "Sentence Perplexity for row 25: 218.88522998107337\n",
      "\n",
      "Processing row 26...\n",
      "Reference Text: Can you tell me the name of the book? I find myself being engaged by a lot of novels these days.\n",
      "Output Text:  I love playing video games. I love the ice \n",
      "Token Probabilities: [0.0016954451566562057]\n",
      "Sentence Perplexity for row 26: 589.8155986196698\n",
      "\n",
      "Processing row 27...\n",
      "Reference Text: Wow how exciting, has he been practicing a lot? \n",
      "Output Text:  That's awesome! I bet it was great! \n",
      "Token Probabilities: [0.0032619312405586243]\n",
      "Sentence Perplexity for row 27: 306.56685449591026\n",
      "\n",
      "Processing row 28...\n",
      "Reference Text: yea i was very happy he helped me\n",
      "Output Text:  I am. I hope it goes well for you. \n",
      "Token Probabilities: [0.022740373387932777]\n",
      "Sentence Perplexity for row 28: 43.97465173244042\n",
      "\n",
      "Processing row 29...\n",
      "Reference Text: They wer really nice and trustworthy. I even let them use my wifi password.\n",
      "Output Text:  I think I was just trying to take a break from the time I was able to get it done. \n",
      "Token Probabilities: [0.10665823519229889]\n",
      "Sentence Perplexity for row 29: 9.375741106132645\n",
      "\n",
      "Processing row 30...\n",
      "Reference Text: Or it could be you and a dope house party\n",
      "Output Text:  I understand. I can't wait to see what I would do.  \n",
      "Token Probabilities: [0.09532337635755539]\n",
      "Sentence Perplexity for row 30: 10.490606168302591\n",
      "\n",
      "Processing row 31...\n",
      "Reference Text: Yeah it might be a good idea to tell him. But you may want to have the money to give back to him first. \n",
      "Output Text:  I would be too. Did you ever get a chance to clean up after him? \n",
      "Token Probabilities: [0.0015710440929979086]\n",
      "Sentence Perplexity for row 31: 636.5193723441415\n",
      "\n",
      "Processing row 32...\n",
      "Reference Text: What did you do with them?\n",
      "Output Text:  I'm glad you're doing okay.  \n",
      "Token Probabilities: [0.04607214406132698]\n",
      "Sentence Perplexity for row 32: 21.705089276264033\n",
      "\n",
      "Processing row 33...\n",
      "Reference Text: Congrats!!\n",
      "Output Text:  I would have been so upset too. \n",
      "Token Probabilities: [0.17659255862236023]\n",
      "Sentence Perplexity for row 33: 5.6627527671677305\n",
      "\n",
      "Processing row 34...\n",
      "Reference Text: what was on it\n",
      "Output Text:  I love pizza!  What do you eat? \n",
      "Token Probabilities: [0.0978078842163086]\n",
      "Sentence Perplexity for row 34: 10.22412465020135\n",
      "\n",
      "Processing row 35...\n",
      "Reference Text: I am so ready for it!\n",
      "Output Text:  It is. I am so glad I have a friend who is going to be able to go to school tomorrow. \n",
      "Token Probabilities: [0.010934957303106785]\n",
      "Sentence Perplexity for row 35: 91.44983124130582\n",
      "\n",
      "Processing row 36...\n",
      "Reference Text: I am going to be a birthday clown.\n",
      "Output Text:  It's a job for a new job, but it's a business business. \n",
      "Token Probabilities: [0.10851693153381348]\n",
      "Sentence Perplexity for row 36: 9.215151828066608\n",
      "\n",
      "Processing row 37...\n",
      "Reference Text: She was 23 years old. I got her when I was 5.\n",
      "Output Text:  She was 13 years old. I was so sad. \n",
      "Token Probabilities: [0.03597905859351158]\n",
      "Sentence Perplexity for row 37: 27.79394567539737\n",
      "\n",
      "Processing row 38...\n",
      "Reference Text: This was a few months ago.\n",
      "Output Text:  I'm not sure about it.  My family had been missing a lot lately. \n",
      "Token Probabilities: [0.2850363850593567]\n",
      "Sentence Perplexity for row 38: 3.5083240330589986\n",
      "\n",
      "Processing row 39...\n",
      "Reference Text: It's a band called Say Anything, I've been a fan of theirs since 2006! \n",
      "Output Text:  It's a Korean- tourist loss of her face all- those things.  \n",
      "Token Probabilities: [0.037260305136442184]\n",
      "Sentence Perplexity for row 39: 26.83821284710728\n",
      "\n",
      "Processing row 40...\n",
      "Reference Text: Oh that's a standard prcedure. Have you ever had one?\n",
      "Output Text:  It is. \n",
      "Token Probabilities: [0.08309899270534515]\n",
      "Sentence Perplexity for row 40: 12.033840212068869\n",
      "\n",
      "Processing row 41...\n",
      "Reference Text: Have you been before? It seems like such a great way to both play and get a workout \n",
      "Output Text:  I think I am going to do well on the day. \n",
      "Token Probabilities: [0.16740919649600983]\n",
      "Sentence Perplexity for row 41: 5.9733874896403005\n",
      "\n",
      "Processing row 42...\n",
      "Reference Text: No, I hate being by myself.\n",
      "Output Text:  I did. I just got to see them I guess. \n",
      "Token Probabilities: [0.12581287324428558]\n",
      "Sentence Perplexity for row 42: 7.9483122371614705\n",
      "\n",
      "Processing row 43...\n",
      "Reference Text: I could see that happening but sounds like you were super brave.\n",
      "Output Text:  I know that I would be so mad. \n",
      "Token Probabilities: [0.15410488843917847]\n",
      "Sentence Perplexity for row 43: 6.489086816961528\n",
      "\n",
      "Processing row 44...\n",
      "Reference Text: He's quite the piece of garbage.\n",
      "Output Text:  I know what you mean. \n",
      "Token Probabilities: [0.1626666635274887]\n",
      "Sentence Perplexity for row 44: 6.14754110224319\n",
      "\n",
      "Processing row 45...\n",
      "Reference Text: Tell me about it. How long have you been job hunting for?\n",
      "Output Text:  Did you get it fixed? \n",
      "Token Probabilities: [0.033238139003515244]\n",
      "Sentence Perplexity for row 45: 30.085920270513355\n",
      "\n",
      "Processing row 46...\n",
      "Reference Text: That is such a beautiful memory to have. I love that we forever have moments like this... How cool Hong Kong! \n",
      "Output Text:  I love my wife. My favorite. She was so cute. \n",
      "Token Probabilities: [0.039256542921066284]\n",
      "Sentence Perplexity for row 46: 25.473460615488094\n",
      "\n",
      "Processing row 47...\n",
      "Reference Text: I think he was slightly over the limit but he had a few drinks earlier, so I felt a bit uncomfortable.\n",
      "Output Text:  She was just a car. I'm not sure if she's not to get it. \n",
      "Token Probabilities: [0.012625747360289097]\n",
      "Sentence Perplexity for row 47: 79.20323220985962\n",
      "\n",
      "Processing row 48...\n",
      "Reference Text: IT is. \n",
      "Output Text:  It's a little bit overwhelming. \n",
      "Token Probabilities: [0.02966621145606041]\n",
      "Sentence Perplexity for row 48: 33.7083823959501\n",
      "\n",
      "Processing row 49...\n",
      "Reference Text: OH that sucks.\n",
      "Output Text:  Well that was good. You must be so upset. \n",
      "Token Probabilities: [0.0001675660751061514]\n",
      "Sentence Perplexity for row 49: 5967.795088394296\n",
      "\n",
      "Processing row 50...\n",
      "Reference Text: thats wonderful\n",
      "Output Text:  That's so awesome! I'm glad you are feeling a lot. \n",
      "Token Probabilities: [0.008305426687002182]\n",
      "Sentence Perplexity for row 50: 120.4032059623112\n",
      "\n",
      "Processing row 51...\n",
      "Reference Text: I've had that feeling as well, especially if it is with someone that is close to me.  Is it because you dont like confrontation or a different reason?\n",
      "Output Text:  I had to leave. I was so nervous. \n",
      "Token Probabilities: [0.20276424288749695]\n",
      "Sentence Perplexity for row 51: 4.931836036568077\n",
      "\n",
      "Processing row 52...\n",
      "Reference Text: No they did not. And it is going to cost too much to take them to court. \n",
      "Output Text:  \n",
      "Token Probabilities: [0.08190029114484787]\n",
      "Sentence Perplexity for row 52: 12.209968805012085\n",
      "\n",
      "Processing row 53...\n",
      "Reference Text: thats good!\n",
      "Output Text:  I bet that was scary.  Did you get any good news? \n",
      "Token Probabilities: [0.06548164784908295]\n",
      "Sentence Perplexity for row 53: 15.271454412764976\n",
      "\n",
      "Processing row 54...\n",
      "Reference Text: That is so true! \n",
      "Output Text:  I'm sorry to hear that.  \n",
      "Token Probabilities: [0.0627611055970192]\n",
      "Sentence Perplexity for row 54: 15.933435054839034\n",
      "\n",
      "Processing row 55...\n",
      "Reference Text: I sort of have. I worked like crazy to get a work visa for the US, so I could be with the person I wanted to spend my life with. It paid off, so I can kind of understand what you're saying.\n",
      "Output Text:  I think I'm going to do a good job. \n",
      "Token Probabilities: [0.252626895904541]\n",
      "Sentence Perplexity for row 55: 3.958406710494774\n",
      "\n",
      "Processing row 56...\n",
      "Reference Text: It sounds like you did great. Studying is the biggest part really.\n",
      "Output Text:  I series? \n",
      "Token Probabilities: [0.07229503244161606]\n",
      "Sentence Perplexity for row 56: 13.83220902221157\n",
      "\n",
      "Processing row 57...\n",
      "Reference Text: Don't tell her right after she awakes up. Women are never in the best mood right after waking up.\n",
      "Output Text:  Oh wow, that sounds like a good idea. \n",
      "Token Probabilities: [0.00038097728975117207]\n",
      "Sentence Perplexity for row 57: 2624.828374030197\n",
      "\n",
      "Processing row 58...\n",
      "Reference Text: Maybe.\n",
      "Output Text:  I think. I'm sure you'll be able to enjoy it. \n",
      "Token Probabilities: [0.010486211627721786]\n",
      "Sentence Perplexity for row 58: 95.36332428732968\n",
      "\n",
      "Processing row 59...\n",
      "Reference Text: They thought it was a better school, and it probably was, but I didn't feel like it was at the time\n",
      "Output Text:  Yes, I think I am going to do well. \n",
      "Token Probabilities: [0.000495953019708395]\n",
      "Sentence Perplexity for row 59: 2016.320014722299\n",
      "\n",
      "Processing row 60...\n",
      "Reference Text: That's great. I hope you have a wonderful time.\n",
      "Output Text:  That is hard. You will get it for it. \n",
      "Token Probabilities: [0.00736700464040041]\n",
      "Sentence Perplexity for row 60: 135.74037873086618\n",
      "\n",
      "Processing row 61...\n",
      "Reference Text: That is bad. What are you planning to do instead?\n",
      "Output Text:  That's good.  What is the competition? \n",
      "Token Probabilities: [0.011280332691967487]\n",
      "Sentence Perplexity for row 61: 88.649867633078\n",
      "\n",
      "Processing row 62...\n",
      "Reference Text: A little bit bu, they took the insurance money and bought a big house - i mean BIG! I know they needed more room for my mother to move in, but what they bought was way over and above what was needed.\n",
      "Output Text:  I do not know, but I'm not sure if I'm not as good. \n",
      "Token Probabilities: [0.12041682004928589]\n",
      "Sentence Perplexity for row 62: 8.304487691924649\n",
      "\n",
      "Processing row 63...\n",
      "Reference Text: Mostly happy. They have annoyed me greatly all summer\n",
      "Output Text:  I am not sure I am.  I have been to a doctor's appointment in the next week.  I am so excited. \n",
      "Token Probabilities: [0.4448929727077484]\n",
      "Sentence Perplexity for row 63: 2.2477316148953945\n",
      "\n",
      "Processing row 64...\n",
      "Reference Text: That is really interesting. Still over my head, but you did a decent job of explaining it in layman's terms. I appreciate it. So are you a med student, or what?\n",
      "Output Text:  Yeah, those were in my neighborhood especially when it's hard to deal with. \n",
      "Token Probabilities: [0.0010853615822270513]\n",
      "Sentence Perplexity for row 64: 921.3519405653757\n",
      "\n",
      "Processing row 65...\n",
      "Reference Text: Oh wow! Congratulations! I also recently applied for grad school to study Computer Science (seriously). What are you wanting to study?\n",
      "Output Text:  That's really important. What are you studying? \n",
      "Token Probabilities: [8.315169543493539e-05]\n",
      "Sentence Perplexity for row 65: 12026.212992644047\n",
      "\n",
      "Processing row 66...\n",
      "Reference Text: I'm sure that much be hard to stand by and watch as someone who works hard for their things. \n",
      "Output Text:  I can't afford her anymore. \n",
      "Token Probabilities: [0.12838108837604523]\n",
      "Sentence Perplexity for row 66: 7.78930925613333\n",
      "\n",
      "Processing row 67...\n",
      "Reference Text: It does get better, but it was just so sudden.\n",
      "Output Text:  I'm glad I did. \n",
      "Token Probabilities: [0.17426250874996185]\n",
      "Sentence Perplexity for row 67: 5.738468975187522\n",
      "\n",
      "Processing row 68...\n",
      "Reference Text: True, driving takes more focus than a lot of people can handle\n",
      "Output Text:  I don't think it's a pain, but it's hard to get in trouble. \n",
      "Token Probabilities: [0.19749297201633453]\n",
      "Sentence Perplexity for row 68: 5.063471321487281\n",
      "\n",
      "Processing row 69...\n",
      "Reference Text: I have no idea. We found it after she left. It was really gross. I wonder if her house is that nasty?\n",
      "Output Text:  They did not, but they were just so busy. \n",
      "Token Probabilities: [0.0547349788248539]\n",
      "Sentence Perplexity for row 69: 18.26985268780122\n",
      "\n",
      "Processing row 70...\n",
      "Reference Text: That's good, it sounds like his bathroom motivated you to take yours to the next level. That's probably good for society.\n",
      "Output Text:  I am sure you will get it. \n",
      "Token Probabilities: [0.07841946184635162]\n",
      "Sentence Perplexity for row 70: 12.751936527686386\n",
      "\n",
      "Processing row 71...\n",
      "Reference Text: I do look a little like a somewhat taller version of him.\n",
      "Output Text:  I do, he is a little boy and I'm not sure if he's just a good kid. \n",
      "Token Probabilities: [0.10116160660982132]\n",
      "Sentence Perplexity for row 71: 9.885173175006836\n",
      "\n",
      "Processing row 72...\n",
      "Reference Text: Absolutely! Not to mention gardening saves a ton of money in the long run.\n",
      "Output Text:  Yes it's a nice set of my friends. \n",
      "Token Probabilities: [0.0010476779425516725]\n",
      "Sentence Perplexity for row 72: 954.4917950304933\n",
      "\n",
      "Processing row 73...\n",
      "Reference Text: That's great! Not too many 16 year olds are that responsible.\n",
      "Output Text:  Oh, that is a great idea. \n",
      "Token Probabilities: [0.00044856464955955744]\n",
      "Sentence Perplexity for row 73: 2229.3330537346023\n",
      "\n",
      "Processing row 74...\n",
      "Reference Text: The prices have risen alot with all the technology and electrical components.\n",
      "Output Text:  I would be too. But the worse is that they were just in the room for me. \n",
      "Token Probabilities: [0.08436217904090881]\n",
      "Sentence Perplexity for row 74: 11.853653039415699\n",
      "\n",
      "Processing row 75...\n",
      "Reference Text: Does he get anything else?\n",
      "Output Text:  That is good, but I don't know what to do. \n",
      "Token Probabilities: [0.01016745064407587]\n",
      "Sentence Perplexity for row 75: 98.35307148332762\n",
      "\n",
      "Processing row 76...\n",
      "Reference Text: Sounds like you have a very responsible young lady growing up.\n",
      "Output Text:  I am sure you will get a job offer soon.  I hope you get the job! \n",
      "Token Probabilities: [0.09723208099603653]\n",
      "Sentence Perplexity for row 76: 10.284671373440656\n",
      "\n",
      "Processing row 77...\n",
      "Reference Text: ah you used her. You should have filled. But however she will understand\n",
      "Output Text:  I'm sorry to hear that. You should get some food fixed. \n",
      "Token Probabilities: [0.017834175378084183]\n",
      "Sentence Perplexity for row 77: 56.07211877196554\n",
      "\n",
      "Processing row 78...\n",
      "Reference Text: I gave him some Tylenol, and we ended up snuggling til he could go back to sleep.  \n",
      "Output Text:  I'm sorry to hear that. Maybe he will help you. \n",
      "Token Probabilities: [0.0028834030963480473]\n",
      "Sentence Perplexity for row 78: 346.81241803011955\n",
      "\n",
      "Processing row 79...\n",
      "Reference Text: It was a hand written note from my dead mother. I never had read or seen it before. \n",
      "Output Text:  It was a car accident.  I was so mad. \n",
      "Token Probabilities: [0.22166374325752258]\n",
      "Sentence Perplexity for row 79: 4.511337692417423\n",
      "\n",
      "Processing row 80...\n",
      "Reference Text: Ouch, I hope you don't either. I'd keep any eye out at work from now on.\n",
      "Output Text:  I'm sorry to hear that.  What's wrong with your car? \n",
      "Token Probabilities: [0.04702267050743103]\n",
      "Sentence Perplexity for row 80: 21.26633790060837\n",
      "\n",
      "Processing row 81...\n",
      "Reference Text: I hope both our ego and your nose heal up quickly!\n",
      "Output Text:  That's good. I'm sure you will do great! \n",
      "Token Probabilities: [0.001208677887916565]\n",
      "Sentence Perplexity for row 81: 827.3502891028568\n",
      "\n",
      "Processing row 82...\n",
      "Reference Text: Yeah I would go off with my friends and have adventures. I miss that so much.\n",
      "Output Text:  I love the summer.  I love the beach.  I've been reading online as I've played with my parents.  I love it! \n",
      "Token Probabilities: [0.10670739412307739]\n",
      "Sentence Perplexity for row 82: 9.371421804627614\n",
      "\n",
      "Processing row 83...\n",
      "Reference Text: a bearded dragon\n",
      "Output Text:  It's a bearded dragon \n",
      "Token Probabilities: [0.0046251146122813225]\n",
      "Sentence Perplexity for row 83: 216.21085828762924\n",
      "\n",
      "Processing row 84...\n",
      "Reference Text: I don't know yet. Kinda need some time to process this.\n",
      "Output Text:  I do. I'm not sure about it. \n",
      "Token Probabilities: [0.23595775663852692]\n",
      "Sentence Perplexity for row 84: 4.23804673449214\n",
      "\n",
      "Processing row 85...\n",
      "Reference Text: It feels so good to update/upgrade, doesn't it? I feel like I have been out of the loop for too long.\n",
      "Output Text:  Oh, that's not too bad.  I'm sorry to hear that.  Did you get it back? \n",
      "Token Probabilities: [0.001251870533451438]\n",
      "Sentence Perplexity for row 85: 798.804647348776\n",
      "\n",
      "Processing row 86...\n",
      "Reference Text: Yeah it hurt and I was listening to music so I might have yelled a cuss word loudly.\n",
      "Output Text:  Yeah, but it was just a good feeling.  \n",
      "Token Probabilities: [0.001495204633101821]\n",
      "Sentence Perplexity for row 86: 668.8047761900572\n",
      "\n",
      "Processing row 87...\n",
      "Reference Text: I cannot imagine anyone wanting to drink that without losing a bet\n",
      "Output Text:  I am sorry to hear that.  I have been there \n",
      "Token Probabilities: [0.0033508548513054848]\n",
      "Sentence Perplexity for row 87: 298.43130913605603\n",
      "\n",
      "Processing row 88...\n",
      "Reference Text: Im taking your advice and putting it into practice tomorrow!\n",
      "Output Text:  I agree, they were just just so inconsiderate but tell the person. \n",
      "Token Probabilities: [0.05840408056974411]\n",
      "Sentence Perplexity for row 88: 17.12209130329233\n",
      "\n",
      "Processing row 89...\n",
      "Reference Text: Thank you, the bracelet means a lot to me\n",
      "Output Text:  I'm sorry to hear that. I hope you find someone. \n",
      "Token Probabilities: [0.008282401598989964]\n",
      "Sentence Perplexity for row 89: 120.73792704303905\n",
      "\n",
      "Processing row 90...\n",
      "Reference Text: How terrible! I'm so sorry that happened. How long ago was it?\n",
      "Output Text:  That is very annoying. \n",
      "Token Probabilities: [0.007083583157509565]\n",
      "Sentence Perplexity for row 90: 141.17149156918745\n",
      "\n",
      "Processing row 91...\n",
      "Reference Text: That's awesome! It really pays not to burn bridges, you never know when someone from your past can help you out like that.\n",
      "Output Text:  That is great.  I hope you get it. \n",
      "Token Probabilities: [0.02062845602631569]\n",
      "Sentence Perplexity for row 91: 48.47672548659491\n",
      "\n",
      "Processing row 92...\n",
      "Reference Text: What did you eat?\n",
      "Output Text:  I bet you were able to get a refund and then you'll be able to fix it. \n",
      "Token Probabilities: [0.013170702382922173]\n",
      "Sentence Perplexity for row 92: 75.92609497399721\n",
      "\n",
      "Processing row 93...\n",
      "Reference Text: wow good for you man\n",
      "Output Text:  Oh, I bet you are. I'm sure you will do great! \n",
      "Token Probabilities: [1.2864104064647108e-05]\n",
      "Sentence Perplexity for row 93: 77735.68955712828\n",
      "\n",
      "Processing row 94...\n",
      "Reference Text: Investigate that right now! You need to know\n",
      "Output Text:  I was at the beach. \n",
      "Token Probabilities: [0.4040645658969879]\n",
      "Sentence Perplexity for row 94: 2.474852002377609\n",
      "\n",
      "Processing row 95...\n",
      "Reference Text: That's really special, and a great attitude to have\n",
      "Output Text:  I bet he was! \n",
      "Token Probabilities: [0.036930184811353683]\n",
      "Sentence Perplexity for row 95: 27.07812065139094\n",
      "\n",
      "Processing row 96...\n",
      "Reference Text: I've never watched a single full star wars movie, just bits and pieces haha\n",
      "Output Text:  I love the beach! It's been a lot of fun. \n",
      "Token Probabilities: [0.11614073067903519]\n",
      "Sentence Perplexity for row 96: 8.61024374612887\n",
      "\n",
      "Processing row 97...\n",
      "Reference Text: Me too! It seems like such a huge accomplishment at the time, doesn't it?\n",
      "Output Text:  That's great.  I'm sorry to hear that.  Do you think you will do well? \n",
      "Token Probabilities: [0.00217570923268795]\n",
      "Sentence Perplexity for row 97: 459.6202401386897\n",
      "\n",
      "Processing row 98...\n",
      "Reference Text: That's great! good luck\n",
      "Output Text:  Oh wow! That's awesome! \n",
      "Token Probabilities: [0.00031735384254716337]\n",
      "Sentence Perplexity for row 98: 3151.0568517896104\n",
      "\n",
      "Processing row 99...\n",
      "Reference Text: No not at all. I just got up and couldnt stop laughing at myself. I could feel the heat coming off of my face.\n",
      "Output Text:  I did.  I was so upset.  I was so mad at myself. \n",
      "Token Probabilities: [0.2699751555919647]\n",
      "Sentence Perplexity for row 99: 3.7040445362734817\n",
      "Completed token-based perplexity calculations for column: new_label_withemotion\n",
      "Average Perplexity for withemotion: 1587.2087837246113\n",
      "new_label_withcontext\n",
      "Calculating token-based perplexity for column: new_label_withcontext\n",
      "\n",
      "Processing row 0...\n",
      "Reference Text: Should have grabbed the gun.\n",
      "Output Text:  I hope that there was a big storm. \n",
      "Token Probabilities: [0.24646367132663727]\n",
      "Sentence Perplexity for row 0: 4.057393102266598\n",
      "\n",
      "Processing row 1...\n",
      "Reference Text: Thank you!  It was so nice, I had no idea it was happening.  They're not usually so good with secrets haha\n",
      "Output Text:  I was shocked to see it. \n",
      "Token Probabilities: [0.27968961000442505]\n",
      "Sentence Perplexity for row 1: 3.5753920211200505\n",
      "\n",
      "Processing row 2...\n",
      "Reference Text: I do!  I'm feeling very optimistic about it\n",
      "Output Text:  I did. I just got a new one and I was so happy. \n",
      "Token Probabilities: [0.1782531589269638]\n",
      "Sentence Perplexity for row 2: 5.609998756934977\n",
      "\n",
      "Processing row 3...\n",
      "Reference Text: It was a medium amount of money but still, he did me so dirty.\n",
      "Output Text:  I was so mad! I was so mad. \n",
      "Token Probabilities: [0.13151168823242188]\n",
      "Sentence Perplexity for row 3: 7.603886874546772\n",
      "\n",
      "Processing row 4...\n",
      "Reference Text: Well, I started walking much faster. It looked like they were carrying a weapon or something.\n",
      "Output Text:  I got to go to work and I had to go to work. \n",
      "Token Probabilities: [0.405577689409256]\n",
      "Sentence Perplexity for row 4: 2.465618859500259\n",
      "\n",
      "Processing row 5...\n",
      "Reference Text: I had braces growing up too, the worst part for me was the molding!\n",
      "Output Text:  I remember the first time and I had to put a lot of faith in my abilities and I have to deal with my new diet and making sure I have to do it. \n",
      "Token Probabilities: [0.1820169985294342]\n",
      "Sentence Perplexity for row 5: 5.493992363786225\n",
      "\n",
      "Processing row 6...\n",
      "Reference Text: Yes, and it really sucks if you forget something important.\n",
      "Output Text:  I know that feeling. I'm sure it'll be a good trip.  \n",
      "Token Probabilities: [0.07213912904262543]\n",
      "Sentence Perplexity for row 6: 13.862102485450333\n",
      "\n",
      "Processing row 7...\n",
      "Reference Text: O no! That's a terrible thing to have happen or see.\n",
      "Output Text:  I am sure you are going to get it fixed \n",
      "Token Probabilities: [9.077706636162475e-05]\n",
      "Sentence Perplexity for row 7: 11015.998203955416\n",
      "\n",
      "Processing row 8...\n",
      "Reference Text: Wow, that is so disgusting.\n",
      "Output Text:  What did you do with it? \n",
      "Token Probabilities: [0.016652293503284454]\n",
      "Sentence Perplexity for row 8: 60.05178804966191\n",
      "\n",
      "Processing row 9...\n",
      "Reference Text: Wow.Really? What kind?\n",
      "Output Text:  Oh no!  I bet you were so happy!  \n",
      "Token Probabilities: [0.0017916131764650345]\n",
      "Sentence Perplexity for row 9: 558.1561986349437\n",
      "\n",
      "Processing row 10...\n",
      "Reference Text: Omg my current dog does that sometimes. She pukes up bile if she doesn't eat, so I always have to make sure she is eating her food.\n",
      "Output Text:  No, but I just got to go back to work. \n",
      "Token Probabilities: [0.0026463011745363474]\n",
      "Sentence Perplexity for row 10: 377.88593740665505\n",
      "\n",
      "Processing row 11...\n",
      "Reference Text: That's amazing, It's always nice to get on with your family! Have you always got on with them? \n",
      "Output Text:  That's awesome.  I bet you're very lucky to have a good family.  \n",
      "Token Probabilities: [0.029315456748008728]\n",
      "Sentence Perplexity for row 11: 34.111697750297736\n",
      "\n",
      "Processing row 12...\n",
      "Reference Text: I am not sure as I could not stop because of all the traffic.\n",
      "Output Text:  I agree. \n",
      "Token Probabilities: [0.2381116896867752]\n",
      "Sentence Perplexity for row 12: 4.1997098139761775\n",
      "\n",
      "Processing row 13...\n",
      "Reference Text: I can barely walk much less imagine that.\n",
      "Output Text:  Yes, he was so hyped up! \n",
      "Token Probabilities: [0.0008466766448691487]\n",
      "Sentence Perplexity for row 13: 1181.088442748467\n",
      "\n",
      "Processing row 14...\n",
      "Reference Text: Oh for sure! I love riding jet skis!\n",
      "Output Text:  I'm glad you're okay.  \n",
      "Token Probabilities: [0.09814102947711945]\n",
      "Sentence Perplexity for row 14: 10.189418282321357\n",
      "\n",
      "Processing row 15...\n",
      "Reference Text: I feel like this is me. I'm clean, but I'm stuck with a dirty roommate who doesn't do dishes. And I also live in a place that is old and looks terrible to begin with. Sorry you have to deal with that, because I know I hate living in it!\n",
      "Output Text:  Oh no! I hope you were able to see that! \n",
      "Token Probabilities: [0.0016756599070504308]\n",
      "Sentence Perplexity for row 15: 596.7798094305681\n",
      "\n",
      "Processing row 16...\n",
      "Reference Text: You can get a adviser\n",
      "Output Text:  I have a lot of people that are always talking to. It will be a better deal. \n",
      "Token Probabilities: [0.1154828667640686]\n",
      "Sentence Perplexity for row 16: 8.65929317500404\n",
      "\n",
      "Processing row 17...\n",
      "Reference Text: Yeah, Medical emergency. I borrowed $5000. Hope I'll repay this month.\n",
      "Output Text:  I was at the store, but I had my car to get to work. \n",
      "Token Probabilities: [0.30745792388916016]\n",
      "Sentence Perplexity for row 17: 3.252477566200259\n",
      "\n",
      "Processing row 18...\n",
      "Reference Text: You shouldn't let those kind of people upset you.\n",
      "Output Text:  Well, it was a good time. \n",
      "Token Probabilities: [0.001924455282278359]\n",
      "Sentence Perplexity for row 18: 519.6275586180947\n",
      "\n",
      "Processing row 19...\n",
      "Reference Text: Oh no! He doesn't seem like such a good friend then. I hate it when friends pull stuff like that!\n",
      "Output Text:  I have a friend like my own.  I am really disappointed about it.  I am so disappointed about it. \n",
      "Token Probabilities: [0.3172953724861145]\n",
      "Sentence Perplexity for row 19: 3.151637517322324\n",
      "\n",
      "Processing row 20...\n",
      "Reference Text: Ohh you have a really good memory. I am very bad at remembering things, lol.\n",
      "Output Text:  I have a huge storm where I was. \n",
      "Token Probabilities: [0.5482277870178223]\n",
      "Sentence Perplexity for row 20: 1.8240593119872106\n",
      "\n",
      "Processing row 21...\n",
      "Reference Text: I wish i could make that type of money!\n",
      "Output Text:  I'm sure it was just a good time. \n",
      "Token Probabilities: [0.17820852994918823]\n",
      "Sentence Perplexity for row 21: 5.6114036757114\n",
      "\n",
      "Processing row 22...\n",
      "Reference Text: I thought we had a ghost for a long time\n",
      "Output Text:  Oh my gosh, I had to be a lot of memories of when I was a kid, so I was so happy. \n",
      "Token Probabilities: [0.00017825618851929903]\n",
      "Sentence Perplexity for row 22: 5609.903410964798\n",
      "\n",
      "Processing row 23...\n",
      "Reference Text: this is true.\n",
      "Output Text:  I love those. I love those memories. \n",
      "Token Probabilities: [0.023494673892855644]\n",
      "Sentence Perplexity for row 23: 42.56283805258876\n",
      "\n",
      "Processing row 24...\n",
      "Reference Text: I get you, I've been in your situation before\n",
      "Output Text:  I'm sure it is.  \n",
      "Token Probabilities: [0.1462847888469696]\n",
      "Sentence Perplexity for row 24: 6.835980746064534\n",
      "\n",
      "Processing row 25...\n",
      "Reference Text: I see that more in the country I guess. That would be horrifying. But maybe he is just immune to pain?\n",
      "Output Text:  I'm sorry. I bet that was so frustrating. \n",
      "Token Probabilities: [0.04228483885526657]\n",
      "Sentence Perplexity for row 25: 23.64913825077638\n",
      "\n",
      "Processing row 26...\n",
      "Reference Text: Can you tell me the name of the book? I find myself being engaged by a lot of novels these days.\n",
      "Output Text:  What was the job that? \n",
      "Token Probabilities: [0.021322190761566162]\n",
      "Sentence Perplexity for row 26: 46.89949598436797\n",
      "\n",
      "Processing row 27...\n",
      "Reference Text: Wow how exciting, has he been practicing a lot? \n",
      "Output Text:  That's great news! \n",
      "Token Probabilities: [0.021189309656620026]\n",
      "Sentence Perplexity for row 27: 47.19360924000547\n",
      "\n",
      "Processing row 28...\n",
      "Reference Text: yea i was very happy he helped me\n",
      "Output Text:  I hope you get better. \n",
      "Token Probabilities: [0.08375130593776703]\n",
      "Sentence Perplexity for row 28: 11.940112321867183\n",
      "\n",
      "Processing row 29...\n",
      "Reference Text: They wer really nice and trustworthy. I even let them use my wifi password.\n",
      "Output Text:  I was in the middle of the night. I did not know if I should. \n",
      "Token Probabilities: [0.02534722164273262]\n",
      "Sentence Perplexity for row 29: 39.45205569647564\n",
      "\n",
      "Processing row 30...\n",
      "Reference Text: Or it could be you and a dope house party\n",
      "Output Text:  That's true. I am glad I've been able to get it. \n",
      "Token Probabilities: [0.008881306275725365]\n",
      "Sentence Perplexity for row 30: 112.5960493821982\n",
      "\n",
      "Processing row 31...\n",
      "Reference Text: Yeah it might be a good idea to tell him. But you may want to have the money to give back to him first. \n",
      "Output Text:  That is really nice. Did you tell him about it? \n",
      "Token Probabilities: [0.005369514226913452]\n",
      "Sentence Perplexity for row 31: 186.23658635407472\n",
      "\n",
      "Processing row 32...\n",
      "Reference Text: What did you do with them?\n",
      "Output Text:  I am going to meet some friends who are both cool. \n",
      "Token Probabilities: [0.3136913478374481]\n",
      "Sentence Perplexity for row 32: 3.1878469294543326\n",
      "\n",
      "Processing row 33...\n",
      "Reference Text: Congrats!!\n",
      "Output Text:  I hope you did well \n",
      "Token Probabilities: [0.0026345672085881233]\n",
      "Sentence Perplexity for row 33: 379.56898451488155\n",
      "\n",
      "Processing row 34...\n",
      "Reference Text: what was on it\n",
      "Output Text:  That's awesome. \n",
      "Token Probabilities: [0.017238376662135124]\n",
      "Sentence Perplexity for row 34: 58.01010266799338\n",
      "\n",
      "Processing row 35...\n",
      "Reference Text: I am so ready for it!\n",
      "Output Text:  I am so sorry. I am sorry to hear that. \n",
      "Token Probabilities: [0.09914243221282959]\n",
      "Sentence Perplexity for row 35: 10.086498562525625\n",
      "\n",
      "Processing row 36...\n",
      "Reference Text: I am going to be a birthday clown.\n",
      "Output Text:  It is a roleworker.  I'm so happy. \n",
      "Token Probabilities: [0.07291249930858612]\n",
      "Sentence Perplexity for row 36: 13.71506956259612\n",
      "\n",
      "Processing row 37...\n",
      "Reference Text: She was 23 years old. I got her when I was 5.\n",
      "Output Text:  She was a little baby, and she was a baby! \n",
      "Token Probabilities: [0.26558059453964233]\n",
      "Sentence Perplexity for row 37: 3.7653353466332917\n",
      "\n",
      "Processing row 38...\n",
      "Reference Text: This was a few months ago.\n",
      "Output Text:  It was a few weeks ago. I had to go to the store. I had to go to the bathroom and go and go with a double-up even though I left the house. \n",
      "Token Probabilities: [0.07861831784248352]\n",
      "Sentence Perplexity for row 38: 12.719681970346395\n",
      "\n",
      "Processing row 39...\n",
      "Reference Text: It's a band called Say Anything, I've been a fan of theirs since 2006! \n",
      "Output Text:  It's a teddy bear, my apartment to a car to a car and it's a teddy bear. I was backed out of the box and it came out of the yard. I was in a rush too. \n",
      "Token Probabilities: [0.008519047871232033]\n",
      "Sentence Perplexity for row 39: 117.38400994046519\n",
      "\n",
      "Processing row 40...\n",
      "Reference Text: Oh that's a standard prcedure. Have you ever had one?\n",
      "Output Text:  I was her, she was her cat? \n",
      "Token Probabilities: [0.099854476749897]\n",
      "Sentence Perplexity for row 40: 10.014573532889013\n",
      "\n",
      "Processing row 41...\n",
      "Reference Text: Have you been before? It seems like such a great way to both play and get a workout \n",
      "Output Text:  I'm happy that you have a lot of family! \n",
      "Token Probabilities: [0.22085292637348175]\n",
      "Sentence Perplexity for row 41: 4.527900156998201\n",
      "\n",
      "Processing row 42...\n",
      "Reference Text: No, I hate being by myself.\n",
      "Output Text:  Yeah, I was so happy. I was so happy. \n",
      "Token Probabilities: [0.00014011100574862212]\n",
      "Sentence Perplexity for row 42: 7137.198071321627\n",
      "\n",
      "Processing row 43...\n",
      "Reference Text: I could see that happening but sounds like you were super brave.\n",
      "Output Text:  I hope you're doing great. \n",
      "Token Probabilities: [0.14659099280834198]\n",
      "Sentence Perplexity for row 43: 6.821701530512408\n",
      "\n",
      "Processing row 44...\n",
      "Reference Text: He's quite the piece of garbage.\n",
      "Output Text:  I know. I'm sure you will be able to relax. \n",
      "Token Probabilities: [0.09422617405653]\n",
      "Sentence Perplexity for row 44: 10.61276243053295\n",
      "\n",
      "Processing row 45...\n",
      "Reference Text: Tell me about it. How long have you been job hunting for?\n",
      "Output Text:  I'm not sure. \n",
      "Token Probabilities: [0.22170299291610718]\n",
      "Sentence Perplexity for row 45: 4.510539018200814\n",
      "\n",
      "Processing row 46...\n",
      "Reference Text: That is such a beautiful memory to have. I love that we forever have moments like this... How cool Hong Kong! \n",
      "Output Text:  Oh, I'm so glad that you were able to visit them.  I'm sure you will see them!  \n",
      "Token Probabilities: [0.0024630920961499214]\n",
      "Sentence Perplexity for row 46: 405.99375133520516\n",
      "\n",
      "Processing row 47...\n",
      "Reference Text: I think he was slightly over the limit but he had a few drinks earlier, so I felt a bit uncomfortable.\n",
      "Output Text:  I did, but it was a very nice deal. I was so happy. \n",
      "Token Probabilities: [0.03690847381949425]\n",
      "Sentence Perplexity for row 47: 27.094049049295066\n",
      "\n",
      "Processing row 48...\n",
      "Reference Text: IT is. \n",
      "Output Text:  It is, it's nice to be able to go to your house and get together. \n",
      "Token Probabilities: [0.04006063565611839]\n",
      "Sentence Perplexity for row 48: 24.962160076141274\n",
      "\n",
      "Processing row 49...\n",
      "Reference Text: OH that sucks.\n",
      "Output Text:  Oh no! I'm so glad you have a great time! \n",
      "Token Probabilities: [0.0012791830813512206]\n",
      "Sentence Perplexity for row 49: 781.7489259971176\n",
      "\n",
      "Processing row 50...\n",
      "Reference Text: thats wonderful\n",
      "Output Text:  I'm sorry. I'm sorry. \n",
      "Token Probabilities: [0.08834926784038544]\n",
      "Sentence Perplexity for row 50: 11.318712927045773\n",
      "\n",
      "Processing row 51...\n",
      "Reference Text: I've had that feeling as well, especially if it is with someone that is close to me.  Is it because you dont like confrontation or a different reason?\n",
      "Output Text:  I'm glad you were okay.  \n",
      "Token Probabilities: [0.09617843478918076]\n",
      "Sentence Perplexity for row 51: 10.397341173122223\n",
      "\n",
      "Processing row 52...\n",
      "Reference Text: No they did not. And it is going to cost too much to take them to court. \n",
      "Output Text:  I hope they can do well. I hope they will come back soon. \n",
      "Token Probabilities: [0.039424434304237366]\n",
      "Sentence Perplexity for row 52: 25.364980313554412\n",
      "\n",
      "Processing row 53...\n",
      "Reference Text: thats good!\n",
      "Output Text:  I bet you were so happy. I was so happy. \n",
      "Token Probabilities: [0.04129413515329361]\n",
      "Sentence Perplexity for row 53: 24.216513950171453\n",
      "\n",
      "Processing row 54...\n",
      "Reference Text: That is so true! \n",
      "Output Text:  I know right? \n",
      "Token Probabilities: [0.1542966365814209]\n",
      "Sentence Perplexity for row 54: 6.481022672664088\n",
      "\n",
      "Processing row 55...\n",
      "Reference Text: I sort of have. I worked like crazy to get a work visa for the US, so I could be with the person I wanted to spend my life with. It paid off, so I can kind of understand what you're saying.\n",
      "Output Text:  Yes, I've been working like a lot about a lot of time. \n",
      "Token Probabilities: [0.000982010504230857]\n",
      "Sentence Perplexity for row 55: 1018.319046172763\n",
      "\n",
      "Processing row 56...\n",
      "Reference Text: It sounds like you did great. Studying is the biggest part really.\n",
      "Output Text:  I am glad you did well on it \n",
      "Token Probabilities: [0.00017166110046673566]\n",
      "Sentence Perplexity for row 56: 5825.431604953381\n",
      "\n",
      "Processing row 57...\n",
      "Reference Text: Don't tell her right after she awakes up. Women are never in the best mood right after waking up.\n",
      "Output Text:  That is awesome! What was she going to do for her? \n",
      "Token Probabilities: [0.007800486404448748]\n",
      "Sentence Perplexity for row 57: 128.1971338902256\n",
      "\n",
      "Processing row 58...\n",
      "Reference Text: Maybe.\n",
      "Output Text:  I have to do not be a good friend. \n",
      "Token Probabilities: [0.2995619475841522]\n",
      "Sentence Perplexity for row 58: 3.3382076998250336\n",
      "\n",
      "Processing row 59...\n",
      "Reference Text: They thought it was a better school, and it probably was, but I didn't feel like it was at the time\n",
      "Output Text:  I have been in the school.  I was so happy. \n",
      "Token Probabilities: [0.3463970124721527]\n",
      "Sentence Perplexity for row 59: 2.8868609254544055\n",
      "\n",
      "Processing row 60...\n",
      "Reference Text: That's great. I hope you have a wonderful time.\n",
      "Output Text:  I have been on a wedding for 6 months now. I've been planning a wedding and the wedding is the first time. \n",
      "Token Probabilities: [0.317331999540329]\n",
      "Sentence Perplexity for row 60: 3.1512737494124425\n",
      "\n",
      "Processing row 61...\n",
      "Reference Text: That is bad. What are you planning to do instead?\n",
      "Output Text:  That is so awful. I hope you get to play it. \n",
      "Token Probabilities: [0.010203605517745018]\n",
      "Sentence Perplexity for row 61: 98.00457282094133\n",
      "\n",
      "Processing row 62...\n",
      "Reference Text: A little bit bu, they took the insurance money and bought a big house - i mean BIG! I know they needed more room for my mother to move in, but what they bought was way over and above what was needed.\n",
      "Output Text:  Yes, I'm not sure but I don't know if I should. \n",
      "Token Probabilities: [0.0004601285036187619]\n",
      "Sentence Perplexity for row 62: 2173.3059180974947\n",
      "\n",
      "Processing row 63...\n",
      "Reference Text: Mostly happy. They have annoyed me greatly all summer\n",
      "Output Text:  I am not sure I did. I have no idea.  \n",
      "Token Probabilities: [0.07376746088266373]\n",
      "Sentence Perplexity for row 63: 13.556112519456562\n",
      "\n",
      "Processing row 64...\n",
      "Reference Text: That is really interesting. Still over my head, but you did a decent job of explaining it in layman's terms. I appreciate it. So are you a med student, or what?\n",
      "Output Text:  I know. I was so mad at my boss. \n",
      "Token Probabilities: [0.13623768091201782]\n",
      "Sentence Perplexity for row 64: 7.340113200002275\n",
      "\n",
      "Processing row 65...\n",
      "Reference Text: Oh wow! Congratulations! I also recently applied for grad school to study Computer Science (seriously). What are you wanting to study?\n",
      "Output Text:  I'm glad you have a great time. \n",
      "Token Probabilities: [0.15656903386116028]\n",
      "Sentence Perplexity for row 65: 6.386959000377837\n",
      "\n",
      "Processing row 66...\n",
      "Reference Text: I'm sure that much be hard to stand by and watch as someone who works hard for their things. \n",
      "Output Text:  I would have to wait for her and she is a good boy. \n",
      "Token Probabilities: [0.23760154843330383]\n",
      "Sentence Perplexity for row 66: 4.208726780586221\n",
      "\n",
      "Processing row 67...\n",
      "Reference Text: It does get better, but it was just so sudden.\n",
      "Output Text:  I'm sure it was a lot of bad times. \n",
      "Token Probabilities: [0.15918003022670746]\n",
      "Sentence Perplexity for row 67: 6.2821950628843295\n",
      "\n",
      "Processing row 68...\n",
      "Reference Text: True, driving takes more focus than a lot of people can handle\n",
      "Output Text:  I don't know.  I'm not sure what I should. \n",
      "Token Probabilities: [0.3215109705924988]\n",
      "Sentence Perplexity for row 68: 3.110313772986169\n",
      "\n",
      "Processing row 69...\n",
      "Reference Text: I have no idea. We found it after she left. It was really gross. I wonder if her house is that nasty?\n",
      "Output Text:  I just had to put some of my friends. I have no idea what I was going to do. \n",
      "Token Probabilities: [0.11936598271131516]\n",
      "Sentence Perplexity for row 69: 8.377596173429788\n",
      "\n",
      "Processing row 70...\n",
      "Reference Text: That's good, it sounds like his bathroom motivated you to take yours to the next level. That's probably good for society.\n",
      "Output Text:  I bet. It's gross. \n",
      "Token Probabilities: [0.04159444198012352]\n",
      "Sentence Perplexity for row 70: 24.041673656251085\n",
      "\n",
      "Processing row 71...\n",
      "Reference Text: I do look a little like a somewhat taller version of him.\n",
      "Output Text:  I am sure he will do the love. \n",
      "Token Probabilities: [0.10701994597911835]\n",
      "Sentence Perplexity for row 71: 9.344052558156957\n",
      "\n",
      "Processing row 72...\n",
      "Reference Text: Absolutely! Not to mention gardening saves a ton of money in the long run.\n",
      "Output Text:  I love that feeling. I am glad you have a good time. \n",
      "Token Probabilities: [0.06806118041276932]\n",
      "Sentence Perplexity for row 72: 14.69266318825679\n",
      "\n",
      "Processing row 73...\n",
      "Reference Text: That's great! Not too many 16 year olds are that responsible.\n",
      "Output Text:  I'm sorry. \n",
      "Token Probabilities: [0.13013111054897308]\n",
      "Sentence Perplexity for row 73: 7.684557488070184\n",
      "\n",
      "Processing row 74...\n",
      "Reference Text: The prices have risen alot with all the technology and electrical components.\n",
      "Output Text:  I'm really sorry to hear that. I hope your life is right. \n",
      "Token Probabilities: [0.03146407753229141]\n",
      "Sentence Perplexity for row 74: 31.782276120242376\n",
      "\n",
      "Processing row 75...\n",
      "Reference Text: Does he get anything else?\n",
      "Output Text:  I know that's good. I hope he does well. \n",
      "Token Probabilities: [0.03646450117230415]\n",
      "Sentence Perplexity for row 75: 27.42393198455514\n",
      "\n",
      "Processing row 76...\n",
      "Reference Text: Sounds like you have a very responsible young lady growing up.\n",
      "Output Text:  Oh, I'm so sorry to hear that. I hope you have a good time. \n",
      "Token Probabilities: [0.0006960050668567419]\n",
      "Sentence Perplexity for row 76: 1436.771149549446\n",
      "\n",
      "Processing row 77...\n",
      "Reference Text: ah you used her. You should have filled. But however she will understand\n",
      "Output Text:  That's terrible. I hope you didn't get it. \n",
      "Token Probabilities: [0.011582444421947002]\n",
      "Sentence Perplexity for row 77: 86.33756084381889\n",
      "\n",
      "Processing row 78...\n",
      "Reference Text: I gave him some Tylenol, and we ended up snuggling til he could go back to sleep.  \n",
      "Output Text:  I am not sure if I will be able to find a new one. \n",
      "Token Probabilities: [0.2802286148071289]\n",
      "Sentence Perplexity for row 78: 3.5685149451574154\n",
      "\n",
      "Processing row 79...\n",
      "Reference Text: It was a hand written note from my dead mother. I never had read or seen it before. \n",
      "Output Text:  I was in a rush. I was so embarrassed at work. \n",
      "Token Probabilities: [0.06950636208057404]\n",
      "Sentence Perplexity for row 79: 14.387172196420922\n",
      "\n",
      "Processing row 80...\n",
      "Reference Text: Ouch, I hope you don't either. I'd keep any eye out at work from now on.\n",
      "Output Text:  I am sorry to hear that. \n",
      "Token Probabilities: [0.14458264410495758]\n",
      "Sentence Perplexity for row 80: 6.916459483712756\n",
      "\n",
      "Processing row 81...\n",
      "Reference Text: I hope both our ego and your nose heal up quickly!\n",
      "Output Text:  That's really gross! \n",
      "Token Probabilities: [0.015847666189074516]\n",
      "Sentence Perplexity for row 81: 63.100773834408926\n",
      "\n",
      "Processing row 82...\n",
      "Reference Text: Yeah I would go off with my friends and have adventures. I miss that so much.\n",
      "Output Text:  I know, it is so sweet, and it is a lot of joy and joy! \n",
      "Token Probabilities: [0.15740641951560974]\n",
      "Sentence Perplexity for row 82: 6.352981047897043\n",
      "\n",
      "Processing row 83...\n",
      "Reference Text: a bearded dragon\n",
      "Output Text:  She was a bearded dragon \n",
      "Token Probabilities: [0.0003666941192932427]\n",
      "Sentence Perplexity for row 83: 2727.068549469447\n",
      "\n",
      "Processing row 84...\n",
      "Reference Text: I don't know yet. Kinda need some time to process this.\n",
      "Output Text:  I am so sorry. \n",
      "Token Probabilities: [0.13609109818935394]\n",
      "Sentence Perplexity for row 84: 7.348019182038076\n",
      "\n",
      "Processing row 85...\n",
      "Reference Text: It feels so good to update/upgrade, doesn't it? I feel like I have been out of the loop for too long.\n",
      "Output Text:  I am so sorry to hear that.  I hope you get a good service to you! \n",
      "Token Probabilities: [0.08394920080900192]\n",
      "Sentence Perplexity for row 85: 11.911965693100077\n",
      "\n",
      "Processing row 86...\n",
      "Reference Text: Yeah it hurt and I was listening to music so I might have yelled a cuss word loudly.\n",
      "Output Text:  it was. I was so embarrassed. \n",
      "Token Probabilities: [0.0004580052336677909]\n",
      "Sentence Perplexity for row 86: 2183.3811635553047\n",
      "\n",
      "Processing row 87...\n",
      "Reference Text: I cannot imagine anyone wanting to drink that without losing a bet\n",
      "Output Text:  Yeah, I was so upset.  I was so upset and embarrassed. \n",
      "Token Probabilities: [0.00020097150991205126]\n",
      "Sentence Perplexity for row 87: 4975.829660819176\n",
      "\n",
      "Processing row 88...\n",
      "Reference Text: Im taking your advice and putting it into practice tomorrow!\n",
      "Output Text:  I'm really glad you have a good time! \n",
      "Token Probabilities: [0.13313649594783783]\n",
      "Sentence Perplexity for row 88: 7.511088472628833\n",
      "\n",
      "Processing row 89...\n",
      "Reference Text: Thank you, the bracelet means a lot to me\n",
      "Output Text:  I hope I'll be okay for it. \n",
      "Token Probabilities: [0.13143989443778992]\n",
      "Sentence Perplexity for row 89: 7.608040194168725\n",
      "\n",
      "Processing row 90...\n",
      "Reference Text: How terrible! I'm so sorry that happened. How long ago was it?\n",
      "Output Text:  I know that feeling.  It was the first time I had no idea. \n",
      "Token Probabilities: [0.23822398483753204]\n",
      "Sentence Perplexity for row 90: 4.197730134864449\n",
      "\n",
      "Processing row 91...\n",
      "Reference Text: That's awesome! It really pays not to burn bridges, you never know when someone from your past can help you out like that.\n",
      "Output Text:  Thats amazing, did you get a new job? \n",
      "Token Probabilities: [0.015864573419094086]\n",
      "Sentence Perplexity for row 91: 63.03352593120673\n",
      "\n",
      "Processing row 92...\n",
      "Reference Text: What did you eat?\n",
      "Output Text:  I did, but I'm going to see a lot of fun. I'm excited about to see the new restaurant on my way to dinner with my wife. \n",
      "Token Probabilities: [0.29723966121673584]\n",
      "Sentence Perplexity for row 92: 3.364288587554398\n",
      "\n",
      "Processing row 93...\n",
      "Reference Text: wow good for you man\n",
      "Output Text:  I do too, I will try to get a decent meal. \n",
      "Token Probabilities: [0.21307635307312012]\n",
      "Sentence Perplexity for row 93: 4.6931533489163675\n",
      "\n",
      "Processing row 94...\n",
      "Reference Text: Investigate that right now! You need to know\n",
      "Output Text:  I'm so sorry. \n",
      "Token Probabilities: [0.12103016674518585]\n",
      "Sentence Perplexity for row 94: 8.262402894192299\n",
      "\n",
      "Processing row 95...\n",
      "Reference Text: That's really special, and a great attitude to have\n",
      "Output Text:  I'm sure you are right. \n",
      "Token Probabilities: [0.13478051126003265]\n",
      "Sentence Perplexity for row 95: 7.4194702976804665\n",
      "\n",
      "Processing row 96...\n",
      "Reference Text: I've never watched a single full star wars movie, just bits and pieces haha\n",
      "Output Text:  I love that, but I have a good time.  I have never been there for that. \n",
      "Token Probabilities: [0.37088674306869507]\n",
      "Sentence Perplexity for row 96: 2.696240884012351\n",
      "\n",
      "Processing row 97...\n",
      "Reference Text: Me too! It seems like such a huge accomplishment at the time, doesn't it?\n",
      "Output Text:  That is great.  I bet you were prepared for it.  I hope you get the job. \n",
      "Token Probabilities: [0.02074703946709633]\n",
      "Sentence Perplexity for row 97: 48.19964803103331\n",
      "\n",
      "Processing row 98...\n",
      "Reference Text: That's great! good luck\n",
      "Output Text:  I am sure you will be fine soon! \n",
      "Token Probabilities: [0.09248042851686478]\n",
      "Sentence Perplexity for row 98: 10.813098685173584\n",
      "\n",
      "Processing row 99...\n",
      "Reference Text: No not at all. I just got up and couldnt stop laughing at myself. I could feel the heat coming off of my face.\n",
      "Output Text:  No, I just had to get a foot outside and then I got a foot steps and the teacher had a huge speech and the teacher had a huge speech. \n",
      "Token Probabilities: [0.002628107788041234]\n",
      "Sentence Perplexity for row 99: 380.5018974299051\n",
      "Completed token-based perplexity calculations for column: new_label_withcontext\n",
      "Average Perplexity for withcontext: 511.2836617769946\n",
      "new_label_gpt_withoutemotion\n",
      "Calculating token-based perplexity for column: new_label_gpt_withoutemotion\n",
      "\n",
      "Processing row 0...\n",
      "Reference Text: Should have grabbed the gun.\n",
      "Output Text:  That sounds like a surprising moment! Did you find out who did it? \n",
      "Token Probabilities: [0.005691718775779009]\n",
      "Sentence Perplexity for row 0: 175.69385266459037\n",
      "\n",
      "Processing row 1...\n",
      "Reference Text: Thank you!  It was so nice, I had no idea it was happening.  They're not usually so good with secrets haha\n",
      "Output Text:  Thank you! How can I assist you today? \n",
      "Token Probabilities: [0.000391823094105348]\n",
      "Sentence Perplexity for row 1: 2552.1721793436045\n",
      "\n",
      "Processing row 2...\n",
      "Reference Text: I do!  I'm feeling very optimistic about it\n",
      "Output Text:  Thank you! I'm here to assist you with any questions you have. \n",
      "Token Probabilities: [0.0007565432460978627]\n",
      "Sentence Perplexity for row 2: 1321.8015032952194\n",
      "\n",
      "Processing row 3...\n",
      "Reference Text: It was a medium amount of money but still, he did me so dirty.\n",
      "Output Text:  No, he's just a bit mad about it. \n",
      "Token Probabilities: [0.001979461405426264]\n",
      "Sentence Perplexity for row 3: 505.1879249874318\n",
      "\n",
      "Processing row 4...\n",
      "Reference Text: Well, I started walking much faster. It looked like they were carrying a weapon or something.\n",
      "Output Text:  I'm here to help! What happened? \n",
      "Token Probabilities: [0.1752871572971344]\n",
      "Sentence Perplexity for row 4: 5.704924510270143\n",
      "\n",
      "Processing row 5...\n",
      "Reference Text: I had braces growing up too, the worst part for me was the molding!\n",
      "Output Text:  It's natural to feel anxious. Focus on your health and strength and growth. \n",
      "Token Probabilities: [0.014637883752584457]\n",
      "Sentence Perplexity for row 5: 68.31588615556811\n",
      "\n",
      "Processing row 6...\n",
      "Reference Text: Yes, and it really sucks if you forget something important.\n",
      "Output Text:  That's great to hear! Embrace your passions and stay positive. \n",
      "Token Probabilities: [0.0034232023172080517]\n",
      "Sentence Perplexity for row 6: 292.1241303714691\n",
      "\n",
      "Processing row 7...\n",
      "Reference Text: O no! That's a terrible thing to have happen or see.\n",
      "Output Text:  That sounds really frustrating! It's tough when someone you care. \n",
      "Token Probabilities: [0.0009691283921711147]\n",
      "Sentence Perplexity for row 7: 1031.855023625636\n",
      "\n",
      "Processing row 8...\n",
      "Reference Text: Wow, that is so disgusting.\n",
      "Output Text:  That's awesome! It is a great way to get the peace. \n",
      "Token Probabilities: [0.002903820713981986]\n",
      "Sentence Perplexity for row 8: 344.3738778998888\n",
      "\n",
      "Processing row 9...\n",
      "Reference Text: Wow.Really? What kind?\n",
      "Output Text:  That's exciting! What kind of car is it? \n",
      "Token Probabilities: [0.01860170252621174]\n",
      "Sentence Perplexity for row 9: 53.75852014571762\n",
      "\n",
      "Processing row 10...\n",
      "Reference Text: Omg my current dog does that sometimes. She pukes up bile if she doesn't eat, so I always have to make sure she is eating her food.\n",
      "Output Text:  It's frustrating when pets aren’t in a rush. Stay safe! \n",
      "Token Probabilities: [0.013586039654910564]\n",
      "Sentence Perplexity for row 10: 73.6049669661135\n",
      "\n",
      "Processing row 11...\n",
      "Reference Text: That's amazing, It's always nice to get on with your family! Have you always got on with them? \n",
      "Output Text:  That's wonderful! Family time is important. \n",
      "Token Probabilities: [0.011671102605760098]\n",
      "Sentence Perplexity for row 11: 85.68170752834143\n",
      "\n",
      "Processing row 12...\n",
      "Reference Text: I am not sure as I could not stop because of all the traffic.\n",
      "Output Text:  Yes, he was just a little bit. \n",
      "Token Probabilities: [0.0010525330435484648]\n",
      "Sentence Perplexity for row 12: 950.0889365227364\n",
      "\n",
      "Processing row 13...\n",
      "Reference Text: I can barely walk much less imagine that.\n",
      "Output Text:  That's great! He's a great athlete! What made it special? \n",
      "Token Probabilities: [0.01819853112101555]\n",
      "Sentence Perplexity for row 13: 54.94948978850311\n",
      "\n",
      "Processing row 14...\n",
      "Reference Text: Oh for sure! I love riding jet skis!\n",
      "Output Text:  That sounds fun! A fun activities are always fun! \n",
      "Token Probabilities: [0.004638334270566702]\n",
      "Sentence Perplexity for row 14: 215.59463843424598\n",
      "\n",
      "Processing row 15...\n",
      "Reference Text: I feel like this is me. I'm clean, but I'm stuck with a dirty roommate who doesn't do dishes. And I also live in a place that is old and looks terrible to begin with. Sorry you have to deal with that, because I know I hate living in it!\n",
      "Output Text:  That sounds really frustrating! It's tough when kids act alone. \n",
      "Token Probabilities: [0.0009182165958918631]\n",
      "Sentence Perplexity for row 15: 1089.0676605868798\n",
      "\n",
      "Processing row 16...\n",
      "Reference Text: You can get a adviser\n",
      "Output Text:  It can be overwhelming; it can be tough to handle. \n",
      "Token Probabilities: [0.00560347456485033]\n",
      "Sentence Perplexity for row 16: 178.46070120007937\n",
      "\n",
      "Processing row 17...\n",
      "Reference Text: Yeah, Medical emergency. I borrowed $5000. Hope I'll repay this month.\n",
      "Output Text:  I'm here to help! What would you like to discuss? \n",
      "Token Probabilities: [0.019543016329407692]\n",
      "Sentence Perplexity for row 17: 51.1691738442255\n",
      "\n",
      "Processing row 18...\n",
      "Reference Text: You shouldn't let those kind of people upset you.\n",
      "Output Text:  It's tough to feel that way. Consider talking to her about it. \n",
      "Token Probabilities: [0.022039609029889107]\n",
      "Sentence Perplexity for row 18: 45.372855691035426\n",
      "\n",
      "Processing row 19...\n",
      "Reference Text: Oh no! He doesn't seem like such a good friend then. I hate it when friends pull stuff like that!\n",
      "Output Text:  That's great! Kindness often takes time. \n",
      "Token Probabilities: [0.006782714743167162]\n",
      "Sentence Perplexity for row 19: 147.43359228064105\n",
      "\n",
      "Processing row 20...\n",
      "Reference Text: Ohh you have a really good memory. I am very bad at remembering things, lol.\n",
      "Output Text:  That sounds like a great idea! Nature is a great experience. \n",
      "Token Probabilities: [0.0025803777389228344]\n",
      "Sentence Perplexity for row 20: 387.5401593014225\n",
      "\n",
      "Processing row 21...\n",
      "Reference Text: I wish i could make that type of money!\n",
      "Output Text:  It's tough when friends aren't available. Stay positive! \n",
      "Token Probabilities: [0.020145291462540627]\n",
      "Sentence Perplexity for row 21: 49.6393910139975\n",
      "\n",
      "Processing row 22...\n",
      "Reference Text: I thought we had a ghost for a long time\n",
      "Output Text:  Yes, I was just so mad. I was just so happy to get it. \n",
      "Token Probabilities: [0.00018283278041053563]\n",
      "Sentence Perplexity for row 22: 5469.478710297923\n",
      "\n",
      "Processing row 23...\n",
      "Reference Text: this is true.\n",
      "Output Text:  It was a good time. I was so happy to see my dad. \n",
      "Token Probabilities: [0.09640278667211533]\n",
      "Sentence Perplexity for row 23: 10.373144122910006\n",
      "\n",
      "Processing row 24...\n",
      "Reference Text: I get you, I've been in your situation before\n",
      "Output Text:  I'm glad you're doing well! Keep it up! \n",
      "Token Probabilities: [0.14439985156059265]\n",
      "Sentence Perplexity for row 24: 6.925214875171688\n",
      "\n",
      "Processing row 25...\n",
      "Reference Text: I see that more in the country I guess. That would be horrifying. But maybe he is just immune to pain?\n",
      "Output Text:  It's tough to be away. Try to stay down and move forward. \n",
      "Token Probabilities: [0.06972264498472214]\n",
      "Sentence Perplexity for row 25: 14.342542515693765\n",
      "\n",
      "Processing row 26...\n",
      "Reference Text: Can you tell me the name of the book? I find myself being engaged by a lot of novels these days.\n",
      "Output Text:  It's understandable to feel scared. Take a deep breath! \n",
      "Token Probabilities: [0.026688946411013603]\n",
      "Sentence Perplexity for row 26: 37.46869526431866\n",
      "\n",
      "Processing row 27...\n",
      "Reference Text: Wow how exciting, has he been practicing a lot? \n",
      "Output Text:  That's great! The Eagles won the game! \n",
      "Token Probabilities: [0.008284504525363445]\n",
      "Sentence Perplexity for row 27: 120.70727910624564\n",
      "\n",
      "Processing row 28...\n",
      "Reference Text: yea i was very happy he helped me\n",
      "Output Text:  It's tough when expectations aren't met. Stay positive! \n",
      "Token Probabilities: [0.015057033859193325]\n",
      "Sentence Perplexity for row 28: 66.41414300794928\n",
      "\n",
      "Processing row 29...\n",
      "Reference Text: They wer really nice and trustworthy. I even let them use my wifi password.\n",
      "Output Text:  I'm here to help. What would you like to talk about? \n",
      "Token Probabilities: [0.03184628486633301]\n",
      "Sentence Perplexity for row 29: 31.400836995500583\n",
      "\n",
      "Processing row 30...\n",
      "Reference Text: Or it could be you and a dope house party\n",
      "Output Text:  I'm glad you're eating it! A fresh room can be tough. \n",
      "Token Probabilities: [0.07108521461486816]\n",
      "Sentence Perplexity for row 30: 14.06762299893008\n",
      "\n",
      "Processing row 31...\n",
      "Reference Text: Yeah it might be a good idea to tell him. But you may want to have the money to give back to him first. \n",
      "Output Text:  That's a nice gesture! It's a special gift and thoughtful gesture. \n",
      "Token Probabilities: [0.004124275874346495]\n",
      "Sentence Perplexity for row 31: 242.4668064083985\n",
      "\n",
      "Processing row 32...\n",
      "Reference Text: What did you do with them?\n",
      "Output Text:  That's wonderful! Family time is important. Cherish those memories! \n",
      "Token Probabilities: [0.0033656656742095947]\n",
      "Sentence Perplexity for row 32: 297.11804344168655\n",
      "\n",
      "Processing row 33...\n",
      "Reference Text: Congrats!!\n",
      "Output Text:  That's great! Your hard work will pay off. \n",
      "Token Probabilities: [0.014456977136433125]\n",
      "Sentence Perplexity for row 33: 69.17075337138728\n",
      "\n",
      "Processing row 34...\n",
      "Reference Text: what was on it\n",
      "Output Text:  That sounds delicious! What toppings did you enjoy? \n",
      "Token Probabilities: [0.0036906565073877573]\n",
      "Sentence Perplexity for row 34: 270.9545030804829\n",
      "\n",
      "Processing row 35...\n",
      "Reference Text: I am so ready for it!\n",
      "Output Text:  I hope it went well for you! How can I assist you today? \n",
      "Token Probabilities: [0.01631835661828518]\n",
      "Sentence Perplexity for row 35: 61.2806806096805\n",
      "\n",
      "Processing row 36...\n",
      "Reference Text: I am going to be a birthday clown.\n",
      "Output Text:  I'm not sure. I've been working really hard on it. \n",
      "Token Probabilities: [0.37420231103897095]\n",
      "Sentence Perplexity for row 36: 2.6723512135013405\n",
      "\n",
      "Processing row 37...\n",
      "Reference Text: She was 23 years old. I got her when I was 5.\n",
      "Output Text:  She was a little baby, but I felt so bad. \n",
      "Token Probabilities: [0.17898960411548615]\n",
      "Sentence Perplexity for row 37: 5.586916653297856\n",
      "\n",
      "Processing row 38...\n",
      "Reference Text: This was a few months ago.\n",
      "Output Text:  I'm here for you. How can I help you today? \n",
      "Token Probabilities: [0.03517758846282959]\n",
      "Sentence Perplexity for row 38: 28.427190256564923\n",
      "\n",
      "Processing row 39...\n",
      "Reference Text: It's a band called Say Anything, I've been a fan of theirs since 2006! \n",
      "Output Text:  What about in your style? I'd love to hear more! \n",
      "Token Probabilities: [0.08349645137786865]\n",
      "Sentence Perplexity for row 39: 11.976556889518989\n",
      "\n",
      "Processing row 40...\n",
      "Reference Text: Oh that's a standard prcedure. Have you ever had one?\n",
      "Output Text:  That's quite an experience! Keep it up! \n",
      "Token Probabilities: [0.022802729159593582]\n",
      "Sentence Perplexity for row 40: 43.85439975193843\n",
      "\n",
      "Processing row 41...\n",
      "Reference Text: Have you been before? It seems like such a great way to both play and get a workout \n",
      "Output Text:  I can't believe I have done it. \n",
      "Token Probabilities: [0.36865681409835815]\n",
      "Sentence Perplexity for row 41: 2.7125498885616652\n",
      "\n",
      "Processing row 42...\n",
      "Reference Text: No, I hate being by myself.\n",
      "Output Text:  I did, but I am so glad I did that. \n",
      "Token Probabilities: [0.38038232922554016]\n",
      "Sentence Perplexity for row 42: 2.628933899311263\n",
      "\n",
      "Processing row 43...\n",
      "Reference Text: I could see that happening but sounds like you were super brave.\n",
      "Output Text:  I'm sorry to hear that! It's tough when plans change. \n",
      "Token Probabilities: [0.12216468155384064]\n",
      "Sentence Perplexity for row 43: 8.185671892078549\n",
      "\n",
      "Processing row 44...\n",
      "Reference Text: He's quite the piece of garbage.\n",
      "Output Text:  I'm glad you think so! It's great to have supportive friends. \n",
      "Token Probabilities: [0.236586332321167]\n",
      "Sentence Perplexity for row 44: 4.226786856996014\n",
      "\n",
      "Processing row 45...\n",
      "Reference Text: Tell me about it. How long have you been job hunting for?\n",
      "Output Text:  I'm glad you're feeling better now. I'm here to help! \n",
      "Token Probabilities: [0.04829859361052513]\n",
      "Sentence Perplexity for row 45: 20.704536617854682\n",
      "\n",
      "Processing row 46...\n",
      "Reference Text: That is such a beautiful memory to have. I love that we forever have moments like this... How cool Hong Kong! \n",
      "Output Text:  It is a great experience! The first time I was going to see the movie. \n",
      "Token Probabilities: [0.0797458365559578]\n",
      "Sentence Perplexity for row 46: 12.539839610288599\n",
      "\n",
      "Processing row 47...\n",
      "Reference Text: I think he was slightly over the limit but he had a few drinks earlier, so I felt a bit uncomfortable.\n",
      "Output Text:  I did, but it was a very stressful experience. \n",
      "Token Probabilities: [0.24878185987472534]\n",
      "Sentence Perplexity for row 47: 4.019585674387804\n",
      "\n",
      "Processing row 48...\n",
      "Reference Text: IT is. \n",
      "Output Text:  I'm glad to hear that! What’s on your mind? \n",
      "Token Probabilities: [0.08454643934965134]\n",
      "Sentence Perplexity for row 48: 11.82781921618706\n",
      "\n",
      "Processing row 49...\n",
      "Reference Text: OH that sucks.\n",
      "Output Text:  I'm so sorry to hear that. It's a tough situation. \n",
      "Token Probabilities: [0.2101520150899887]\n",
      "Sentence Perplexity for row 49: 4.758460201163393\n",
      "\n",
      "Processing row 50...\n",
      "Reference Text: thats wonderful\n",
      "Output Text:  That's great! How did you feel about it? \n",
      "Token Probabilities: [0.0018444274319335818]\n",
      "Sentence Perplexity for row 50: 542.173675519271\n",
      "\n",
      "Processing row 51...\n",
      "Reference Text: I've had that feeling as well, especially if it is with someone that is close to me.  Is it because you dont like confrontation or a different reason?\n",
      "Output Text:  It's natural to feel nervous. Trust your instincts and stay positive! \n",
      "Token Probabilities: [0.01483472902327776]\n",
      "Sentence Perplexity for row 51: 67.40938768958033\n",
      "\n",
      "Processing row 52...\n",
      "Reference Text: No they did not. And it is going to cost too much to take them to court. \n",
      "Output Text:  I’m glad to hear that! What else is your favorite part? \n",
      "Token Probabilities: [0.10677986592054367]\n",
      "Sentence Perplexity for row 52: 9.365061394103204\n",
      "\n",
      "Processing row 53...\n",
      "Reference Text: thats good!\n",
      "Output Text:  I'm sure it was a big deal. \n",
      "Token Probabilities: [0.23874785006046295]\n",
      "Sentence Perplexity for row 53: 4.188519392935893\n",
      "\n",
      "Processing row 54...\n",
      "Reference Text: That is so true! \n",
      "Output Text:  That's a beautiful way to stay safe! Stay safe! \n",
      "Token Probabilities: [0.0029576083179563284]\n",
      "Sentence Perplexity for row 54: 338.11103178496194\n",
      "\n",
      "Processing row 55...\n",
      "Reference Text: I sort of have. I worked like crazy to get a work visa for the US, so I could be with the person I wanted to spend my life with. It paid off, so I can kind of understand what you're saying.\n",
      "Output Text:  Yes, I have a supportive family. \n",
      "Token Probabilities: [0.0013389786472544074]\n",
      "Sentence Perplexity for row 55: 746.8378992081108\n",
      "\n",
      "Processing row 56...\n",
      "Reference Text: It sounds like you did great. Studying is the biggest part really.\n",
      "Output Text:  It sounds like a significant milestone. How did you feel about it? \n",
      "Token Probabilities: [0.007305508013814688]\n",
      "Sentence Perplexity for row 56: 136.88302005952278\n",
      "\n",
      "Processing row 57...\n",
      "Reference Text: Don't tell her right after she awakes up. Women are never in the best mood right after waking up.\n",
      "Output Text:  That's great! What did you enjoy most about it? \n",
      "Token Probabilities: [0.0020245404448360205]\n",
      "Sentence Perplexity for row 57: 493.9392554743433\n",
      "\n",
      "Processing row 58...\n",
      "Reference Text: Maybe.\n",
      "Output Text:  It's okay to feel that way; mistakes happen. Stay positive! \n",
      "Token Probabilities: [0.00618382403627038]\n",
      "Sentence Perplexity for row 58: 161.7122340698305\n",
      "\n",
      "Processing row 59...\n",
      "Reference Text: They thought it was a better school, and it probably was, but I didn't feel like it was at the time\n",
      "Output Text:  Yes, I think so. I am so proud of him. \n",
      "Token Probabilities: [0.0016840379685163498]\n",
      "Sentence Perplexity for row 59: 593.810839598235\n",
      "\n",
      "Processing row 60...\n",
      "Reference Text: That's great. I hope you have a wonderful time.\n",
      "Output Text:  I'm sorry to hear that. It's tough when plans change. \n",
      "Token Probabilities: [0.15395495295524597]\n",
      "Sentence Perplexity for row 60: 6.495406486147253\n",
      "\n",
      "Processing row 61...\n",
      "Reference Text: That is bad. What are you planning to do instead?\n",
      "Output Text:  That sounds like a good plan! What was your favorite part? \n",
      "Token Probabilities: [0.003689825301989913]\n",
      "Sentence Perplexity for row 61: 271.0155408877224\n",
      "\n",
      "Processing row 62...\n",
      "Reference Text: A little bit bu, they took the insurance money and bought a big house - i mean BIG! I know they needed more room for my mother to move in, but what they bought was way over and above what was needed.\n",
      "Output Text:  It's important to communicate your feelings, but communication helps. \n",
      "Token Probabilities: [0.027109874412417412]\n",
      "Sentence Perplexity for row 62: 36.88692853338929\n",
      "\n",
      "Processing row 63...\n",
      "Reference Text: Mostly happy. They have annoyed me greatly all summer\n",
      "Output Text:  Yes, I am so happy for him. He's the best! \n",
      "Token Probabilities: [0.0015160476323217154]\n",
      "Sentence Perplexity for row 63: 659.6098820909559\n",
      "\n",
      "Processing row 64...\n",
      "Reference Text: That is really interesting. Still over my head, but you did a decent job of explaining it in layman's terms. I appreciate it. So are you a med student, or what?\n",
      "Output Text:  It's tough; communication can help build communication. \n",
      "Token Probabilities: [0.002188919112086296]\n",
      "Sentence Perplexity for row 64: 456.846483946537\n",
      "\n",
      "Processing row 65...\n",
      "Reference Text: Oh wow! Congratulations! I also recently applied for grad school to study Computer Science (seriously). What are you wanting to study?\n",
      "Output Text:  That's great! What are you studying? \n",
      "Token Probabilities: [0.009343864396214485]\n",
      "Sentence Perplexity for row 65: 107.0221010918281\n",
      "\n",
      "Processing row 66...\n",
      "Reference Text: I'm sure that much be hard to stand by and watch as someone who works hard for their things. \n",
      "Output Text:  That's great! It's great to have supportive friends in life. \n",
      "Token Probabilities: [0.008387207053601742]\n",
      "Sentence Perplexity for row 66: 119.22920152192586\n",
      "\n",
      "Processing row 67...\n",
      "Reference Text: It does get better, but it was just so sudden.\n",
      "Output Text:  It's tough to feel that way. Consider exploring new opportunities. \n",
      "Token Probabilities: [0.00043091241968795657]\n",
      "Sentence Perplexity for row 67: 2320.6571783754703\n",
      "\n",
      "Processing row 68...\n",
      "Reference Text: True, driving takes more focus than a lot of people can handle\n",
      "Output Text:  I understand your frustration; it's frustrating to deal with behavior. \n",
      "Token Probabilities: [0.10242671519517899]\n",
      "Sentence Perplexity for row 68: 9.763077904963101\n",
      "\n",
      "Processing row 69...\n",
      "Reference Text: I have no idea. We found it after she left. It was really gross. I wonder if her house is that nasty?\n",
      "Output Text:  They were so bad \n",
      "Token Probabilities: [0.0018537440337240696]\n",
      "Sentence Perplexity for row 69: 539.4488029671793\n",
      "\n",
      "Processing row 70...\n",
      "Reference Text: That's good, it sounds like his bathroom motivated you to take yours to the next level. That's probably good for society.\n",
      "Output Text:  That sounds like a fun way to feel that way! Enjoy! \n",
      "Token Probabilities: [0.003774882759898901]\n",
      "Sentence Perplexity for row 70: 264.9088895218515\n",
      "\n",
      "Processing row 71...\n",
      "Reference Text: I do look a little like a somewhat taller version of him.\n",
      "Output Text:  Yes, I am so excited! What are you excited about? \n",
      "Token Probabilities: [9.474247781326994e-05]\n",
      "Sentence Perplexity for row 71: 10554.927663713022\n",
      "\n",
      "Processing row 72...\n",
      "Reference Text: Absolutely! Not to mention gardening saves a ton of money in the long run.\n",
      "Output Text:  I have a reliable car. I'm really looking forward to it! \n",
      "Token Probabilities: [0.20598432421684265]\n",
      "Sentence Perplexity for row 72: 4.854738358377629\n",
      "\n",
      "Processing row 73...\n",
      "Reference Text: That's great! Not too many 16 year olds are that responsible.\n",
      "Output Text:  It's tough to see loved ones suffer. Stay strong! \n",
      "Token Probabilities: [0.013285011984407902]\n",
      "Sentence Perplexity for row 73: 75.27279622883746\n",
      "\n",
      "Processing row 74...\n",
      "Reference Text: The prices have risen alot with all the technology and electrical components.\n",
      "Output Text:  I'm sorry to hear that. It's tough when people don't care. \n",
      "Token Probabilities: [0.20789892971515656]\n",
      "Sentence Perplexity for row 74: 4.81002957239898\n",
      "\n",
      "Processing row 75...\n",
      "Reference Text: Does he get anything else?\n",
      "Output Text:  I understand, I hope he can help you with him. \n",
      "Token Probabilities: [0.12277552485466003]\n",
      "Sentence Perplexity for row 75: 8.14494583658906\n",
      "\n",
      "Processing row 76...\n",
      "Reference Text: Sounds like you have a very responsible young lady growing up.\n",
      "Output Text:  It's great to feel prepared! Your support means a lot to her. \n",
      "Token Probabilities: [0.015881244093179703]\n",
      "Sentence Perplexity for row 76: 62.96735911448246\n",
      "\n",
      "Processing row 77...\n",
      "Reference Text: ah you used her. You should have filled. But however she will understand\n",
      "Output Text:  I'm sorry to hear that. It's tough to feel that way. \n",
      "Token Probabilities: [0.2270732969045639]\n",
      "Sentence Perplexity for row 77: 4.403864362881416\n",
      "\n",
      "Processing row 78...\n",
      "Reference Text: I gave him some Tylenol, and we ended up snuggling til he could go back to sleep.  \n",
      "Output Text:  It's tough to be apart. Have you talked to him about it? \n",
      "Token Probabilities: [0.0179677102714777]\n",
      "Sentence Perplexity for row 78: 55.65539430961439\n",
      "\n",
      "Processing row 79...\n",
      "Reference Text: It was a hand written note from my dead mother. I never had read or seen it before. \n",
      "Output Text:  It was a good way to take care of her. \n",
      "Token Probabilities: [0.08433924615383148]\n",
      "Sentence Perplexity for row 79: 11.856876194696346\n",
      "\n",
      "Processing row 80...\n",
      "Reference Text: Ouch, I hope you don't either. I'd keep any eye out at work from now on.\n",
      "Output Text:  It's tough to feel that way. Try to stay safe. \n",
      "Token Probabilities: [0.007110604550689459]\n",
      "Sentence Perplexity for row 80: 140.6350181438564\n",
      "\n",
      "Processing row 81...\n",
      "Reference Text: I hope both our ego and your nose heal up quickly!\n",
      "Output Text:  I'm sorry to hear that! It's tough to see loved ones suffer. \n",
      "Token Probabilities: [0.044186294078826904]\n",
      "Sentence Perplexity for row 81: 22.63145214703982\n",
      "\n",
      "Processing row 82...\n",
      "Reference Text: Yeah I would go off with my friends and have adventures. I miss that so much.\n",
      "Output Text:  That's a beautiful memory! Cherish those moments together. \n",
      "Token Probabilities: [0.0058738416992127895]\n",
      "Sentence Perplexity for row 82: 170.24633131226872\n",
      "\n",
      "Processing row 83...\n",
      "Reference Text: a bearded dragon\n",
      "Output Text:  What kind of pet is it? I'm here to help! \n",
      "Token Probabilities: [0.04165605455636978]\n",
      "Sentence Perplexity for row 83: 24.006114132743434\n",
      "\n",
      "Processing row 84...\n",
      "Reference Text: I don't know yet. Kinda need some time to process this.\n",
      "Output Text:  No, I don't know it is much of a kid. \n",
      "Token Probabilities: [0.0022269056644290686]\n",
      "Sentence Perplexity for row 84: 449.0535975426595\n",
      "\n",
      "Processing row 85...\n",
      "Reference Text: It feels so good to update/upgrade, doesn't it? I feel like I have been out of the loop for too long.\n",
      "Output Text:  I'm really sorry to hear that. It's tough to feel that way. \n",
      "Token Probabilities: [0.21209579706192017]\n",
      "Sentence Perplexity for row 85: 4.714850618694984\n",
      "\n",
      "Processing row 86...\n",
      "Reference Text: Yeah it hurt and I was listening to music so I might have yelled a cuss word loudly.\n",
      "Output Text:  No, it was a very bad experience. \n",
      "Token Probabilities: [0.003482130588963628]\n",
      "Sentence Perplexity for row 86: 287.1804989650391\n",
      "\n",
      "Processing row 87...\n",
      "Reference Text: I cannot imagine anyone wanting to drink that without losing a bet\n",
      "Output Text:  I'm sorry to hear that! It's important to talk about such behavior. \n",
      "Token Probabilities: [0.04610974341630936]\n",
      "Sentence Perplexity for row 87: 21.687390254405372\n",
      "\n",
      "Processing row 88...\n",
      "Reference Text: Im taking your advice and putting it into practice tomorrow!\n",
      "Output Text:  Absolutely! It's wonderful to have supportive friends in life! \n",
      "Token Probabilities: [0.0005389598663896322]\n",
      "Sentence Perplexity for row 88: 1855.4257234379427\n",
      "\n",
      "Processing row 89...\n",
      "Reference Text: Thank you, the bracelet means a lot to me\n",
      "Output Text:  It's tough when others don't have a value! \n",
      "Token Probabilities: [0.02851494401693344]\n",
      "Sentence Perplexity for row 89: 35.06933064312367\n",
      "\n",
      "Processing row 90...\n",
      "Reference Text: How terrible! I'm so sorry that happened. How long ago was it?\n",
      "Output Text:  It's tough when plans change; it can be tough. \n",
      "Token Probabilities: [0.004720320459455252]\n",
      "Sentence Perplexity for row 90: 211.85002344425686\n",
      "\n",
      "Processing row 91...\n",
      "Reference Text: That's awesome! It really pays not to burn bridges, you never know when someone from your past can help you out like that.\n",
      "Output Text:  That's awesome! What kind of card did you get? \n",
      "Token Probabilities: [0.0073279510252177715]\n",
      "Sentence Perplexity for row 91: 136.4637941163481\n",
      "\n",
      "Processing row 92...\n",
      "Reference Text: What did you eat?\n",
      "Output Text:  That sounds lovely! A thoughtful gesture to have a strong connection. \n",
      "Token Probabilities: [0.006983731873333454]\n",
      "Sentence Perplexity for row 92: 143.18991881953266\n",
      "\n",
      "Processing row 93...\n",
      "Reference Text: wow good for you man\n",
      "Output Text:  That's great! What was your favorite game? \n",
      "Token Probabilities: [0.0023288452066481113]\n",
      "Sentence Perplexity for row 93: 429.39736704926463\n",
      "\n",
      "Processing row 94...\n",
      "Reference Text: Investigate that right now! You need to know\n",
      "Output Text:  It's normal to feel nervous! Trust your instincts. \n",
      "Token Probabilities: [0.028497423976659775]\n",
      "Sentence Perplexity for row 94: 35.09089105103077\n",
      "\n",
      "Processing row 95...\n",
      "Reference Text: That's really special, and a great attitude to have\n",
      "Output Text:  Yes, he's just a good name. \n",
      "Token Probabilities: [0.0014742952771484852]\n",
      "Sentence Perplexity for row 95: 678.2901739563014\n",
      "\n",
      "Processing row 96...\n",
      "Reference Text: I've never watched a single full star wars movie, just bits and pieces haha\n",
      "Output Text:  I think I will be a good one! \n",
      "Token Probabilities: [0.31324273347854614]\n",
      "Sentence Perplexity for row 96: 3.1924124428842964\n",
      "\n",
      "Processing row 97...\n",
      "Reference Text: Me too! It seems like such a huge accomplishment at the time, doesn't it?\n",
      "Output Text:  That's wonderful! Congratulations on your graduation! 🎉 \n",
      "Token Probabilities: [0.02894403785467148]\n",
      "Sentence Perplexity for row 97: 34.54942966219908\n",
      "\n",
      "Processing row 98...\n",
      "Reference Text: That's great! good luck\n",
      "Output Text:  That's fantastic! Your hard work will surely pay off! \n",
      "Token Probabilities: [0.005047654267400503]\n",
      "Sentence Perplexity for row 98: 198.111825221142\n",
      "\n",
      "Processing row 99...\n",
      "Reference Text: No not at all. I just got up and couldnt stop laughing at myself. I could feel the heat coming off of my face.\n",
      "Output Text:  No, I didn't. I was so upset. \n",
      "Token Probabilities: [0.0031543797813355923]\n",
      "Sentence Perplexity for row 99: 317.0195313566813\n",
      "Completed token-based perplexity calculations for column: new_label_gpt_withoutemotion\n",
      "Average Perplexity for gpt_withoutemotion: 404.2289543040273\n",
      "new_label_gpt_blocksize_256\n",
      "Calculating token-based perplexity for column: new_label_gpt_blocksize_256\n",
      "\n",
      "Processing row 0...\n",
      "Reference Text: Should have grabbed the gun.\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 0: 15.56259441258386\n",
      "\n",
      "Processing row 1...\n",
      "Reference Text: Thank you!  It was so nice, I had no idea it was happening.  They're not usually so good with secrets haha\n",
      "Output Text:  That was very nice of them. \n",
      "Token Probabilities: [0.01958432048559189]\n",
      "Sentence Perplexity for row 1: 51.06125590294012\n",
      "\n",
      "Processing row 2...\n",
      "Reference Text: I do!  I'm feeling very optimistic about it\n",
      "Output Text:  I did and I was so proud of myself for my job. \n",
      "Token Probabilities: [0.3962172567844391]\n",
      "Sentence Perplexity for row 2: 2.52386786006155\n",
      "\n",
      "Processing row 3...\n",
      "Reference Text: It was a medium amount of money but still, he did me so dirty.\n",
      "Output Text:  Yes, he had a lot of money. \n",
      "Token Probabilities: [0.00040748590254224837]\n",
      "Sentence Perplexity for row 3: 2454.0726286753434\n",
      "\n",
      "Processing row 4...\n",
      "Reference Text: Well, I started walking much faster. It looked like they were carrying a weapon or something.\n",
      "Output Text:  I'm here to listen. What happened? \n",
      "Token Probabilities: [0.041594281792640686]\n",
      "Sentence Perplexity for row 4: 24.041766245304686\n",
      "\n",
      "Processing row 5...\n",
      "Reference Text: I had braces growing up too, the worst part for me was the molding!\n",
      "Output Text:  I am so glad to hear that! \n",
      "Token Probabilities: [0.13962969183921814]\n",
      "Sentence Perplexity for row 5: 7.161800522710368\n",
      "\n",
      "Processing row 6...\n",
      "Reference Text: Yes, and it really sucks if you forget something important.\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 6: 15.56259441258386\n",
      "\n",
      "Processing row 7...\n",
      "Reference Text: O no! That's a terrible thing to have happen or see.\n",
      "Output Text:  That's a bummer! Did you find out? \n",
      "Token Probabilities: [0.019144130870699883]\n",
      "Sentence Perplexity for row 7: 52.235330334609294\n",
      "\n",
      "Processing row 8...\n",
      "Reference Text: Wow, that is so disgusting.\n",
      "Output Text:  That sounds intriguing! What did you enjoy most about it? \n",
      "Token Probabilities: [0.0009854075033217669]\n",
      "Sentence Perplexity for row 8: 1014.8085909931096\n",
      "\n",
      "Processing row 9...\n",
      "Reference Text: Wow.Really? What kind?\n",
      "Output Text:  That sounds exciting! What kind of car did you get? \n",
      "Token Probabilities: [0.0021100956946611404]\n",
      "Sentence Perplexity for row 9: 473.91215598901516\n",
      "\n",
      "Processing row 10...\n",
      "Reference Text: Omg my current dog does that sometimes. She pukes up bile if she doesn't eat, so I always have to make sure she is eating her food.\n",
      "Output Text:  Yes, I don't have a dog to do that. \n",
      "Token Probabilities: [0.0009002767619676888]\n",
      "Sentence Perplexity for row 10: 1110.7695347088054\n",
      "\n",
      "Processing row 11...\n",
      "Reference Text: That's amazing, It's always nice to get on with your family! Have you always got on with them? \n",
      "Output Text:  That's great! Family is truly a great life. \n",
      "Token Probabilities: [0.007205856032669544]\n",
      "Sentence Perplexity for row 11: 138.77601709862793\n",
      "\n",
      "Processing row 12...\n",
      "Reference Text: I am not sure as I could not stop because of all the traffic.\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 12: 15.56259441258386\n",
      "\n",
      "Processing row 13...\n",
      "Reference Text: I can barely walk much less imagine that.\n",
      "Output Text:  That's awesome!  He must have been really talented.  \n",
      "Token Probabilities: [0.01981767825782299]\n",
      "Sentence Perplexity for row 13: 50.4599977348634\n",
      "\n",
      "Processing row 14...\n",
      "Reference Text: Oh for sure! I love riding jet skis!\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 14: 15.56259441258386\n",
      "\n",
      "Processing row 15...\n",
      "Reference Text: I feel like this is me. I'm clean, but I'm stuck with a dirty roommate who doesn't do dishes. And I also live in a place that is old and looks terrible to begin with. Sorry you have to deal with that, because I know I hate living in it!\n",
      "Output Text:  That sounds really frustrating! It's tough to see loved ones hurt. \n",
      "Token Probabilities: [5.556008545681834e-05]\n",
      "Sentence Perplexity for row 15: 17998.532431653763\n",
      "\n",
      "Processing row 16...\n",
      "Reference Text: You can get a adviser\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 16: 15.56259441258386\n",
      "\n",
      "Processing row 17...\n",
      "Reference Text: Yeah, Medical emergency. I borrowed $5000. Hope I'll repay this month.\n",
      "Output Text:  I’m here to help! What do you need assistance with? \n",
      "Token Probabilities: [0.0033321408554911613]\n",
      "Sentence Perplexity for row 17: 300.10736141362753\n",
      "\n",
      "Processing row 18...\n",
      "Reference Text: You shouldn't let those kind of people upset you.\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 18: 15.56259441258386\n",
      "\n",
      "Processing row 19...\n",
      "Reference Text: Oh no! He doesn't seem like such a good friend then. I hate it when friends pull stuff like that!\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 19: 15.56259441258386\n",
      "\n",
      "Processing row 20...\n",
      "Reference Text: Ohh you have a really good memory. I am very bad at remembering things, lol.\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 20: 15.56259441258386\n",
      "\n",
      "Processing row 21...\n",
      "Reference Text: I wish i could make that type of money!\n",
      "Output Text:  It's tough to see others succeed! Remember, you'll be honest! \n",
      "Token Probabilities: [0.0010236866073682904]\n",
      "Sentence Perplexity for row 21: 976.8614660016077\n",
      "\n",
      "Processing row 22...\n",
      "Reference Text: I thought we had a ghost for a long time\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 22: 15.56259441258386\n",
      "\n",
      "Processing row 23...\n",
      "Reference Text: this is true.\n",
      "Output Text:  I agree, they are so lucky \n",
      "Token Probabilities: [0.007922942750155926]\n",
      "Sentence Perplexity for row 23: 126.21572962651027\n",
      "\n",
      "Processing row 24...\n",
      "Reference Text: I get you, I've been in your situation before\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 24: 15.56259441258386\n",
      "\n",
      "Processing row 25...\n",
      "Reference Text: I see that more in the country I guess. That would be horrifying. But maybe he is just immune to pain?\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 25: 15.56259441258386\n",
      "\n",
      "Processing row 26...\n",
      "Reference Text: Can you tell me the name of the book? I find myself being engaged by a lot of novels these days.\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 26: 15.56259441258386\n",
      "\n",
      "Processing row 27...\n",
      "Reference Text: Wow how exciting, has he been practicing a lot? \n",
      "Output Text:  That's great! Enjoy your new semester together! \n",
      "Token Probabilities: [0.030066071078181267]\n",
      "Sentence Perplexity for row 27: 33.26008234995801\n",
      "\n",
      "Processing row 28...\n",
      "Reference Text: yea i was very happy he helped me\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 28: 15.56259441258386\n",
      "\n",
      "Processing row 29...\n",
      "Reference Text: They wer really nice and trustworthy. I even let them use my wifi password.\n",
      "Output Text:  I didn't know how. I was really upset with myself. \n",
      "Token Probabilities: [0.24088497459888458]\n",
      "Sentence Perplexity for row 29: 4.151358969836845\n",
      "\n",
      "Processing row 30...\n",
      "Reference Text: Or it could be you and a dope house party\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 30: 15.56259441258386\n",
      "\n",
      "Processing row 31...\n",
      "Reference Text: Yeah it might be a good idea to tell him. But you may want to have the money to give back to him first. \n",
      "Output Text:  That's a nice surprise! It's great you can help them grow. \n",
      "Token Probabilities: [0.0028923049103468657]\n",
      "Sentence Perplexity for row 31: 345.74501340526814\n",
      "\n",
      "Processing row 32...\n",
      "Reference Text: What did you do with them?\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 32: 15.56259441258386\n",
      "\n",
      "Processing row 33...\n",
      "Reference Text: Congrats!!\n",
      "Output Text:  I understand! It’s tough to lose a job. \n",
      "Token Probabilities: [0.09985863417387009]\n",
      "Sentence Perplexity for row 33: 10.014156595200749\n",
      "\n",
      "Processing row 34...\n",
      "Reference Text: what was on it\n",
      "Output Text:  That sounds delicious! What toppings did you use? \n",
      "Token Probabilities: [0.0003997102321591228]\n",
      "Sentence Perplexity for row 34: 2501.8123619159796\n",
      "\n",
      "Processing row 35...\n",
      "Reference Text: I am so ready for it!\n",
      "Output Text:  Oh, I'm glad you have a great experience. What happened? \n",
      "Token Probabilities: [0.0045723747462034225]\n",
      "Sentence Perplexity for row 35: 218.70473342770714\n",
      "\n",
      "Processing row 36...\n",
      "Reference Text: I am going to be a birthday clown.\n",
      "Output Text:  It's great to hear you're happy! What job are you referring to? \n",
      "Token Probabilities: [0.0006398961995728314]\n",
      "Sentence Perplexity for row 36: 1562.7534601198743\n",
      "\n",
      "Processing row 37...\n",
      "Reference Text: She was 23 years old. I got her when I was 5.\n",
      "Output Text:  She was really sick and we had to go to the party.  \n",
      "Token Probabilities: [0.13758958876132965]\n",
      "Sentence Perplexity for row 37: 7.267991779048444\n",
      "\n",
      "Processing row 38...\n",
      "Reference Text: This was a few months ago.\n",
      "Output Text:  I'm here for you. How can I assist you today? \n",
      "Token Probabilities: [0.010445651598274708]\n",
      "Sentence Perplexity for row 38: 95.73361609774236\n",
      "\n",
      "Processing row 39...\n",
      "Reference Text: It's a band called Say Anything, I've been a fan of theirs since 2006! \n",
      "Output Text:  I can't believe that. I love the kiddo are you! \n",
      "Token Probabilities: [0.18934457004070282]\n",
      "Sentence Perplexity for row 39: 5.281376697441248\n",
      "\n",
      "Processing row 40...\n",
      "Reference Text: Oh that's a standard prcedure. Have you ever had one?\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 40: 15.56259441258386\n",
      "\n",
      "Processing row 41...\n",
      "Reference Text: Have you been before? It seems like such a great way to both play and get a workout \n",
      "Output Text:  It's great to hear you have a great job! \n",
      "Token Probabilities: [0.03541596233844757]\n",
      "Sentence Perplexity for row 41: 28.235855641691828\n",
      "\n",
      "Processing row 42...\n",
      "Reference Text: No, I hate being by myself.\n",
      "Output Text:  No, I haven't been able to do that. \n",
      "Token Probabilities: [0.010828740894794464]\n",
      "Sentence Perplexity for row 42: 92.34683974022451\n",
      "\n",
      "Processing row 43...\n",
      "Reference Text: I could see that happening but sounds like you were super brave.\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 43: 15.56259441258386\n",
      "\n",
      "Processing row 44...\n",
      "Reference Text: He's quite the piece of garbage.\n",
      "Output Text:  It's tough to see that happen. I'm sorry you're feeling this way. \n",
      "Token Probabilities: [0.019360067322850227]\n",
      "Sentence Perplexity for row 44: 51.65271294380903\n",
      "\n",
      "Processing row 45...\n",
      "Reference Text: Tell me about it. How long have you been job hunting for?\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 45: 15.56259441258386\n",
      "\n",
      "Processing row 46...\n",
      "Reference Text: That is such a beautiful memory to have. I love that we forever have moments like this... How cool Hong Kong! \n",
      "Output Text:  That sounds like a wonderful experience! Nostalgia is always special. \n",
      "Token Probabilities: [0.002678718650713563]\n",
      "Sentence Perplexity for row 46: 373.3128149660725\n",
      "\n",
      "Processing row 47...\n",
      "Reference Text: I think he was slightly over the limit but he had a few drinks earlier, so I felt a bit uncomfortable.\n",
      "Output Text:  I'm here to listen. What happened? \n",
      "Token Probabilities: [0.041594281792640686]\n",
      "Sentence Perplexity for row 47: 24.041766245304686\n",
      "\n",
      "Processing row 48...\n",
      "Reference Text: IT is. \n",
      "Output Text:  I love to hear that! What do you like most about it? \n",
      "Token Probabilities: [0.08936714380979538]\n",
      "Sentence Perplexity for row 48: 11.189794787761718\n",
      "\n",
      "Processing row 49...\n",
      "Reference Text: OH that sucks.\n",
      "Output Text:  That's really sad. Did you find out why? \n",
      "Token Probabilities: [0.046626847237348557]\n",
      "Sentence Perplexity for row 49: 21.446871475345873\n",
      "\n",
      "Processing row 50...\n",
      "Reference Text: thats wonderful\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 50: 15.56259441258386\n",
      "\n",
      "Processing row 51...\n",
      "Reference Text: I've had that feeling as well, especially if it is with someone that is close to me.  Is it because you dont like confrontation or a different reason?\n",
      "Output Text: > \n",
      "Token Probabilities: [0.0036030469927936792]\n",
      "Sentence Perplexity for row 51: 277.5428691327264\n",
      "\n",
      "Processing row 52...\n",
      "Reference Text: No they did not. And it is going to cost too much to take them to court. \n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 52: 15.56259441258386\n",
      "\n",
      "Processing row 53...\n",
      "Reference Text: thats good!\n",
      "Output Text:  It's tough to feel that way; it’s a powerful feeling. \n",
      "Token Probabilities: [0.0034051197580993176]\n",
      "Sentence Perplexity for row 53: 293.6754273095474\n",
      "\n",
      "Processing row 54...\n",
      "Reference Text: That is so true! \n",
      "Output Text:  It’s frustrating when people don't get home. \n",
      "Token Probabilities: [0.06606884300708771]\n",
      "Sentence Perplexity for row 54: 15.135727439524294\n",
      "\n",
      "Processing row 55...\n",
      "Reference Text: I sort of have. I worked like crazy to get a work visa for the US, so I could be with the person I wanted to spend my life with. It paid off, so I can kind of understand what you're saying.\n",
      "Output Text:  Yes, I am sure I will have to work in the back. \n",
      "Token Probabilities: [0.0003801825805567205]\n",
      "Sentence Perplexity for row 55: 2630.3151463058866\n",
      "\n",
      "Processing row 56...\n",
      "Reference Text: It sounds like you did great. Studying is the biggest part really.\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 56: 15.56259441258386\n",
      "\n",
      "Processing row 57...\n",
      "Reference Text: Don't tell her right after she awakes up. Women are never in the best mood right after waking up.\n",
      "Output Text:  That sounds like a great time! Enjoy the meal! \n",
      "Token Probabilities: [0.0074741109274327755]\n",
      "Sentence Perplexity for row 57: 133.79517774209467\n",
      "\n",
      "Processing row 58...\n",
      "Reference Text: Maybe.\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 58: 15.56259441258386\n",
      "\n",
      "Processing row 59...\n",
      "Reference Text: They thought it was a better school, and it probably was, but I didn't feel like it was at the time\n",
      "Output Text:  Yes, we are just going to do a lot of time in school.  \n",
      "Token Probabilities: [0.00113914895337075]\n",
      "Sentence Perplexity for row 59: 877.8483244364074\n",
      "\n",
      "Processing row 60...\n",
      "Reference Text: That's great. I hope you have a wonderful time.\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 60: 15.56259441258386\n",
      "\n",
      "Processing row 61...\n",
      "Reference Text: That is bad. What are you planning to do instead?\n",
      "Output Text:  It's understandable to feel scared. You're not alone. \n",
      "Token Probabilities: [0.021877408027648926]\n",
      "Sentence Perplexity for row 61: 45.70925398183314\n",
      "\n",
      "Processing row 62...\n",
      "Reference Text: A little bit bu, they took the insurance money and bought a big house - i mean BIG! I know they needed more room for my mother to move in, but what they bought was way over and above what was needed.\n",
      "Output Text:  I can't imagine. I hope you enjoy it with you. \n",
      "Token Probabilities: [0.1062888354063034]\n",
      "Sentence Perplexity for row 62: 9.408325871455501\n",
      "\n",
      "Processing row 63...\n",
      "Reference Text: Mostly happy. They have annoyed me greatly all summer\n",
      "Output Text:  I'm here for you! What's on your mind? \n",
      "Token Probabilities: [0.04909326136112213]\n",
      "Sentence Perplexity for row 63: 20.36939433793491\n",
      "\n",
      "Processing row 64...\n",
      "Reference Text: That is really interesting. Still over my head, but you did a decent job of explaining it in layman's terms. I appreciate it. So are you a med student, or what?\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 64: 15.56259441258386\n",
      "\n",
      "Processing row 65...\n",
      "Reference Text: Oh wow! Congratulations! I also recently applied for grad school to study Computer Science (seriously). What are you wanting to study?\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 65: 15.56259441258386\n",
      "\n",
      "Processing row 66...\n",
      "Reference Text: I'm sure that much be hard to stand by and watch as someone who works hard for their things. \n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 66: 15.56259441258386\n",
      "\n",
      "Processing row 67...\n",
      "Reference Text: It does get better, but it was just so sudden.\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 67: 15.56259441258386\n",
      "\n",
      "Processing row 68...\n",
      "Reference Text: True, driving takes more focus than a lot of people can handle\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 68: 15.56259441258386\n",
      "\n",
      "Processing row 69...\n",
      "Reference Text: I have no idea. We found it after she left. It was really gross. I wonder if her house is that nasty?\n",
      "Output Text:  That sounds frustrating! Have you considered talking to them? \n",
      "Token Probabilities: [0.0016521024517714977]\n",
      "Sentence Perplexity for row 69: 605.2893383989177\n",
      "\n",
      "Processing row 70...\n",
      "Reference Text: That's good, it sounds like his bathroom motivated you to take yours to the next level. That's probably good for society.\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 70: 15.56259441258386\n",
      "\n",
      "Processing row 71...\n",
      "Reference Text: I do look a little like a somewhat taller version of him.\n",
      "Output Text:  I don't have a favorite one. I'm not sure what you mean? \n",
      "Token Probabilities: [0.08378517627716064]\n",
      "Sentence Perplexity for row 71: 11.935285505541081\n",
      "\n",
      "Processing row 72...\n",
      "Reference Text: Absolutely! Not to mention gardening saves a ton of money in the long run.\n",
      "Output Text:  That's great! It shows your unique qualities! \n",
      "Token Probabilities: [0.0019208660814911127]\n",
      "Sentence Perplexity for row 72: 520.5984996224873\n",
      "\n",
      "Processing row 73...\n",
      "Reference Text: That's great! Not too many 16 year olds are that responsible.\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 73: 15.56259441258386\n",
      "\n",
      "Processing row 74...\n",
      "Reference Text: The prices have risen alot with all the technology and electrical components.\n",
      "Output Text:  I can't imagine being a free break. \n",
      "Token Probabilities: [0.2657413184642792]\n",
      "Sentence Perplexity for row 74: 3.7630580211575926\n",
      "\n",
      "Processing row 75...\n",
      "Reference Text: Does he get anything else?\n",
      "Output Text:  It's tough when people overlook their own, but it can be tough. \n",
      "Token Probabilities: [0.043171633034944534]\n",
      "Sentence Perplexity for row 75: 23.163358198439404\n",
      "\n",
      "Processing row 76...\n",
      "Reference Text: Sounds like you have a very responsible young lady growing up.\n",
      "Output Text:  That's nice of you to keep yourself occupied. \n",
      "Token Probabilities: [0.022057656198740005]\n",
      "Sentence Perplexity for row 76: 45.33573245452628\n",
      "\n",
      "Processing row 77...\n",
      "Reference Text: ah you used her. You should have filled. But however she will understand\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 77: 15.56259441258386\n",
      "\n",
      "Processing row 78...\n",
      "Reference Text: I gave him some Tylenol, and we ended up snuggling til he could go back to sleep.  \n",
      "Output Text:  It's tough to feel that way; healing takes time. \n",
      "Token Probabilities: [0.0007292355876415968]\n",
      "Sentence Perplexity for row 78: 1371.2989559849589\n",
      "\n",
      "Processing row 79...\n",
      "Reference Text: It was a hand written note from my dead mother. I never had read or seen it before. \n",
      "Output Text:  It was a little crazy! I was so shocked. \n",
      "Token Probabilities: [0.12216077744960785]\n",
      "Sentence Perplexity for row 79: 8.185933495818713\n",
      "\n",
      "Processing row 80...\n",
      "Reference Text: Ouch, I hope you don't either. I'd keep any eye out at work from now on.\n",
      "Output Text:  I understand. I don't think they're just not like to do anything, but I'm sure they're not going to be able to get up. \n",
      "Token Probabilities: [0.30148887634277344]\n",
      "Sentence Perplexity for row 80: 3.316871959359006\n",
      "\n",
      "Processing row 81...\n",
      "Reference Text: I hope both our ego and your nose heal up quickly!\n",
      "Output Text:  It's natural to feel that way; it's okay to feel that way. \n",
      "Token Probabilities: [0.02465965785086155]\n",
      "Sentence Perplexity for row 81: 40.55206305163973\n",
      "\n",
      "Processing row 82...\n",
      "Reference Text: Yeah I would go off with my friends and have adventures. I miss that so much.\n",
      "Output Text:  I understand. Summer vacations are tough for us. \n",
      "Token Probabilities: [0.08941099047660828]\n",
      "Sentence Perplexity for row 82: 11.18430737283489\n",
      "\n",
      "Processing row 83...\n",
      "Reference Text: a bearded dragon\n",
      "Output Text:  It's a wonderful time. What kind of pet do you enjoy? \n",
      "Token Probabilities: [0.0004349658847786486]\n",
      "Sentence Perplexity for row 83: 2299.030878039766\n",
      "\n",
      "Processing row 84...\n",
      "Reference Text: I don't know yet. Kinda need some time to process this.\n",
      "Output Text:  I'm not sure! I can help with her! \n",
      "Token Probabilities: [0.3538871109485626]\n",
      "Sentence Perplexity for row 84: 2.8257598795265237\n",
      "\n",
      "Processing row 85...\n",
      "Reference Text: It feels so good to update/upgrade, doesn't it? I feel like I have been out of the loop for too long.\n",
      "Output Text:  That's a great idea! What do you plan to buy? \n",
      "Token Probabilities: [0.04208002984523773]\n",
      "Sentence Perplexity for row 85: 23.764241700345938\n",
      "\n",
      "Processing row 86...\n",
      "Reference Text: Yeah it hurt and I was listening to music so I might have yelled a cuss word loudly.\n",
      "Output Text:  I'm here to listen. What happened? \n",
      "Token Probabilities: [0.041594281792640686]\n",
      "Sentence Perplexity for row 86: 24.041766245304686\n",
      "\n",
      "Processing row 87...\n",
      "Reference Text: I cannot imagine anyone wanting to drink that without losing a bet\n",
      "Output Text:  That sounds frustrating! It's tough to lose something else. \n",
      "Token Probabilities: [0.00152524933218956]\n",
      "Sentence Perplexity for row 87: 655.630511612457\n",
      "\n",
      "Processing row 88...\n",
      "Reference Text: Im taking your advice and putting it into practice tomorrow!\n",
      "Output Text:  Yes! I am so sorry for you. \n",
      "Token Probabilities: [0.000541865301784128]\n",
      "Sentence Perplexity for row 88: 1845.4770894305893\n",
      "\n",
      "Processing row 89...\n",
      "Reference Text: Thank you, the bracelet means a lot to me\n",
      "Output Text:  I'm sorry to hear that! It's tough to feel that way. \n",
      "Token Probabilities: [0.11154505610466003]\n",
      "Sentence Perplexity for row 89: 8.964987198193025\n",
      "\n",
      "Processing row 90...\n",
      "Reference Text: How terrible! I'm so sorry that happened. How long ago was it?\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 90: 15.56259441258386\n",
      "\n",
      "Processing row 91...\n",
      "Reference Text: That's awesome! It really pays not to burn bridges, you never know when someone from your past can help you out like that.\n",
      "Output Text:  That's great to hear! It's great to see a supportive network! \n",
      "Token Probabilities: [0.0009101488976739347]\n",
      "Sentence Perplexity for row 91: 1098.7213219240257\n",
      "\n",
      "Processing row 92...\n",
      "Reference Text: What did you eat?\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 92: 15.56259441258386\n",
      "\n",
      "Processing row 93...\n",
      "Reference Text: wow good for you man\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 93: 15.56259441258386\n",
      "\n",
      "Processing row 94...\n",
      "Reference Text: Investigate that right now! You need to know\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 94: 15.56259441258386\n",
      "\n",
      "Processing row 95...\n",
      "Reference Text: That's really special, and a great attitude to have\n",
      "Output Text:  \n",
      "Token Probabilities: [0.06425663828849792]\n",
      "Sentence Perplexity for row 95: 15.56259441258386\n",
      "\n",
      "Processing row 96...\n",
      "Reference Text: I've never watched a single full star wars movie, just bits and pieces haha\n",
      "Output Text:  Cool. I am sure I will do the next movie. I am sure it will be fun! \n",
      "Token Probabilities: [0.00016398193838540465]\n",
      "Sentence Perplexity for row 96: 6098.23258491867\n",
      "\n",
      "Processing row 97...\n",
      "Reference Text: Me too! It seems like such a huge accomplishment at the time, doesn't it?\n",
      "Output Text:  That's wonderful! Congratulations on your achievement! \n",
      "Token Probabilities: [0.002624240703880787]\n",
      "Sentence Perplexity for row 97: 381.0626054695276\n",
      "\n",
      "Processing row 98...\n",
      "Reference Text: That's great! good luck\n",
      "Output Text:  That's exciting! Congratulations on your achievement! \n",
      "Token Probabilities: [0.003668899880722165]\n",
      "Sentence Perplexity for row 98: 272.56126700387534\n",
      "\n",
      "Processing row 99...\n",
      "Reference Text: No not at all. I just got up and couldnt stop laughing at myself. I could feel the heat coming off of my face.\n",
      "Output Text:  No, I didn't know. \n",
      "Token Probabilities: [0.012546062469482422]\n",
      "Sentence Perplexity for row 99: 79.7062825434229\n",
      "Completed token-based perplexity calculations for column: new_label_gpt_blocksize_256\n",
      "Average Perplexity for gpt_blocksize_256: 504.67186487360993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'withoutemotion_single': 1061.468651178604,\n",
       " 'withoutemotion_whole': inf,\n",
       " 'withemotion': 1587.2087837246113,\n",
       " 'withcontext': 511.2836617769946,\n",
       " 'gpt_withoutemotion': 404.2289543040273,\n",
       " 'gpt_blocksize_256': 504.67186487360993}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_scores_average()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
